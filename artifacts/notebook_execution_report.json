{
  "timestamp": "2026-01-17T19:38:51.966631",
  "total_notebooks": 817,
  "execution_method": "nbclient",
  "timeout_per_notebook": 300,
  "results": [
    {
      "path": "Course 01/unit1-ai-foundations/examples/01_ai_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.8988161087036133,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/02_ai_history.ipynb",
      "status": "passed",
      "execution_time": 1.030184030532837,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/03_intelligent_agents_rationality.ipynb",
      "status": "passed",
      "execution_time": 0.6810281276702881,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/04_philosophy_turing_test.ipynb",
      "status": "passed",
      "execution_time": 0.6413397789001465,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/05_adversarial_search_minimax.ipynb",
      "status": "passed",
      "execution_time": 0.56492018699646,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/06_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.6964452266693115,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/07_python_basics_for_ai.ipynb",
      "status": "passed",
      "execution_time": 0.5669999122619629,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/08_generative_ai_intro.ipynb",
      "status": "passed",
      "execution_time": 0.5452170372009277,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/09_case_studies_intelligent_agents.ipynb",
      "status": "passed",
      "execution_time": 0.7351217269897461,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/implementing_search_algorithms_uninformed_heuristic_greedy.ipynb",
      "status": "passed",
      "execution_time": 1.5217218399047852,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/examples/working_with_numpy_for_data_processing_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.4738843441009521,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-ai-foundations/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.7032420635223389,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit1-ai-foundations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.5393538475036621,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-ai-foundations",
      "type": "other"
    },
    {
      "path": "Course 01/unit1-introduction/examples/10_implementing_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.5414578914642334,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/10_search_algorithms_uninformed_heuristic.ipynb",
      "status": "passed",
      "execution_time": 0.5700201988220215,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/11_numpy_data_processing.ipynb",
      "status": "passed",
      "execution_time": 0.6140069961547852,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit1-introduction/examples/11_working_with_numpy_data_processing.ipynb",
      "status": "passed",
      "execution_time": 0.5317468643188477,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/01_applied_python_review.ipynb",
      "status": "passed",
      "execution_time": 0.6380667686462402,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/02_encoding_categorical_features.ipynb",
      "status": "passed",
      "execution_time": 1.294867992401123,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/03_supervised_unsupervised_models.ipynb",
      "status": "passed",
      "execution_time": 1.8513069152832031,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_applied_python_review.ipynb",
      "status": "passed",
      "execution_time": 0.8286092281341553,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_data_generation_process.ipynb",
      "status": "passed",
      "execution_time": 0.9834020137786865,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/04_implementing_expert_system.ipynb",
      "status": "passed",
      "execution_time": 0.7325601577758789,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/05_implementing_simple_expert_system.ipynb",
      "status": "passed",
      "execution_time": 0.7433218955993652,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/05_working_with_rdf_sparql.ipynb",
      "status": "passed",
      "execution_time": 0.6990482807159424,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_applying_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.7639532089233398,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_expert_system_python.ipynb",
      "status": "passed",
      "execution_time": 0.7395367622375488,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/06_working_with_rdf_sparql.ipynb",
      "status": "passed",
      "execution_time": 0.814180850982666,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/07_applying_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.6082141399383545,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/07_bayes_theorem_applications.ipynb",
      "status": "passed",
      "execution_time": 0.5592513084411621,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/08_encoding_categorical_features.ipynb",
      "status": "passed",
      "execution_time": 1.2962911128997803,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/09_supervised_unsupervised_models.ipynb",
      "status": "passed",
      "execution_time": 1.5706970691680908,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-ai-concepts/examples/10_data_generation_process.ipynb",
      "status": "passed",
      "execution_time": 0.8284428119659424,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-ai-concepts",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/01_bfs_algorithm.ipynb",
      "status": "passed",
      "execution_time": 1.0470099449157715,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/02_dfs_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.9948818683624268,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/03_astar_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.7783679962158203,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/04_expert_systems.ipynb",
      "status": "passed",
      "execution_time": 0.538327693939209,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/05_bayes_theorem.ipynb",
      "status": "passed",
      "execution_time": 0.7410378456115723,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/06_machine_learning_intro.ipynb",
      "status": "failed",
      "execution_time": 1.5160210132598877,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom sklearn.preprocessing import LabelEncoder\n# Method 1: Label Encoding (for ordinal data)\nlabel_encoder = LabelEncoder()\ndf['location_encoded'] = label_encoder.fit_transform(df['location'])\n\nprint(\"=== Label Encoding ===\")\nprint(df[['location', 'location_encoded']])\n\n# Method 2: One-Hot Encoding (for nominal data)\nonehot_encoder = OneHotEncoder(sparse=False)\nlocation_onehot = onehot_encoder.fit_transform(df[['location']])\nlocation_df = pd.DataFrame(\n location_onehot, columns=[f'location_{cat}' for cat in label_encoder.classes_]\n)\n\nprint(\"\\n=== One-Hot Encoding ===\")\nprint(location_df)\n\n# Combine with original features\nX_encoded = pd.concat([X, location_df], axis=1)\nprint(\"\\n=== Combined Features ===\")\nprint(X_encoded)\n\n------------------\n\n----- stdout -----\n=== Label Encoding ===\n  location  location_encoded\n0        A                 0\n1        B                 1\n2        A                 0\n3        C                 2\n4        B                 1\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 2: One-Hot Encoding (for nominal data)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m location_onehot \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m location_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     13\u001b[0m  location_onehot, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_]\n\u001b[1;32m     14\u001b[0m )\n\n\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom sklearn.preprocessing import LabelEncoder\n# Method 1: Label Encoding (for ordinal data)\nlabel_encoder = LabelEncoder()\ndf['location_encoded'] = label_encoder.fit_transform(df['location'])\n\nprint(\"=== Label Encoding ===\")\nprint(df[['location', 'location_encoded']])\n\n# Method 2: One-Hot Encoding (for nominal data)\nonehot_encoder = OneHotEncoder(sparse=False)\nlocation_onehot = onehot_encoder.fit_transform(df[['location']])\nlocation_df = pd.DataFrame(\n location_onehot, columns=[f'location_{cat}' for cat in label_encoder.classes_]\n)\n\nprint(\"\\n=== One-Hot Encoding ===\")\nprint(location_df)\n\n# Combine with original features\nX_encoded = pd.concat([X, location_df], axis=1)\nprint(\"\\n=== Combined Features ===\")\nprint(X_encoded)\n\n------------------\n\n----- stdout -----\n=== Label Encoding ===\n  location  location_encoded\n0        A                 0\n1        B                 1\n2        A                 0\n3        C                 2\n4        B                 1\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 2: One-Hot Encoding (for nominal data)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m location_onehot \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m location_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     13\u001b[0m  location_onehot, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_]\n\u001b[1;32m     14\u001b[0m )\n\n\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/examples/07_rdf_sparql_knowledge_graph.ipynb",
      "status": "failed",
      "execution_time": 0.7716009616851807,
      "error": "An error occurred while executing the following cell:\n------------------\n# Serialize the graph in different formats\nprint(\"=\" * 60)\nprint(\"RDF/XML Format:\")\nprint(\"=\" * 60)\nprint(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\u001b[0m\n\u001b[0m                                                                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Serialize the graph in different formats\nprint(\"=\" * 60)\nprint(\"RDF/XML Format:\")\nprint(\"=\" * 60)\nprint(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else (g.serialize(format='xml') if isinstance(g.serialize(format='xml'), str) else g.serialize(format='xml').decode(\\'utf-8\\')))\u001b[0m\n\u001b[0m                                                                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 01/unit2-search-algorithms/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6273448467254639,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 1: AI Concepts and Applications\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0627\u0644\u062a\u0637\u0628\u064a\u0642\u0627\u062a\n\nComplete the following exercises to practice Unit 2 concepts.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0648\u062d\u062f\u0629 2.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n\n# Exercise 1: Expert System Implementation\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631p\nrint(\"Exercise 1: Expert System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631\")\nprint(\"-\" * 60)\n\n# TODO: Create a simple expert system for product recommendation\n# The system should recommend products based on:\n# - Budget (low, medium, high)\n# - Interest (tech, fashion, sports)\n# - Age group (young, adult, senior)\n# TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637 \u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u0645\u0646\u062a\u062c\u0627\u062a\n\ndef bfs_complete(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Complete the BFS implementation.\n TODO: \u0623\u0643\u0645\u0644 \u062a\u0646\u0641\u064a\u0630 BFS.\n \n Args:\n graph: Dictionary representing the graph\n start: Starting nodegoal: Target node\n \n Returns:\n Shortest path from start to goal\n \"\"\"\n # TODO: Initialize queue with start node\n # TODO: Initialize visited se\nt\n # TODO: Implement BFS algorith\nm\n # TODO: Return path when goal is foun\nd\n pass\n\n# Test your implementation\nprint(\"\\nTesting BFS:\")\nresult = bfs_complete(graph, '1', '6')\nprint(f\"Path from 1 to 6: {result}\")\n\n# Exercise 2: DFS Path Findin\ng\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DF\nSp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: DFS Path Finding\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DFS\")\nprint(\"=\" * 60)\n\ndef dfs_path(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Implement DFS to find any path from start to goal.\n TODO: \u0646\u0641\u0630 DFS \u0644\u0625\u064a\u062c\u0627\u062f \u0623\u064a \u0645\u0633\u0627\u0631 \u0645\u0646 \u0627\u0644\u0628\u062f\u0627\u064a\u0629 \u0625\u0644\u0649 \u0627\u0644\u0647\u062f\u0641.\n \"\"\"\n # TODO: Implement DFS (recursive or iterativ\ne)\n pass\n\n# Test your implementation\nresult = dfs_path(graph, '4', '3')\nprint(f\"Path from 4 to 3: {result}\")\n\n# Exercise 3: Maze Solver\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 3: Maze Solver\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629\")\nprint(\"=\" * 60)\n\n# Simple maze representation (0 = wall, 1 = path)\n# \u062a\u0645\u062b\u064a\u0644 \u0645\u062a\u0627\u0647\u0629 \u0628\u0633\u064a\u0637\u0629 (0 = \u062c\u062f\u0627\u0631\u060c 1 = \u0645\u0633\u0627\u0631)\nmaze = [\n [1, 1, 0, 1],\n [0, 1, 1, 1],\n [1, 0, 1, 0],\n [1, 1, 1, 1]\n]\n\ndef solve_maze(maze, start, end):\n \n    \n    \"\"\"\n TODO: Use BFS or DFS to solve the maze.\n TODO: \u0627\u0633\u062a\u062e\u062f\u0645 BFS \u0623\u0648 DFS \u0644\u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629.\n \n Args:\n maze: 2D list representing the mazestart: (row, col) starting position\n end: (row, col) ending position\n \n Returns:\n List of (row, col) positions forming the path\n \"\"\"\n # TODO: Implement maze solving algorith\nm\n pass\n\n# Test maze solver\nstart_pos = (0, 0)\nend_pos = (3, 3)\npath = solve_maze(maze, start_pos, end_pos)\nprint(f\"Path from {start_pos} to {end_pos}: {path}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 1: AI Concepts and Applications\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0648\u0627\u0644\u062a\u0637\u0628\u064a\u0642\u0627\u062a\n\nComplete the following exercises to practice Unit 2 concepts.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629 \u0644\u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0648\u062d\u062f\u0629 2.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n\n# Exercise 1: Expert System Implementation\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631p\nrint(\"Exercise 1: Expert System\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631\")\nprint(\"-\" * 60)\n\n# TODO: Create a simple expert system for product recommendation\n# The system should recommend products based on:\n# - Budget (low, medium, high)\n# - Interest (tech, fashion, sports)\n# - Age group (young, adult, senior)\n# TODO: \u0623\u0646\u0634\u0626 \u0646\u0638\u0627\u0645 \u062e\u0628\u064a\u0631 \u0628\u0633\u064a\u0637 \u0644\u062a\u0648\u0635\u064a\u0629 \u0627\u0644\u0645\u0646\u062a\u062c\u0627\u062a\n\ndef bfs_complete(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Complete the BFS implementation.\n TODO: \u0623\u0643\u0645\u0644 \u062a\u0646\u0641\u064a\u0630 BFS.\n \n Args:\n graph: Dictionary representing the graph\n start: Starting nodegoal: Target node\n \n Returns:\n Shortest path from start to goal\n \"\"\"\n # TODO: Initialize queue with start node\n # TODO: Initialize visited se\nt\n # TODO: Implement BFS algorith\nm\n # TODO: Return path when goal is foun\nd\n pass\n\n# Test your implementation\nprint(\"\\nTesting BFS:\")\nresult = bfs_complete(graph, '1', '6')\nprint(f\"Path from 1 to 6: {result}\")\n\n# Exercise 2: DFS Path Findin\ng\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DF\nSp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: DFS Path Finding\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0625\u064a\u062c\u0627\u062f \u0627\u0644\u0645\u0633\u0627\u0631 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 DFS\")\nprint(\"=\" * 60)\n\ndef dfs_path(graph, start, goal):\n \n    \n    \"\"\"\n TODO: Implement DFS to find any path from start to goal.\n TODO: \u0646\u0641\u0630 DFS \u0644\u0625\u064a\u062c\u0627\u062f \u0623\u064a \u0645\u0633\u0627\u0631 \u0645\u0646 \u0627\u0644\u0628\u062f\u0627\u064a\u0629 \u0625\u0644\u0649 \u0627\u0644\u0647\u062f\u0641.\n \"\"\"\n # TODO: Implement DFS (recursive or iterativ\ne)\n pass\n\n# Test your implementation\nresult = dfs_path(graph, '4', '3')\nprint(f\"Path from 4 to 3: {result}\")\n\n# Exercise 3: Maze Solver\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 3: Maze Solver\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 3: \u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629\")\nprint(\"=\" * 60)\n\n# Simple maze representation (0 = wall, 1 = path)\n# \u062a\u0645\u062b\u064a\u0644 \u0645\u062a\u0627\u0647\u0629 \u0628\u0633\u064a\u0637\u0629 (0 = \u062c\u062f\u0627\u0631\u060c 1 = \u0645\u0633\u0627\u0631)\nmaze = [\n [1, 1, 0, 1],\n [0, 1, 1, 1],\n [1, 0, 1, 0],\n [1, 1, 1, 1]\n]\n\ndef solve_maze(maze, start, end):\n \n    \n    \"\"\"\n TODO: Use BFS or DFS to solve the maze.\n TODO: \u0627\u0633\u062a\u062e\u062f\u0645 BFS \u0623\u0648 DFS \u0644\u062d\u0644 \u0627\u0644\u0645\u062a\u0627\u0647\u0629.\n \n Args:\n maze: 2D list representing the mazestart: (row, col) starting position\n end: (row, col) ending position\n \n Returns:\n List of (row, col) positions forming the path\n \"\"\"\n # TODO: Implement maze solving algorith\nm\n pass\n\n# Test maze solver\nstart_pos = (0, 0)\nend_pos = (3, 3)\npath = solve_maze(maze, start_pos, end_pos)\nprint(f\"Path from {start_pos} to {end_pos}: {path}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder for answers.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/ \u0644\u0644\u0625\u062c\u0627\u0628\u0627\u062a.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit2-search-algorithms/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.5304548740386963,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit2-search-algorithms",
      "type": "other"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/01_knowledge_graph.ipynb",
      "status": "passed",
      "execution_time": 0.6827938556671143,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/02_rule_based_systems.ipynb",
      "status": "passed",
      "execution_time": 0.6388571262359619,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/03_expert_systems.ipynb",
      "status": "passed",
      "execution_time": 0.526756763458252,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/04_regression_classification.ipynb",
      "status": "passed",
      "execution_time": 1.5710771083831787,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/examples/05_perceptron_xor.ipynb",
      "status": "passed",
      "execution_time": 13.298107862472534,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.7103266716003418,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit3-knowledge-representation/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6474928855895996,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-knowledge-representation",
      "type": "other"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/04_implementing_regression_classification.ipynb",
      "status": "passed",
      "execution_time": 1.4593462944030762,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/04_xor_problem_neural_network.ipynb",
      "status": "passed",
      "execution_time": 0.7542917728424072,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit3-ml-basics/examples/05_solving_xor_keras.ipynb",
      "status": "passed",
      "execution_time": 11.721268892288208,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit3-ml-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/05_single_neuron_activation_functions.ipynb",
      "status": "passed",
      "execution_time": 0.893444299697876,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/06_multiclass_classification_keras.ipynb",
      "status": "passed",
      "execution_time": 0.6822249889373779,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/07_cnn_image_classification.ipynb",
      "status": "passed",
      "execution_time": 0.6164920330047607,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/08_rnn_lstm_gru_sequential.ipynb",
      "status": "passed",
      "execution_time": 0.7166039943695068,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks/examples/09_early_stopping_regularization.ipynb",
      "status": "passed",
      "execution_time": 0.7665481567382812,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/01_simple_perceptron.ipynb",
      "status": "passed",
      "execution_time": 0.6847889423370361,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/02_generative_ai_intro.ipynb",
      "status": "passed",
      "execution_time": 0.7789640426635742,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/03_cnn_rnn_architectures.ipynb",
      "status": "passed",
      "execution_time": 3.085097074508667,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/applying_early_stopping_and_regularization_to_prevent_overfitting.ipynb",
      "status": "passed",
      "execution_time": 1.5320651531219482,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/building_a_multi_class_classification_model_with_keras.ipynb",
      "status": "passed",
      "execution_time": 1.3419389724731445,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/experimenting_with_rnn_lstm_gru_for_sequential_data.ipynb",
      "status": "passed",
      "execution_time": 1.525038242340088,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/implementing_a_cnn_for_image_classification_using_tensorflowkeras.ipynb",
      "status": "passed",
      "execution_time": 1.5070371627807617,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/examples/implementing_a_single_neuron_with_different_activation_functions_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.7094807624816895,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "example"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6478140354156494,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 1: Neural Networks Basics\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\nComplete the following exercises.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Implement Activation Function\ns\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637p\nrint(\"Exercise 1: Activation Functions\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\nprint(\"-\" * 60)\n\ndef sigmoid(x):\n \n    \n    \"\"\"\n TODO: Implement sigmoid activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n \n Formula: 1\n(1 + e^(-x))\n \"\"\"\n # TODO: Implement sigmoi\nd\n pass\n\ndef relu(x):\n \n    \n    \"\"\"\n TODO: Implement ReLU activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n \n Formula: max(0, x)\n \"\"\"\n # TODO: Implement ReLU\n pass\n\n# Test activation function\nst\nest_values = [-2, -1, 0, 1, 2]\nprint(\"\\nTesting activation functions:\")\nfor x in test_values:\n sig_result = sigmoid(x)\n relu_result = relu(x)\n print(f\"x={x:3d}: sigmoid={sig_result:.3f}, ReLU={relu_result:.3f}\")\n\n# Exercise 2: Simple Perceptron for OR Gate\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: OR Gate Perceptron\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\nprint(\"=\" * 60)\n\n# TODO: Create training data for OR gate\n# TODO: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nX_or = np.array([\n # TODO: Add OR gate inputs\n])\n\ny_or = np.array([\n # TODO: Add OR gate output\ns\n])\n\n# TODO: Train a perceptron to learn OR gate\n# TODO: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:41\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 1: Neural Networks Basics\u0627\u0644\u0648\u062d\u062f\u0629 4 - \u062a\u0645\u0631\u064a\u0646 1: \u0623\u0633\u0627\u0633\u064a\u0627\u062a \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\nComplete the following exercises.\n\u0623\u0643\u0645\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646 \u0627\u0644\u062a\u0627\u0644\u064a\u0629.\n\"\"\"\n\nimport numpy as np\n\n# Exercise 1: Implement Activation Function\ns\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062a\u0646\u0641\u064a\u0630 \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637p\nrint(\"Exercise 1: Activation Functions\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 1: \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637\")\nprint(\"-\" * 60)\n\ndef sigmoid(x):\n \n    \n    \"\"\"\n TODO: Implement sigmoid activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 \u0627\u0644\u0633\u064a\u062c\u0645\u0648\u064a\u062f.\n \n Formula: 1\n(1 + e^(-x))\n \"\"\"\n # TODO: Implement sigmoi\nd\n pass\n\ndef relu(x):\n \n    \n    \"\"\"\n TODO: Implement ReLU activation function.\n TODO: \u0646\u0641\u0630 \u062f\u0627\u0644\u0629 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 ReLU.\n \n Formula: max(0, x)\n \"\"\"\n # TODO: Implement ReLU\n pass\n\n# Test activation function\nst\nest_values = [-2, -1, 0, 1, 2]\nprint(\"\\nTesting activation functions:\")\nfor x in test_values:\n sig_result = sigmoid(x)\n relu_result = relu(x)\n print(f\"x={x:3d}: sigmoid={sig_result:.3f}, ReLU={relu_result:.3f}\")\n\n# Exercise 2: Simple Perceptron for OR Gate\n# \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0633\u064a\u0637 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercise 2: OR Gate Perceptron\")\nprint(\"\u0627\u0644\u062a\u0645\u0631\u064a\u0646 2: \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0628\u0648\u0627\u0628\u0629 OR\")\nprint(\"=\" * 60)\n\n# TODO: Create training data for OR gate\n# TODO: \u0623\u0646\u0634\u0626 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0644\u0628\u0648\u0627\u0628\u0629 OR\nX_or = np.array([\n # TODO: Add OR gate inputs\n])\n\ny_or = np.array([\n # TODO: Add OR gate output\ns\n])\n\n# TODO: Train a perceptron to learn OR gate\n# TODO: \u062f\u0631\u0628 \u0628\u064a\u0631\u0633\u0628\u062a\u0631\u0648\u0646 \u0644\u062a\u0639\u0644\u0645 \u0628\u0648\u0627\u0628\u0629 OR\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Exercises completed! Check solutions/ folder.\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u062a\u0645\u0627\u0631\u064a\u0646! \u0631\u0627\u062c\u0639 \u0645\u062c\u0644\u062f solutions/.\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:41\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit4-neural-networks-basics/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7310788631439209,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit4-neural-networks-basics",
      "type": "other"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/04_gan_transformer_generative.ipynb",
      "status": "passed",
      "execution_time": 0.7678251266479492,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/05_eda_data_preprocessing_medical.ipynb",
      "status": "passed",
      "execution_time": 1.485558032989502,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai/examples/06_feature_scaling_encoding_missing_data.ipynb",
      "status": "passed",
      "execution_time": 1.2752110958099365,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/01_generative_ai_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.8047809600830078,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/02_generative_vs_discriminative.ipynb",
      "status": "passed",
      "execution_time": 1.8018889427185059,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/03_course_summary.ipynb",
      "status": "passed",
      "execution_time": 0.7246031761169434,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/04_diabetes_classification_ffnn.ipynb",
      "status": "failed",
      "execution_time": 0.8083949089050293,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nprint(\"=== Binary Classification Metrics ===\")\nprint(\"\\nMetrics for evaluating binary classification:\")\nprint(\" - Accuracy: (TP + TN)\n(TP + TN + FP + FN)\")\nprint(\" - Precision: TP\n(TP + FP) - How many predicted positives are actually positive?\")\nprint(\" - Recall: TP\n(TP + FN) - How many actual positives did we catch?\")\nprint(\" - F1-score: 2 * (Precision * Recall)\n(Precision + Recall) - Harmonic mean\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" - Accuracy: (TP + TN)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 13)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nprint(\"=== Binary Classification Metrics ===\")\nprint(\"\\nMetrics for evaluating binary classification:\")\nprint(\" - Accuracy: (TP + TN)\n(TP + TN + FP + FN)\")\nprint(\" - Precision: TP\n(TP + FP) - How many predicted positives are actually positive?\")\nprint(\" - Recall: TP\n(TP + FN) - How many actual positives did we catch?\")\nprint(\" - F1-score: 2 * (Precision * Recall)\n(Precision + Recall) - Harmonic mean\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" - Accuracy: (TP + TN)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 13)\n\n\n",
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/developing_simple_supervised_and_unsupervised_learning_models.ipynb",
      "status": "passed",
      "execution_time": 1.2898988723754883,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/eda_and_data_preprocessing_for_medical_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.632171869277954,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/encoding_categorical_features_for_ml_models.ipynb",
      "status": "passed",
      "execution_time": 1.5098659992218018,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/exploring_the_data_generation_process_using_python_and_pandas.ipynb",
      "status": "passed",
      "execution_time": 1.536139965057373,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/implementing_a_simple_expert_system_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.4356632232666016,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/implementing_feature_scaling_encoding_and_handling_missing_data_in_a_medical_dat.ipynb",
      "status": "passed",
      "execution_time": 1.5029840469360352,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/examples/solving_the_xor_problem_using_a_neural_network_in_keras.ipynb",
      "status": "passed",
      "execution_time": 1.4021267890930176,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "example"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/exercises/01_generative_ai_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.6566119194030762,
      "error": null,
      "error_traceback": null,
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "exercise"
    },
    {
      "path": "Course 01/unit5-generative-ai-intro/solutions/01_generative_ai_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7621850967407227,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Solution 1: Generative AI Concepts\n\u0627\u0644\u0648\u062d\u062f\u0629 5 - \u062d\u0644 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\n\nComplete solutions to Exercise 1.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt_\nprint(\"=\" * 70)\nprint(\"Solution 1: Generative AI Concepts\")\nprint(\"=\" * 70)\n\n# Solution 1: Identify Model Types_\nprint(\"\\nSolution 1: Identify Model Types\")\nprint(\"-\" * 70)\n\nmodels = {\n    \"Logistic Regression\": \"D\",  # Discriminative - learns P(Y|X)\n    \"GAN (Generative Adversarial Network)\": \"G\",  # Generative - creates new data\n    \"Support Vector Machine\": \"D\",  # Discriminative - learns decision boundary\n    \"VAE (Variational Autoencoder)\": \"G\",  # Generative - learns data distribution\n    \"Neural Network Classifier\": \"D\",  # Discriminative - learns P(Y|X)\n    \"Naive Bayes\": \"G\"  # Generative - learns P(X|Y) and P(Y)\n}\n\nfor model, answer in models.items():\n    print(f\"{model}: {answer}\")\n\n# Solution 2: Generate Synthetic Data_\nprint(\"\\nSolution 2: Generate Synthetic Data\")\nprint(\"-\" * 70)\n\ndef generate_square_pattern(n_points=100):\n    \n    \n    \n    \"\"\"\n    Generate synthetic data points forming a square pattern.\n    \"\"\"\n    # Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\n    \n    # Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\n    y_top = np.full(points_per_side, side_length/2)\n    \n    # Right side_x_right = np.full(points_per_side, side_length/2)\n    y_right = np.linspace(side_length/2, -side_length/2, points_per_side)\n    \n    # Bottom side_x_bottom = np.linspace(side_length/2, -side_length/2, points_per_side)\n    y_bottom = np.full(points_per_side, -side_length/2)\n    \n    # Left side_x_left = np.full(points_per_side, -side_length/2)\n    y_left = np.linspace(-side_length/2, side_length/2, points_per_side)\n    \n    # Combine and add noise_x = np.concatenate([x_top, x_right, x_bottom, x_left])\n    y = np.concatenate([y_top, y_right, y_bottom, y_left])\n    \n    # Add noise to make it more realistic\n    x += np.random.normal(0, 0.1, len(x))\n    y += np.random.normal(0, 0.1, len(y))\n    \n    return x, y\n\n# Test and visualize\nx_square, y_square = generate_square_pattern(200)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_square, y_square, alpha=0.6, s=30)\nplt.title('Generated Square Pattern\\n(Solution)', fontsize=12)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.show()\n\nprint(\"\u2705 Square pattern generated successfully!\")\n\n# Solution 3: Compare Approaches_\nprint(\"\\nSolution 3: Compare Generative vs Discriminative\")\nprint(\"-\" * 70)\n\ncomparison = {\n    \"What does it learn?\": {\n        \"Generative\": \"P(X|Y) and P(Y) - Joint probability distribution\", \"Discriminative\": \"P(Y|X) - Conditional probability\"\n    },\n    \"Can it generate new data?\": {\n        \"Generative\": True,\n        \"Discriminative\": False\n    },\n    \"Best use case\": {\n        \"Generative\": \"Image generation, data augmentation, anomaly detection\",\n        \"Discriminative\": \"Classification, prediction, spam detection\"\n    }\n}\n\nfor question, answers in comparison.items():\n    print(f\"\\n{question}\")\n    for model_type, answer in answers.items():\n        print(f\"  {model_type}: {answer}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\u2705 All exercises completed!\")\nprint(\"=\" * 70)\n\n------------------\n\n----- stdout -----\n======================================================================\nSolution 1: Generative AI Concepts\n======================================================================\n\nSolution 1: Identify Model Types\n----------------------------------------------------------------------\nLogistic Regression: D\nGAN (Generative Adversarial Network): G\nSupport Vector Machine: D\nVAE (Variational Autoencoder): G\nNeural Network Classifier: D\nNaive Bayes: G\n\nSolution 2: Generate Synthetic Data\n----------------------------------------------------------------------\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Test and visualize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m x_square, y_square \u001b[38;5;241m=\u001b[39m generate_square_pattern(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_square, y_square, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mgenerate_square_pattern\u001b[0;34m(n_points)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mGenerate synthetic data points forming a square pattern.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m y_top \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(points_per_side, side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Right side_x_right = np.full(points_per_side, side_length/2)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39mside_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, points_per_side)\n\n\u001b[0;31mNameError\u001b[0m: name 'points_per_side' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Solution 1: Generative AI Concepts\n\u0627\u0644\u0648\u062d\u062f\u0629 5 - \u062d\u0644 1: \u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0630\u0643\u0627\u0621 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\n\nComplete solutions to Exercise 1.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt_\nprint(\"=\" * 70)\nprint(\"Solution 1: Generative AI Concepts\")\nprint(\"=\" * 70)\n\n# Solution 1: Identify Model Types_\nprint(\"\\nSolution 1: Identify Model Types\")\nprint(\"-\" * 70)\n\nmodels = {\n    \"Logistic Regression\": \"D\",  # Discriminative - learns P(Y|X)\n    \"GAN (Generative Adversarial Network)\": \"G\",  # Generative - creates new data\n    \"Support Vector Machine\": \"D\",  # Discriminative - learns decision boundary\n    \"VAE (Variational Autoencoder)\": \"G\",  # Generative - learns data distribution\n    \"Neural Network Classifier\": \"D\",  # Discriminative - learns P(Y|X)\n    \"Naive Bayes\": \"G\"  # Generative - learns P(X|Y) and P(Y)\n}\n\nfor model, answer in models.items():\n    print(f\"{model}: {answer}\")\n\n# Solution 2: Generate Synthetic Data_\nprint(\"\\nSolution 2: Generate Synthetic Data\")\nprint(\"-\" * 70)\n\ndef generate_square_pattern(n_points=100):\n    \n    \n    \n    \"\"\"\n    Generate synthetic data points forming a square pattern.\n    \"\"\"\n    # Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\n    \n    # Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\n    y_top = np.full(points_per_side, side_length/2)\n    \n    # Right side_x_right = np.full(points_per_side, side_length/2)\n    y_right = np.linspace(side_length/2, -side_length/2, points_per_side)\n    \n    # Bottom side_x_bottom = np.linspace(side_length/2, -side_length/2, points_per_side)\n    y_bottom = np.full(points_per_side, -side_length/2)\n    \n    # Left side_x_left = np.full(points_per_side, -side_length/2)\n    y_left = np.linspace(-side_length/2, side_length/2, points_per_side)\n    \n    # Combine and add noise_x = np.concatenate([x_top, x_right, x_bottom, x_left])\n    y = np.concatenate([y_top, y_right, y_bottom, y_left])\n    \n    # Add noise to make it more realistic\n    x += np.random.normal(0, 0.1, len(x))\n    y += np.random.normal(0, 0.1, len(y))\n    \n    return x, y\n\n# Test and visualize\nx_square, y_square = generate_square_pattern(200)\nplt.figure(figsize=(8, 8))\nplt.scatter(x_square, y_square, alpha=0.6, s=30)\nplt.title('Generated Square Pattern\\n(Solution)', fontsize=12)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.show()\n\nprint(\"\u2705 Square pattern generated successfully!\")\n\n# Solution 3: Compare Approaches_\nprint(\"\\nSolution 3: Compare Generative vs Discriminative\")\nprint(\"-\" * 70)\n\ncomparison = {\n    \"What does it learn?\": {\n        \"Generative\": \"P(X|Y) and P(Y) - Joint probability distribution\", \"Discriminative\": \"P(Y|X) - Conditional probability\"\n    },\n    \"Can it generate new data?\": {\n        \"Generative\": True,\n        \"Discriminative\": False\n    },\n    \"Best use case\": {\n        \"Generative\": \"Image generation, data augmentation, anomaly detection\",\n        \"Discriminative\": \"Classification, prediction, spam detection\"\n    }\n}\n\nfor question, answers in comparison.items():\n    print(f\"\\n{question}\")\n    for model_type, answer in answers.items():\n        print(f\"  {model_type}: {answer}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\u2705 All exercises completed!\")\nprint(\"=\" * 70)\n\n------------------\n\n----- stdout -----\n======================================================================\nSolution 1: Generative AI Concepts\n======================================================================\n\nSolution 1: Identify Model Types\n----------------------------------------------------------------------\nLogistic Regression: D\nGAN (Generative Adversarial Network): G\nSupport Vector Machine: D\nVAE (Variational Autoencoder): G\nNeural Network Classifier: D\nNaive Bayes: G\n\nSolution 2: Generate Synthetic Data\n----------------------------------------------------------------------\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Test and visualize\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m x_square, y_square \u001b[38;5;241m=\u001b[39m generate_square_pattern(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_square, y_square, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\nCell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mgenerate_square_pattern\u001b[0;34m(n_points)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mGenerate synthetic data points forming a square pattern.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate points along square perimeter_side_length = 4_points_per_side = n_points // 4\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Top side_x_top = np.linspace(-side_length/2, side_length/2, points_per_side)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m y_top \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(points_per_side, side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Right side_x_right = np.full(points_per_side, side_length/2)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(side_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39mside_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, points_per_side)\n\n\u001b[0;31mNameError\u001b[0m: name 'points_per_side' is not defined\n\n",
      "course": "Course 01",
      "unit": "unit5-generative-ai-intro",
      "type": "other"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_01_search_algorithms_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5450179576873779,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_02_knowledge_representation_solution.ipynb",
      "status": "passed",
      "execution_time": 0.574181079864502,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_03_probability_and_uncertainty_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5217149257659912,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_04_optimization_techniques_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5816810131072998,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/SOLUTIONS/exercise_05_machine_learning_models_solution.ipynb",
      "status": "passed",
      "execution_time": 0.667651891708374,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_01_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.520806074142456,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_02_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.744271993637085,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_03_probability_and_uncertainty.ipynb",
      "status": "passed",
      "execution_time": 0.6356589794158936,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_04_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.7342960834503174,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/EXERCISES/exercise_05_machine_learning_models.ipynb",
      "status": "passed",
      "execution_time": 0.5209980010986328,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 02/NOTEBOOKS/00_Python_Libraries_for_AI.ipynb",
      "status": "passed",
      "execution_time": 13.217427015304565,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/01_Introduction_Search_Algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.2104918956756592,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/02_Knowledge_Representation.ipynb",
      "status": "passed",
      "execution_time": 1.0285792350769043,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/03_Learning_Under_Uncertainty.ipynb",
      "status": "passed",
      "execution_time": 1.497725009918213,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/04_Optimization_Techniques.ipynb",
      "status": "passed",
      "execution_time": 2.202730894088745,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/NOTEBOOKS/05_AI_Learning_Models.ipynb",
      "status": "passed",
      "execution_time": 2.0673251152038574,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/00_Python_Libraries_for_AI.ipynb",
      "status": "passed",
      "execution_time": 11.961430788040161,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/01_Introduction_Search_Algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.0678248405456543,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/02_real_world_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 0.7323288917541504,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/03_implementing_ai_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.5348742008209229,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/04_implementing_adversarial_search.ipynb",
      "status": "passed",
      "execution_time": 0.760840892791748,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/05_ai_learning_methods_research.ipynb",
      "status": "passed",
      "execution_time": 0.5844502449035645,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/ai_learning_methods_and_research.ipynb",
      "status": "passed",
      "execution_time": 1.3326337337493896,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/evaluating_ai_models.ipynb",
      "status": "passed",
      "execution_time": 1.2504019737243652,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/implementing_adversarial_search.ipynb",
      "status": "passed",
      "execution_time": 1.6074087619781494,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/implementing_ai_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.3382439613342285,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/examples/real_world_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.4934117794036865,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "example"
    },
    {
      "path": "Course 02/unit1-search-algorithms/exercises/exercise_01_search_algorithms.ipynb",
      "status": "passed",
      "execution_time": 0.5427510738372803,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit1-search-algorithms",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/02_Knowledge_Representation.ipynb",
      "status": "passed",
      "execution_time": 1.028223991394043,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/03_propositional_logic_truth_tables.ipynb",
      "status": "passed",
      "execution_time": 0.9551489353179932,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/04_inference_rules_logical_reasoning.ipynb",
      "status": "passed",
      "execution_time": 0.8313701152801514,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/05_first_order_logic_fol.ipynb",
      "status": "passed",
      "execution_time": 0.8576161861419678,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/06_logical_operators_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.6690330505371094,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/07_logical_arguments_validation.ipynb",
      "status": "passed",
      "execution_time": 0.7327487468719482,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/08_model_checking_temporal_logic.ipynb",
      "status": "passed",
      "execution_time": 0.5895922183990479,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/09_fol_parsing_evaluation.ipynb",
      "status": "passed",
      "execution_time": 0.514477014541626,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/building_logical_arguments_and_validating_them_programmatically.ipynb",
      "status": "passed",
      "execution_time": 1.4815900325775146,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/implementing_logical_operators_and_or_not_implies_biconditional.ipynb",
      "status": "passed",
      "execution_time": 1.5137920379638672,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/implementing_model_checking_algorithms_for_temporal_logic.ipynb",
      "status": "passed",
      "execution_time": 1.5937559604644775,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/examples/writing_code_to_parse_and_evaluate_fol_formulas.ipynb",
      "status": "passed",
      "execution_time": 1.4117729663848877,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "example"
    },
    {
      "path": "Course 02/unit2-knowledge-representation/exercises/exercise_02_knowledge_representation.ipynb",
      "status": "passed",
      "execution_time": 0.6451399326324463,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit2-knowledge-representation",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/02_bayesian_networks.ipynb",
      "status": "passed",
      "execution_time": 0.525749921798706,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/03_Learning_Under_Uncertainty.ipynb",
      "status": "passed",
      "execution_time": 1.4505829811096191,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/03_hmm_viterbi.ipynb",
      "status": "passed",
      "execution_time": 0.538020133972168,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/examples/04_mdp_value_iteration.ipynb",
      "status": "passed",
      "execution_time": 0.8612592220306396,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "example"
    },
    {
      "path": "Course 02/unit3-learning-under-uncertainty/exercises/exercise_03_probability_and_uncertainty.ipynb",
      "status": "passed",
      "execution_time": 0.8486719131469727,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit3-learning-under-uncertainty",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/03_gradient_descent_variants.ipynb",
      "status": "passed",
      "execution_time": 0.7646899223327637,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/04_Optimization_Techniques.ipynb",
      "status": "passed",
      "execution_time": 2.0005228519439697,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/04_advanced_optimizers_adam_rmsprop.ipynb",
      "status": "passed",
      "execution_time": 0.547015905380249,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/applying_advanced_optimizers_adam_rmsprop_in_neural_networks.ipynb",
      "status": "passed",
      "execution_time": 1.5648679733276367,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/comparing_different_optimization_algorithms_on_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.4944789409637451,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_bayesian_optimization_for_hyperparameter_search.ipynb",
      "status": "passed",
      "execution_time": 1.5212829113006592,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_gradient_descent_algorithms_batch_stochastic_mini_batch.ipynb",
      "status": "passed",
      "execution_time": 1.4992609024047852,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/implementing_regularization_techniques_l1_l2_dropout_early_stopping.ipynb",
      "status": "passed",
      "execution_time": 1.3315110206604004,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/performing_hyperparameter_tuning_using_grid_search_and_random_search.ipynb",
      "status": "passed",
      "execution_time": 1.269484043121338,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/examples/using_cross_validation_to_select_optimal_hyperparameters.ipynb",
      "status": "passed",
      "execution_time": 1.3880729675292969,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "example"
    },
    {
      "path": "Course 02/unit4-optimization-techniques/exercises/exercise_04_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.6098461151123047,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit4-optimization-techniques",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/03_neural_network_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.6568529605865479,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/04_transfer_learning_pretrained.ipynb",
      "status": "passed",
      "execution_time": 0.5250160694122314,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/05_AI_Learning_Models.ipynb",
      "status": "passed",
      "execution_time": 2.0263519287109375,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/05_model_evaluation_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.6573781967163086,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/applying_transfer_learning_with_pre_trained_models_vgg_resnet_bert.ipynb",
      "status": "passed",
      "execution_time": 1.4066500663757324,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/building_simple_apis_for_model_serving_flask_fastapi.ipynb",
      "status": "passed",
      "execution_time": 1.5067081451416016,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/fine_tuning_pre_trained_models_for_domain_specific_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.3726091384887695,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/implementing_different_neural_network_architectures_feedforward_cnn_rnn.ipynb",
      "status": "passed",
      "execution_time": 1.494898796081543,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/implementing_model_selection_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.2662081718444824,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/introduction_to_reinforcement_learning_setting_up_environments_and_agents.ipynb",
      "status": "passed",
      "execution_time": 1.3432657718658447,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/performing_model_evaluation_and_comparison_using_cross_validation.ipynb",
      "status": "passed",
      "execution_time": 1.5066101551055908,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/serializing_and_saving_models_for_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.394604206085205,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/examples/working_on_end_to_end_projects_integrating_multiple_ai_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.270421028137207,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "example"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/exercises/exercise_05_machine_learning_models.ipynb",
      "status": "passed",
      "execution_time": 0.6526870727539062,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "exercise"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_01_search_algorithms_solution.ipynb",
      "status": "passed",
      "execution_time": 0.8571791648864746,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_02_knowledge_representation_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7822699546813965,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_03_probability_and_uncertainty_solution.ipynb",
      "status": "passed",
      "execution_time": 0.536221981048584,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_04_optimization_techniques_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7311532497406006,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 02/unit5-ai-learning-models/solutions/exercise_05_machine_learning_models_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7326362133026123,
      "error": null,
      "error_traceback": null,
      "course": "Course 02",
      "unit": "unit5-ai-learning-models",
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/examples/01_vectors_matrices_basics.ipynb",
      "status": "passed",
      "execution_time": 0.7247200012207031,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/examples/02_matrix_operations.ipynb",
      "status": "passed",
      "execution_time": 0.9901750087738037,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/examples/03_eigenvalues_eigenvectors.ipynb",
      "status": "passed",
      "execution_time": 0.9727420806884766,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_01/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7810733318328857,
      "error": "An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 01: Vector and Matrix Operations\")\n print(\"=\" * 60)\n \n # Test 1: Create data matrix\n print(\"\\n1. Testing create_data\\n_matrix:\")\n data = create_data_matrix(5, 3)\n if data is None:\n print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.random.randn(samples, features)\")\n raise NotImplementedError(\"Please implement create_data_matrix() first!\")\n print(f\" Created matrix shape: {data.shape}\")\n print(f\" Expected: (5, 3)\")\n assert data.shape == (5, 3), \"Shape should be (5, 3)\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Dot product\n print(\"\\n2. Testing compute\\n_dot\\n_product:\")\n v1 = np.array([1, 2, 3])\n v2 = np.array([4, 5, 6])\n result = compute_dot_product(v1, v2)\n if result is None:\n print(\" \u274c ERROR: compute\\n_dot\\n_product() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(v1, v2)\")\n raise NotImplementedError(\"Please implement compute_dot_product() first!\")\n expected = 32 # 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n print(f\" Result: {result}\")\n print(f\" Expected: {expected}\")\n assert result == expected, f\"Expected {expected}, got {result}\"\n print(\" \u2705 Passed!\")\n \n # Test 3: Matrix multiplication\n print(\"\\n3. Testing matrix_multiplication:\")\n A = np.array([[1, 2], [3, 4]])\n B = np.array([[5, 6], [7, 8]])\n result = matrix_multiplication(A, B)\n if result is None:\n print(\" \u274c ERROR: matrix_multiplication() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(A, B)\")\n raise NotImplementedError(\"Please implement matrix_multiplication() first!\")\n expected = np.array([[19, 22], [43, 50]])\n print(f\" Result:\\n{result}\")\n print(f\" Expected:\\n{expected}\")\n assert np.allclose(result, expected), \"Matrix multiplication incorrect\"\n print(\" \u2705 Passed!\")\n \n # Test 4: Transpose\n print(\"\\n4. Testing compute\\n_transpose:\")\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\n result = compute_transpose(matrix)\n if result is None:\n print(\" \u274c ERROR: compute\\n_transpose() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return matrix.T\")\n raise NotImplementedError(\"Please implement compute_transpose() first!\")\n expected = np.array([[1, 4], [2, 5], [3, 6]])\n print(f\" Original shape: {matrix.shape}\")\n print(f\" Transposed shape: {result.shape}\")\n assert np.allclose(result, expected), \"Transpose incorrect\"\n print(\" \u2705 Passed!\")\n \n print(\"\\n\" + \"=\" * 60)\n print(\"\ud83c\udf89 All tests passed! Great job!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 01: Vector and Matrix Operations\")\n print(\"=\" * 60)\n \n # Test 1: Create data matrix\n print(\"\\n1. Testing create_data\\n_matrix:\")\n data = create_data_matrix(5, 3)\n if data is None:\n print(\" \u274c ERROR: create_data\\n_matrix() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.random.randn(samples, features)\")\n raise NotImplementedError(\"Please implement create_data_matrix() first!\")\n print(f\" Created matrix shape: {data.shape}\")\n print(f\" Expected: (5, 3)\")\n assert data.shape == (5, 3), \"Shape should be (5, 3)\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Dot product\n print(\"\\n2. Testing compute\\n_dot\\n_product:\")\n v1 = np.array([1, 2, 3])\n v2 = np.array([4, 5, 6])\n result = compute_dot_product(v1, v2)\n if result is None:\n print(\" \u274c ERROR: compute\\n_dot\\n_product() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(v1, v2)\")\n raise NotImplementedError(\"Please implement compute_dot_product() first!\")\n expected = 32 # 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n print(f\" Result: {result}\")\n print(f\" Expected: {expected}\")\n assert result == expected, f\"Expected {expected}, got {result}\"\n print(\" \u2705 Passed!\")\n \n # Test 3: Matrix multiplication\n print(\"\\n3. Testing matrix_multiplication:\")\n A = np.array([[1, 2], [3, 4]])\n B = np.array([[5, 6], [7, 8]])\n result = matrix_multiplication(A, B)\n if result is None:\n print(\" \u274c ERROR: matrix_multiplication() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return np.dot(A, B)\")\n raise NotImplementedError(\"Please implement matrix_multiplication() first!\")\n expected = np.array([[19, 22], [43, 50]])\n print(f\" Result:\\n{result}\")\n print(f\" Expected:\\n{expected}\")\n assert np.allclose(result, expected), \"Matrix multiplication incorrect\"\n print(\" \u2705 Passed!\")\n \n # Test 4: Transpose\n print(\"\\n4. Testing compute\\n_transpose:\")\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\n result = compute_transpose(matrix)\n if result is None:\n print(\" \u274c ERROR: compute\\n_transpose() returned None!\")\n print(\" \ud83d\udca1 SOLUTION: Replace 'pass' with: return matrix.T\")\n raise NotImplementedError(\"Please implement compute_transpose() first!\")\n expected = np.array([[1, 4], [2, 5], [3, 6]])\n print(f\" Original shape: {matrix.shape}\")\n print(f\" Transposed shape: {result.shape}\")\n assert np.allclose(result, expected), \"Transpose incorrect\"\n print(\" \u2705 Passed!\")\n \n print(\"\\n\" + \"=\" * 60)\n print(\"\ud83c\udf89 All tests passed! Great job!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_01/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.5184059143066406,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_determinant(matrix):\n \n # TODO: Compute determinant using np.linalg.de\nt()\n pass\n\n\ndef compute_matrix_inverse(matrix):\n \n # TODO: Compute inverse using np.linalg.in\nv()\n # Note: Matrix must be square and have non-zero determinan\ntpass\n\n\ndef compute_eigenvalues__eigenvectors(matrix):\n \n # TODO: Use np.linalg.eig() to compute eigenvalues and eigenvectors\n pass\n\n\ndef verify_inverse(matrix, inverse):\n \n # TODO: Multiply matrix by inverse and check if result is identity\n # Use np.allclose() for floating point comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_determinant(matrix):\n \n # TODO: Compute determinant using np.linalg.de\nt()\n pass\n\n\ndef compute_matrix_inverse(matrix):\n \n # TODO: Compute inverse using np.linalg.in\nv()\n # Note: Matrix must be square and have non-zero determinan\ntpass\n\n\ndef compute_eigenvalues__eigenvectors(matrix):\n \n # TODO: Use np.linalg.eig() to compute eigenvalues and eigenvectors\n pass\n\n\ndef verify_inverse(matrix, inverse):\n \n # TODO: Multiply matrix by inverse and check if result is identity\n # Use np.allclose() for floating point comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_01/notebook_01_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 0.841806173324585,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.6515779495239258,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7229890823364258,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef create_data_matrix(samples, features):        # # SOLUTION: Create a matrix with the specified shape    # Use np.random.randn() to generate random values    pass\ndef compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\ndef matrix_multiplication(A, B):        # # SOLUTION: Perform matrix multiplication    # Remember: A @ B or np.dot(A, B)    pass\ndef compute_transpose(matrix):        # # SOLUTION: Compute transpose using .T or np.transpose()    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef create_data_matrix(samples, features):        # # SOLUTION: Create a matrix with the specified shape    # Use np.random.randn() to generate random values    pass\ndef compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\ndef matrix_multiplication(A, B):        # # SOLUTION: Perform matrix multiplication    # Remember: A @ B or np.dot(A, B)    pass\ndef compute_transpose(matrix):        # # SOLUTION: Compute transpose using .T or np.transpose()    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_dot_product(v1, v2):        # # SOLUTION: Compute dot product using np.dot() or v1 @ v2    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_01/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.6107308864593506,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_determinant(matrix):        # # SOLUTION: Compute determinant using np.linalg.det()    pass\ndef compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\ndef compute_eigenvalues_eigenvectors(matrix):        # # SOLUTION: Use np.linalg.eig() to compute eigenvalues and eigenvectors    pass\ndef verify_inverse(matrix, inverse):        # # SOLUTION: Multiply matrix by inverse and check if result is identity    # Use np.allclose() for floating point comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_determinant(matrix):        # # SOLUTION: Compute determinant using np.linalg.det()    pass\ndef compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\ndef compute_eigenvalues_eigenvectors(matrix):        # # SOLUTION: Use np.linalg.eig() to compute eigenvalues and eigenvectors    pass\ndef verify_inverse(matrix, inverse):        # # SOLUTION: Multiply matrix by inverse and check if result is identity    # Use np.allclose() for floating point comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_matrix_inverse(matrix):        # # SOLUTION: Compute inverse using np.linalg.inv()    # Note: Matrix must be square and have non-zero determinant    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/examples/01_derivatives_basics.ipynb",
      "status": "passed",
      "execution_time": 0.965947151184082,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/examples/02_gradients_multivariable.ipynb",
      "status": "passed",
      "execution_time": 0.8614482879638672,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/examples/03_gradient_descent.ipynb",
      "status": "passed",
      "execution_time": 0.7379348278045654,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_02/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5102758407592773,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead def compute_derivative(func, x, h=1e-6):\n \n # TODO: Implement numerical derivative\n # Formula: (f(x+h) - f(x))  h pass\n\n\ndef compute_gradient(func, point):\n \n # TODO: Compute partial derivatives\n # Use compute_derivative for each variable h = 1e-6\n pass\n\n\ndef gradient_descent_step(func, x, learning_rate=0.1):\n \n # TODO: \n # 1. Compute gradient at current point\n # 2. Move in opposite direction: x_new = x - lr * gradient pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Test your solution\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead def compute_derivative(func, x, h=1e-6):\n \n # TODO: Implement numerical derivative\n # Formula: (f(x+h) - f(x))  h pass\n\n\ndef compute_gradient(func, point):\n \n # TODO: Compute partial derivatives\n # Use compute_derivative for each variable h = 1e-6\n pass\n\n\ndef gradient_descent_step(func, x, learning_rate=0.1):\n \n # TODO: \n # 1. Compute gradient at current point\n # 2. Move in opposite direction: x_new = x - lr * gradient pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    # Test your solution\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_02/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.5980160236358643,
      "error": "An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 02: Gradient Descent\")\nprint(\"=\" * 60)\n \n # Test 1: Gradient descent print(\"\\n1. Testing gradient_descent:\")\ndef f(x):\n return (x - 3)**2 # Minimum at x = 3 def grad_f(x):\n return 2 * (x - 3) # Gradient of (x-3)\u00b2\n \n initial_x = 5.0\n final_x, history = gradient_descent(f, grad_f, initial_x, learning_rate=0.1, iterations=20)\nprint(f\" Function: f(x) = (x - 3)\u00b2 (minimum at x = 3)\")\n print(f\" Starting at: {initial_x}\")\nprint(f\" Final value: {final_x:.4f}\")\nprint(f\" Expected: close to 3.0\")\nprint(f\" Converged: {abs(final_x - 3) < 0.1}\")\n assert abs(final_x - 3) < 0.5, \"Should converge close to minimum\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Learning rate analysis print(\"\\n2. Testing analyze\\n_learning_rate:\")\nlearning_rates = [0.01, 0.1, 0.5, 1.0]\n results = analyze_learning_rate(f, grad_f, initial_x, learning_rates, iterations=30)\nprint(f\" Learning Rate Analysis:\")\nfor lr, final_val in results.items():\n converged = abs(final_val - 3) < 0.5\n status = \"\u2705 Converged\" if converged else \"\u274c Diverged\"\n print(f\" LR = {lr:.2\nf}: Final x = {final_val:.4f} {status}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83c\udf89 All tests passed!\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\":\n print(\"Testing Exercise 02: Gradient Descent\")\nprint(\"=\" * 60)\n \n # Test 1: Gradient descent print(\"\\n1. Testing gradient_descent:\")\ndef f(x):\n return (x - 3)**2 # Minimum at x = 3 def grad_f(x):\n return 2 * (x - 3) # Gradient of (x-3)\u00b2\n \n initial_x = 5.0\n final_x, history = gradient_descent(f, grad_f, initial_x, learning_rate=0.1, iterations=20)\nprint(f\" Function: f(x) = (x - 3)\u00b2 (minimum at x = 3)\")\n print(f\" Starting at: {initial_x}\")\nprint(f\" Final value: {final_x:.4f}\")\nprint(f\" Expected: close to 3.0\")\nprint(f\" Converged: {abs(final_x - 3) < 0.1}\")\n assert abs(final_x - 3) < 0.5, \"Should converge close to minimum\"\n print(\" \u2705 Passed!\")\n \n # Test 2: Learning rate analysis print(\"\\n2. Testing analyze\\n_learning_rate:\")\nlearning_rates = [0.01, 0.1, 0.5, 1.0]\n results = analyze_learning_rate(f, grad_f, initial_x, learning_rates, iterations=30)\nprint(f\" Learning Rate Analysis:\")\nfor lr, final_val in results.items():\n converged = abs(final_val - 3) < 0.5\n status = \"\u2705 Converged\" if converged else \"\u274c Diverged\"\n print(f\" LR = {lr:.2\nf}: Final x = {final_val:.4f} {status}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83c\udf89 All tests passed!\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\":\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_02/notebook_02_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 0.516953706741333,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Why Calculus matters in ML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example: Understanding loss functions and optimization\n# In ML, we want to minimize a loss function\ndef simple_loss_function(x):\n \n    \n    \"\"\"A simple quadratic loss function\"\"\"\n return (x - 3)**2 + 2\n\n# The derivative tells us the direction to minimize\ndef loss_derivative(x):\n \n    \n    \"\"\"Derivative of the loss function\"\"\"\n return 2 * (x - 3)\n\n# Example: Finding the minimum\nx_values = np.linspace(0, 6, 100)\nloss_values = [simple_loss_function(x) for x in x_values]\n\nprint(\"Loss function example:\")\nprint(f\"At x=2, loss = {simple_loss_function(2):.2f}, derivative = {loss_derivative(2):.2f}\")\nprint(f\"At x=4, loss = {simple_loss_function(4):.2f}, derivative = {loss_derivative(4):.2f}\")\nprint(\"\\nThe derivative tells us which direction to move to minimize loss!\")\nprint(\"This is exactly how gradient descent works in ML!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (x - 3)**2 + 2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Why Calculus matters in ML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example: Understanding loss functions and optimization\n# In ML, we want to minimize a loss function\ndef simple_loss_function(x):\n \n    \n    \"\"\"A simple quadratic loss function\"\"\"\n return (x - 3)**2 + 2\n\n# The derivative tells us the direction to minimize\ndef loss_derivative(x):\n \n    \n    \"\"\"Derivative of the loss function\"\"\"\n return 2 * (x - 3)\n\n# Example: Finding the minimum\nx_values = np.linspace(0, 6, 100)\nloss_values = [simple_loss_function(x) for x in x_values]\n\nprint(\"Loss function example:\")\nprint(f\"At x=2, loss = {simple_loss_function(2):.2f}, derivative = {loss_derivative(2):.2f}\")\nprint(f\"At x=4, loss = {simple_loss_function(4):.2f}, derivative = {loss_derivative(4):.2f}\")\nprint(\"\\nThe derivative tells us which direction to move to minimize loss!\")\nprint(\"This is exactly how gradient descent works in ML!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (x - 3)**2 + 2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.5206129550933838,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.652944803237915,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy.misc import derivative\ndef compute_derivative(func, x, h=1e-6):        # # SOLUTION: Implement numerical derivative    # Formula: (f(x+h) - f(x))\nh    pass\ndef compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\ndef gradient_descent_step(func, x, learning_rate=0.1):        # # SOLUTION:     # 1. Compute gradient at current point    # 2. Move in opposite direction: x_new = x - lr * gradient    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    h    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy.misc import derivative\ndef compute_derivative(func, x, h=1e-6):        # # SOLUTION: Implement numerical derivative    # Formula: (f(x+h) - f(x))\nh    pass\ndef compute_gradient(func, point):        # # SOLUTION: Compute partial derivatives    # Use compute_derivative for each variable    h = 1e-6    pass\ndef gradient_descent_step(func, x, learning_rate=0.1):        # # SOLUTION:     # 1. Compute gradient at current point    # 2. Move in opposite direction: x_new = x - lr * gradient    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    h    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_02/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5445811748504639,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50):        results = {}        # # SOLUTION: For each learning rate, run gradient descent    # Store the final value in results dictionary       return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\u001b[0m\n\u001b[0m                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50):        results = {}        # # SOLUTION: For each learning rate, run gradient descent    # Store the final value in results dictionary       return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate=0.1, iterations=100):        x = initial_x    history = [x]        # # SOLUTION: Implement gradient descent loop    # For each iteration:    #   1. Compute gradient at current point    #   2. Update: x = x - learning_rate * gradient    #   3. Store x in history       return x, history\u001b[0m\n\u001b[0m                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/examples/01_optimizers_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.8913319110870361,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/examples/02_loss_functions.ipynb",
      "status": "passed",
      "execution_time": 0.8277649879455566,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/examples/03_statistical_measures.ipynb",
      "status": "passed",
      "execution_time": 0.7232122421264648,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_03/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6662189960479736,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\nclass SimpleGDOptimizer:\n \n \ndef__init__(self, lr=0.01):\n self.lr = lr\n \n def update(self, params, grads):\n \n # TODO: Implement simple gradient descent update\n pass\n\n\nclass MomentumOptimizer:\n \n \ndef__init__(self, lr=0.01, momentum=0.9):\n self.lr = lr\n self.momentum = momentum\n self.velocity = None\n \n def update(self, params, grads):\n \n # TODO: Initialize velocity if first call\n # TODO: Update velocity: v = momentum * v + lr * grad\ns\n # TODO: Update params: params = params - velocity\n pass\n\n\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):\n \n results = {}\n \n # TODO: For each optimize\nr:\n # 1. Start with initial_params\n # 2. Run for 'iterations' step\ns\n # 3. Store final parameters\n \n return results\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\nclass SimpleGDOptimizer:\n \n \ndef__init__(self, lr=0.01):\n self.lr = lr\n \n def update(self, params, grads):\n \n # TODO: Implement simple gradient descent update\n pass\n\n\nclass MomentumOptimizer:\n \n \ndef__init__(self, lr=0.01, momentum=0.9):\n self.lr = lr\n self.momentum = momentum\n self.velocity = None\n \n def update(self, params, grads):\n \n # TODO: Initialize velocity if first call\n # TODO: Update velocity: v = momentum * v + lr * grad\ns\n # TODO: Update params: params = params - velocity\n pass\n\n\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):\n \n results = {}\n \n # TODO: For each optimize\nr:\n # 1. Start with initial_params\n # 2. Run for 'iterations' step\ns\n # 3. Store final parameters\n \n return results\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_03/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.7264881134033203,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef calculate_mse(predictions, targets):\n \n # TODO: Calculate MS\nE\n # Formula: mean((predictions - targets)^2)\n pass\n\n\ndef calculate_rmse(predictions, targets):\n \n # TODO: Calculate RMSE\n # Formula: sqrt(MS\nE)\npass\n\n\ndef calculate_r2__score(predictions, targets):\n \n # TODO: Calculate R\u00b2\n # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(target\ns))^2)\n pass\n\n\ndef evaluate_model(predictions, targets):\n \n # TODO: Calculate all metrics and return as dictionary pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    E)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef calculate_mse(predictions, targets):\n \n # TODO: Calculate MS\nE\n # Formula: mean((predictions - targets)^2)\n pass\n\n\ndef calculate_rmse(predictions, targets):\n \n # TODO: Calculate RMSE\n # Formula: sqrt(MS\nE)\npass\n\n\ndef calculate_r2__score(predictions, targets):\n \n # TODO: Calculate R\u00b2\n # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(target\ns))^2)\n pass\n\n\ndef evaluate_model(predictions, targets):\n \n # TODO: Calculate all metrics and return as dictionary pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    E)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_03/notebook_03_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 1.2961061000823975,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.7168169021606445,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.8011188507080078,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nclass SimpleGDOptimizer:        \n\ndef__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\nclass MomentumOptimizer:        \n\ndef__init__(self, lr=0.01, momentum=0.9):        self.lr = lr        self.momentum = momentum        self.velocity = None        def update(self, params, grads):                # # SOLUTION: Initialize velocity if first call        # # SOLUTION: Update velocity: v = momentum * v + lr * grads        # # SOLUTION: Update params: params = params - velocity        pass\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):        results = {}        # # SOLUTION: For each optimizer:    #   1. Start with initial_params    #   2. Run for 'iterations' steps    #   3. Store final parameters        return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nclass SimpleGDOptimizer:        \n\ndef__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\nclass MomentumOptimizer:        \n\ndef__init__(self, lr=0.01, momentum=0.9):        self.lr = lr        self.momentum = momentum        self.velocity = None        def update(self, params, grads):                # # SOLUTION: Initialize velocity if first call        # # SOLUTION: Update velocity: v = momentum * v + lr * grads        # # SOLUTION: Update params: params = params - velocity        pass\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100):        results = {}        # # SOLUTION: For each optimizer:    #   1. Start with initial_params    #   2. Run for 'iterations' steps    #   3. Store final parameters        return results# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01):        self.lr = lr        def update(self, params, grads):                # # SOLUTION: Implement simple gradient descent update        pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_03/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5205070972442627,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef calculate_mse(predictions, targets):        # # SOLUTION: Calculate MSE    # Formula: mean((predictions - targets)^2)    pass\ndef calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\ndef calculate_r2_score(predictions, targets):        # # SOLUTION: Calculate R\u00b2    # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(targets))^2)    pass\ndef evaluate_model(predictions, targets):        # # SOLUTION: Calculate all metrics and return as dictionary    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef calculate_mse(predictions, targets):        # # SOLUTION: Calculate MSE    # Formula: mean((predictions - targets)^2)    pass\ndef calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\ndef calculate_r2_score(predictions, targets):        # # SOLUTION: Calculate R\u00b2    # Formula: 1 - sum((targets - predictions)^2)\nsum((targets - mean(targets))^2)    pass\ndef evaluate_model(predictions, targets):        # # SOLUTION: Calculate all metrics and return as dictionary    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calculate_rmse(predictions, targets):        # # SOLUTION: Calculate RMSE    # Formula: sqrt(MSE)    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/examples/01_pca_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.7052538394927979,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/examples/02_curse_dimensionality.ipynb",
      "status": "passed",
      "execution_time": 0.772996187210083,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/examples/03_feature_selection.ipynb",
      "status": "passed",
      "execution_time": 0.9311740398406982,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_04/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.55265212059021,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_covariance_matrix(data):\n \n # TODO: Compute covariance matrix\n # Hint: Center data first (subtract mean), then compute covariance\n pass\n\n\ndef pca_from_scratch(data, n_components=2):\n \n # TODO: Implement PC\nA\n # Step\ns:\n # 1. Center the data (subtract mean)\n # 2. Compute covariance matrix\n # 3. Find eigenvalues and eigenvectors\n # 4. Sort by eigenvalues (descending)\n # 5. Select top n_components\n # 6. Project data: reduced = data @ eigenvectors\n # 7. Calculate explained variance rati\no\n pass\n\n\ndef calculate_variance_explained(eigenvalues, n_components):\n \n # TODO: Calculate variance explaine\nd\n # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    A\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 11\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\n\ndef compute_covariance_matrix(data):\n \n # TODO: Compute covariance matrix\n # Hint: Center data first (subtract mean), then compute covariance\n pass\n\n\ndef pca_from_scratch(data, n_components=2):\n \n # TODO: Implement PC\nA\n # Step\ns:\n # 1. Center the data (subtract mean)\n # 2. Compute covariance matrix\n # 3. Find eigenvalues and eigenvectors\n # 4. Sort by eigenvalues (descending)\n # 5. Select top n_components\n # 6. Project data: reduced = data @ eigenvectors\n # 7. Calculate explained variance rati\no\n pass\n\n\ndef calculate_variance_explained(eigenvalues, n_components):\n \n # TODO: Calculate variance explaine\nd\n # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    A\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 11\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_04/notebook_04_why_how_after.ipynb",
      "status": "passed",
      "execution_time": 1.7133910655975342,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.5138068199157715,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_04/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5896627902984619,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_covariance_matrix(data):        # # SOLUTION: Compute covariance matrix    # Hint: Center data first (subtract mean), then compute covariance    pass\ndef pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\ndef calculate_variance_explained(eigenvalues, n_components):        # # SOLUTION: Calculate variance explained    # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\ndef compute_covariance_matrix(data):        # # SOLUTION: Compute covariance matrix    # Hint: Center data first (subtract mean), then compute covariance    pass\ndef pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\ndef calculate_variance_explained(eigenvalues, n_components):        # # SOLUTION: Calculate variance explained    # Formula: sum(top_n_eigenvalues)\nsum(all_eigenvalues)    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pca_from_scratch(data, n_components=2):        # # SOLUTION: Implement PCA    # Steps:    # 1. Center the data (subtract mean)    # 2. Compute covariance matrix    # 3. Find eigenvalues and eigenvectors    # 4. Sort by eigenvalues (descending)    # 5. Select top n_components    # 6. Project data: reduced = data @ eigenvectors    # 7. Calculate explained variance ratio    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 3\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/examples/01_probability_distributions.ipynb",
      "status": "passed",
      "execution_time": 1.0405240058898926,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/examples/02_statistical_inference.ipynb",
      "status": "passed",
      "execution_time": 0.7536590099334717,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/examples/03_bayesian_inference.ipynb",
      "status": "passed",
      "execution_time": 1.1515209674835205,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 03/modules/module_05/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5839500427246094,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\n\n\ndef compute_confidence_interval(data, confidence=0.95):\n \n # TODO: Compute confidence interval\n # Step\ns:\n # 1. Calculate sample mean and standard erro\nr\n # 2. Get t-critical value for confidence leve\nl\n # 3. CI = mean \u00b1 t_critical * standard_error\n pass\n\n\ndef t_test_two_samples(sample1, sample2):\n \n # TODO: Perform two-sample t-test\n # Use scipy.stats.ttest_in\nd()\n pass\n\n\ndef interpret_p__value(p_value, alpha=0.05):\n \n # TODO: Interpret p-valu\ne\n # If p < alpha: significant difference\n # If p >= alpha: no significant difference\n pass\n\n\ndef compare_models(model1_scores, model2_scores, alpha=0.05):\n \n # TODO: \n # 1. Compute means and confidence interval\ns\n # 2. Perform t-test\n # 3. Interpret result\ns\n # 4. Return comprehensive comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    s:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\n\n\ndef compute_confidence_interval(data, confidence=0.95):\n \n # TODO: Compute confidence interval\n # Step\ns:\n # 1. Calculate sample mean and standard erro\nr\n # 2. Get t-critical value for confidence leve\nl\n # 3. CI = mean \u00b1 t_critical * standard_error\n pass\n\n\ndef t_test_two_samples(sample1, sample2):\n \n # TODO: Perform two-sample t-test\n # Use scipy.stats.ttest_in\nd()\n pass\n\n\ndef interpret_p__value(p_value, alpha=0.05):\n \n # TODO: Interpret p-valu\ne\n # If p < alpha: significant difference\n # If p >= alpha: no significant difference\n pass\n\n\ndef compare_models(model1_scores, model2_scores, alpha=0.05):\n \n # TODO: \n # 1. Compute means and confidence interval\ns\n # 2. Perform t-test\n # 3. Interpret result\ns\n # 4. Return comprehensive comparison\n pass\n\n\n# Test your solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    s:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 5\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 03/modules/module_05/notebook_05_why_how_after.ipynb",
      "status": "failed",
      "execution_time": 1.205578088760376,
      "error": "An error occurred while executing the following cell:\n------------------\n# Example: Basic Probability and Statistical Inference Operations in Python\n# This shows HOW each concept works and WHY it's used in ML\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"HOW Probabilities and Statistical Inference Work in ML\")\nprint(\"=\" * 60)\n\n# 1. Working with probability distributions\n# WHY: ML models need to understand data distributions\n# HOW: Use probability distributions to model uncertainty\nprint(\"\\n1. Probability Distributions (Modeling Uncertainty):\")\nprint(\" WHY: Need to understand and model data distributions\")\nprint(\" HOW: Use probability distributions to describe data patterns\")\n\n# Normal distribution example\nmu, sigma = 0, 1\nsamples = np.random.normal(mu, sigma, 1000)\nprint(f\" Normal distribution: mean={np.mean(samples):.4f}, std={np.std(samples):.4f}\")\nprint(\" HOW: This distribution models continuous data (e.g., prediction errors)\")\n\n# Binomial distribution example\nn, p = 10, 0.5\nbinomial_samples = np.random.binomial(n, p, 1000)\nprint(f\" Binomial distribution: mean={np.mean(binomial_samples):.4f}, std={np.std(binomial_samples):.4f}\")\nprint(\" HOW: This distribution models binary outcomes (e.g., classification)\")\n\n# 2. Statistical hypothesis testing\n# WHY: Determine if differences between models are statistically significant\n# HOW: Compute test statistic and p-value\nprint(\"\\n2. Statistical Hypothesis Testing (Model Comparison):\")\nprint(\" WHY: Need to know if model improvements are real or by chance\")\nprint(\" HOW: Use statistical tests to compare models\")\n\n# Example: Comparing two models\nmodel_a_scores = np.random.normal(0.85, 0.02, 100)\nmodel_b_scores = np.random.normal(0.87, 0.02, 100)\n\nt_stat, p_value = stats.ttest_ind(model_a_scores, model_b_scores)\nprint(f\" Model A mean: {np.mean(model_a_scores):.4f}\")\nprint(f\" Model B mean: {np.mean(model_b_scores):.4f}\")\nprint(f\" t-statistic: {t_stat:.4f}\")\nprint(f\" p-value: {p_value:.4f}\")\nif p_value < 0.05:\n print(\" \u2705 Significant difference! (p < 0.05)\")\n print(\" HOW: p-value < 0.05 means < 5% chance this difference is by chance\")\nelse:\n print(\" \u274c No significant difference (p >= 0.05)\")\n\n# 3. Confidence intervals\n# WHY: Point estimates don't show uncertainty\n# HOW: Compute range of likely values\nprint(\"\\n3. Confidence Intervals (Uncertainty Quantification):\")\nprint(\" WHY: Need to know the range of likely values, not just a point estimate\")\nprint(\" HOW: Compute confidence interval using standard error\")\n\n# Example: Confidence interval for mean\nmean_score = np.mean(model_a_scores)\nstd_error = stats.sem(model_a_scores)\nci_95 = stats.t.interval(0.95, len(model_a_scores)-1, loc=mean_score, scale=std_error)\nprint(f\" Mean score: {mean_score:.4f}\")\nprint(f\" 95% Confidence Interval: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\nprint(\" HOW: 95% CI means we're 95% confident the true mean is in this range\")\n\n# 4. Sampling methods\n# WHY: Need representative samples for training/testing\n# HOW: Use proper sampling techniques\nprint(\"\\n4. Sampling Methods (Data Splitting):\")\nprint(\" WHY: Can't use all data - need representative train/test splits\")\nprint(\" HOW: Use random sampling to ensure representativeness\")\n\n# Example: Train/test split\ndata = np.random.normal(0, 1, 1000)\ntrain_size = int(0.8 * len(data))\ntrain_data = data[:train_size]\ntest_data = data[train_size:]\nprint(f\" Total data: {len(data)} samples\")\nprint(f\" Training set: {len(train_data)} samples ({len(train_data)/len(data)*100:.1f}%)\")\nprint(f\" Test set: {len(test_data)} samples ({len(test_data)/len(data)*100:.1f}%)\")\nprint(\" HOW: Random split ensures both sets are representative\")\n\n# 5. Bayesian inference basics\n# WHY: Incorporate prior knowledge into models\n# HOW: Update prior beliefs with observed data\nprint(\"\\n5. Bayesian Inference (Prior Knowledge Integration):\")\nprint(\" WHY: Want to incorporate what we know before seeing data\")\nprint(\" HOW: Start with prior, update with data to get posterior\")\n\n# Simple Bayesian example\nprior_belief = 0.5 # 50% chance before seeing data\nlikelihood = 0.8 # Data suggests 80% chance\n# Simplified: posterior = (prior * likelihood)\nnormalization\n# In practice, use Bayes' theorem properly\nprint(f\" Prior belief: {prior_belief:.1%}\")\nprint(f\" Likelihood from data: {likelihood:.1%}\")\nprint(\" HOW: Bayes' theorem combines prior knowledge with observed data\")\nprint(\" Result: Updated belief (posterior) that balances both\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Key Takeaway:\")\nprint(\" Probabilities quantify uncertainty\")\nprint(\" Statistical inference helps make data-driven decisions\")\nprint(\" Both are essential for evaluating and improving ML models!\")\nprint(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nHOW Probabilities and Statistical Inference Work in ML\n============================================================\n\n1. Probability Distributions (Modeling Uncertainty):\n WHY: Need to understand and model data distributions\n HOW: Use probability distributions to describe data patterns\n Normal distribution: mean=0.0045, std=0.9640\n HOW: This distribution models continuous data (e.g., prediction errors)\n Binomial distribution: mean=4.9780, std=1.5484\n HOW: This distribution models binary outcomes (e.g., classification)\n\n2. Statistical Hypothesis Testing (Model Comparison):\n WHY: Need to know if model improvements are real or by chance\n HOW: Use statistical tests to compare models\n Model A mean: 0.8511\n Model B mean: 0.8660\n t-statistic: -5.4530\n p-value: 0.0000\n \u2705 Significant difference! (p < 0.05)\n HOW: p-value < 0.05 means < 5% chance this difference is by chance\n\n3. Confidence Intervals (Uncertainty Quantification):\n WHY: Need to know the range of likely values, not just a point estimate\n HOW: Compute confidence interval using standard error\n Mean score: 0.8511\n 95% Confidence Interval: [0.8476, 0.8547]\n HOW: 95% CI means we're 95% confident the true mean is in this range\n\n4. Sampling Methods (Data Splitting):\n WHY: Can't use all data - need representative train/test splits\n HOW: Use random sampling to ensure representativeness\n Total data: 1000 samples\n Training set: 800 samples (80.0%)\n Test set: 200 samples (20.0%)\n HOW: Random split ensures both sets are representative\n\n5. Bayesian Inference (Prior Knowledge Integration):\n WHY: Want to incorporate what we know before seeing data\n HOW: Start with prior, update with data to get posterior\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;66;03m# Data suggests 80% chance\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Simplified: posterior = (prior * likelihood)\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m normalization\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# In practice, use Bayes' theorem properly\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Prior belief: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprior_belief\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'normalization' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Example: Basic Probability and Statistical Inference Operations in Python\n# This shows HOW each concept works and WHY it's used in ML\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nprint(\"=\" * 60)\nprint(\"HOW Probabilities and Statistical Inference Work in ML\")\nprint(\"=\" * 60)\n\n# 1. Working with probability distributions\n# WHY: ML models need to understand data distributions\n# HOW: Use probability distributions to model uncertainty\nprint(\"\\n1. Probability Distributions (Modeling Uncertainty):\")\nprint(\" WHY: Need to understand and model data distributions\")\nprint(\" HOW: Use probability distributions to describe data patterns\")\n\n# Normal distribution example\nmu, sigma = 0, 1\nsamples = np.random.normal(mu, sigma, 1000)\nprint(f\" Normal distribution: mean={np.mean(samples):.4f}, std={np.std(samples):.4f}\")\nprint(\" HOW: This distribution models continuous data (e.g., prediction errors)\")\n\n# Binomial distribution example\nn, p = 10, 0.5\nbinomial_samples = np.random.binomial(n, p, 1000)\nprint(f\" Binomial distribution: mean={np.mean(binomial_samples):.4f}, std={np.std(binomial_samples):.4f}\")\nprint(\" HOW: This distribution models binary outcomes (e.g., classification)\")\n\n# 2. Statistical hypothesis testing\n# WHY: Determine if differences between models are statistically significant\n# HOW: Compute test statistic and p-value\nprint(\"\\n2. Statistical Hypothesis Testing (Model Comparison):\")\nprint(\" WHY: Need to know if model improvements are real or by chance\")\nprint(\" HOW: Use statistical tests to compare models\")\n\n# Example: Comparing two models\nmodel_a_scores = np.random.normal(0.85, 0.02, 100)\nmodel_b_scores = np.random.normal(0.87, 0.02, 100)\n\nt_stat, p_value = stats.ttest_ind(model_a_scores, model_b_scores)\nprint(f\" Model A mean: {np.mean(model_a_scores):.4f}\")\nprint(f\" Model B mean: {np.mean(model_b_scores):.4f}\")\nprint(f\" t-statistic: {t_stat:.4f}\")\nprint(f\" p-value: {p_value:.4f}\")\nif p_value < 0.05:\n print(\" \u2705 Significant difference! (p < 0.05)\")\n print(\" HOW: p-value < 0.05 means < 5% chance this difference is by chance\")\nelse:\n print(\" \u274c No significant difference (p >= 0.05)\")\n\n# 3. Confidence intervals\n# WHY: Point estimates don't show uncertainty\n# HOW: Compute range of likely values\nprint(\"\\n3. Confidence Intervals (Uncertainty Quantification):\")\nprint(\" WHY: Need to know the range of likely values, not just a point estimate\")\nprint(\" HOW: Compute confidence interval using standard error\")\n\n# Example: Confidence interval for mean\nmean_score = np.mean(model_a_scores)\nstd_error = stats.sem(model_a_scores)\nci_95 = stats.t.interval(0.95, len(model_a_scores)-1, loc=mean_score, scale=std_error)\nprint(f\" Mean score: {mean_score:.4f}\")\nprint(f\" 95% Confidence Interval: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\nprint(\" HOW: 95% CI means we're 95% confident the true mean is in this range\")\n\n# 4. Sampling methods\n# WHY: Need representative samples for training/testing\n# HOW: Use proper sampling techniques\nprint(\"\\n4. Sampling Methods (Data Splitting):\")\nprint(\" WHY: Can't use all data - need representative train/test splits\")\nprint(\" HOW: Use random sampling to ensure representativeness\")\n\n# Example: Train/test split\ndata = np.random.normal(0, 1, 1000)\ntrain_size = int(0.8 * len(data))\ntrain_data = data[:train_size]\ntest_data = data[train_size:]\nprint(f\" Total data: {len(data)} samples\")\nprint(f\" Training set: {len(train_data)} samples ({len(train_data)/len(data)*100:.1f}%)\")\nprint(f\" Test set: {len(test_data)} samples ({len(test_data)/len(data)*100:.1f}%)\")\nprint(\" HOW: Random split ensures both sets are representative\")\n\n# 5. Bayesian inference basics\n# WHY: Incorporate prior knowledge into models\n# HOW: Update prior beliefs with observed data\nprint(\"\\n5. Bayesian Inference (Prior Knowledge Integration):\")\nprint(\" WHY: Want to incorporate what we know before seeing data\")\nprint(\" HOW: Start with prior, update with data to get posterior\")\n\n# Simple Bayesian example\nprior_belief = 0.5 # 50% chance before seeing data\nlikelihood = 0.8 # Data suggests 80% chance\n# Simplified: posterior = (prior * likelihood)\nnormalization\n# In practice, use Bayes' theorem properly\nprint(f\" Prior belief: {prior_belief:.1%}\")\nprint(f\" Likelihood from data: {likelihood:.1%}\")\nprint(\" HOW: Bayes' theorem combines prior knowledge with observed data\")\nprint(\" Result: Updated belief (posterior) that balances both\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\ud83d\udca1 Key Takeaway:\")\nprint(\" Probabilities quantify uncertainty\")\nprint(\" Statistical inference helps make data-driven decisions\")\nprint(\" Both are essential for evaluating and improving ML models!\")\nprint(\"=\" * 60)\n------------------\n\n----- stdout -----\n============================================================\nHOW Probabilities and Statistical Inference Work in ML\n============================================================\n\n1. Probability Distributions (Modeling Uncertainty):\n WHY: Need to understand and model data distributions\n HOW: Use probability distributions to describe data patterns\n Normal distribution: mean=0.0045, std=0.9640\n HOW: This distribution models continuous data (e.g., prediction errors)\n Binomial distribution: mean=4.9780, std=1.5484\n HOW: This distribution models binary outcomes (e.g., classification)\n\n2. Statistical Hypothesis Testing (Model Comparison):\n WHY: Need to know if model improvements are real or by chance\n HOW: Use statistical tests to compare models\n Model A mean: 0.8511\n Model B mean: 0.8660\n t-statistic: -5.4530\n p-value: 0.0000\n \u2705 Significant difference! (p < 0.05)\n HOW: p-value < 0.05 means < 5% chance this difference is by chance\n\n3. Confidence Intervals (Uncertainty Quantification):\n WHY: Need to know the range of likely values, not just a point estimate\n HOW: Compute confidence interval using standard error\n Mean score: 0.8511\n 95% Confidence Interval: [0.8476, 0.8547]\n HOW: 95% CI means we're 95% confident the true mean is in this range\n\n4. Sampling Methods (Data Splitting):\n WHY: Can't use all data - need representative train/test splits\n HOW: Use random sampling to ensure representativeness\n Total data: 1000 samples\n Training set: 800 samples (80.0%)\n Test set: 200 samples (20.0%)\n HOW: Random split ensures both sets are representative\n\n5. Bayesian Inference (Prior Knowledge Integration):\n WHY: Want to incorporate what we know before seeing data\n HOW: Start with prior, update with data to get posterior\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;66;03m# Data suggests 80% chance\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Simplified: posterior = (prior * likelihood)\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m normalization\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# In practice, use Bayes' theorem properly\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Prior belief: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprior_belief\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'normalization' is not defined\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/scripts/utils.ipynb",
      "status": "passed",
      "execution_time": 0.8479518890380859,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/modules/module_05/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5103449821472168,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95):        # # SOLUTION: Compute confidence interval    # Steps:    # 1. Calculate sample mean and standard error    # 2. Get t-critical value for confidence level    # 3. CI = mean \u00b1 t_critical * standard_error    pass\ndef t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\ndef interpret_p_value(p_value, alpha=0.05):        # # SOLUTION: Interpret p-value    # If p < alpha: significant difference    # If p >= alpha: no significant difference    pass\ndef compare_models(model1_scores, model2_scores, alpha=0.05):        # # SOLUTION:     # 1. Compute means and confidence intervals    # 2. Perform t-test    # 3. Interpret results    # 4. Return comprehensive comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# import numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95):        # # SOLUTION: Compute confidence interval    # Steps:    # 1. Calculate sample mean and standard error    # 2. Get t-critical value for confidence level    # 3. CI = mean \u00b1 t_critical * standard_error    pass\ndef t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\ndef interpret_p_value(p_value, alpha=0.05):        # # SOLUTION: Interpret p-value    # If p < alpha: significant difference    # If p >= alpha: no significant difference    pass\ndef compare_models(model1_scores, model2_scores, alpha=0.05):        # # SOLUTION:     # 1. Compute means and confidence intervals    # 2. Perform t-test    # 3. Interpret results    # 4. Return comprehensive comparison    pass# Test your solutions\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def t_test_two_samples(sample1, sample2):        # # SOLUTION: Perform two-sample t-test    # Use scipy.stats.ttest_ind()    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n\n\n",
      "course": "Course 03",
      "unit": null,
      "type": "other"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/01_vectors_matrices_basics.ipynb",
      "status": "passed",
      "execution_time": 0.7441549301147461,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/02_matrix_operations.ipynb",
      "status": "passed",
      "execution_time": 0.9869709014892578,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/03_eigenvalues_eigenvectors.ipynb",
      "status": "passed",
      "execution_time": 0.8627498149871826,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/04_substitution_elimination_linear_equations.ipynb",
      "status": "passed",
      "execution_time": 1.1990571022033691,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/05_determinants_inverse_matrices.ipynb",
      "status": "passed",
      "execution_time": 0.7887461185455322,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/06_transformation_matrices_orthogonal_basis.ipynb",
      "status": "failed",
      "execution_time": 0.9774022102355957,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Applying Transformation Matrices\")\nprint(\"=\" * 60)\n\n# Transformation matrices represent linear transformations\n# Examples: rotation, scaling, reflection, shearing\n\ndef apply_transformation(points, transformation_matrix):\n \n    \n    \"\"\"Apply transformation matrix to points\"\"\"\n return (transformation_matrix @ points.T).T\n\n# Example: 2D points\npoints = np.array([[1, 0],\n [0, 1],\n [1, 1],\n [2, 1]])\n\nprint(\"\\nOriginal points:\")\nprint(points)\n\n# Rotation matrix (90 degrees counterclockwise)\nrotation_90 = np.array([[0, -1],\n [1, 0]])\n\nrotated_points = apply_transformation(points, rotation_90)\nprint(\"\\nRotated 90\u00b0 counterclockwise:\")\nprint(rotated_points)\n\n# Scaling matrix\nscaling = np.array([[2, 0],\n [0, 3]])\n\nscaled_points = apply_transformation(points, scaling)\nprint(\"\\nScaled (x*2, y*3):\")\nprint(scaled_points)\n\n# Shear transformation\nshear = np.array([[1, 0.5],\n [0, 1]])\n\nsheared_points = apply_transformation(points, shear)\nprint(\"\\nSheared:\")\nprint(sheared_points)\n\n# Visualize transformations\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n# Original\naxes[0, 0].scatter(points[:, 0], points[:, 1], c='blue', s=100, alpha=0.7)\naxes[0, 0].plot([0, 0], [0, 2], 'b--', alpha=0.3)\naxes[0, 0].plot([0, 2], [0, 0], 'b--', alpha=0.3)\naxes[0, 0].set_title('Original Points')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(-2, 3)\naxes[0, 0].set_ylim(-2, 3)\naxes[0, 0].axis('equal')\n\n# Rotated\naxes[0, 1].scatter(rotated_points[:, 0], rotated_points[:, 1], c='red', s=100, alpha=0.7)\naxes[0, 1].plot([0, 0], [-2, 2], 'r--', alpha=0.3)\naxes[0, 1].plot([-2, 2], [0, 0], 'r--', alpha=0.3)\naxes[0, 1].set_title('Rotated 90\u00b0')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(-2, 3)\naxes[0, 1].set_ylim(-2, 3)\naxes[0, 1].axis('equal')\n\n# Scaled\naxes[1, 0].scatter(scaled_points[:, 0], scaled_points[:, 1], c='green', s=100, alpha=0.7)\naxes[1, 0].plot([0, 0], [0, 3], 'g--', alpha=0.3)\naxes[1, 0].plot([0, 4], [0, 0], 'g--', alpha=0.3)\naxes[1, 0].set_title('Scaled (x*2, y*3)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(-1, 5)\naxes[1, 0].set_ylim(-1, 4)\naxes[1, 0].axis('equal')\n\n# Sheared\naxes[1, 1].scatter(sheared_points[:, 0], sheared_points[:, 1], c='orange', s=100, alpha=0.7)\naxes[1, 1].plot([0, 0], [0, 2], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].plot([0, 3], [0, 0], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].set_title('Sheared')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].set_xlim(-1, 4)\naxes[1, 1].set_ylim(-1, 2)\naxes[1, 1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Transformation matrices applied and visualized!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (transformation_matrix @ points.T).T\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Applying Transformation Matrices\")\nprint(\"=\" * 60)\n\n# Transformation matrices represent linear transformations\n# Examples: rotation, scaling, reflection, shearing\n\ndef apply_transformation(points, transformation_matrix):\n \n    \n    \"\"\"Apply transformation matrix to points\"\"\"\n return (transformation_matrix @ points.T).T\n\n# Example: 2D points\npoints = np.array([[1, 0],\n [0, 1],\n [1, 1],\n [2, 1]])\n\nprint(\"\\nOriginal points:\")\nprint(points)\n\n# Rotation matrix (90 degrees counterclockwise)\nrotation_90 = np.array([[0, -1],\n [1, 0]])\n\nrotated_points = apply_transformation(points, rotation_90)\nprint(\"\\nRotated 90\u00b0 counterclockwise:\")\nprint(rotated_points)\n\n# Scaling matrix\nscaling = np.array([[2, 0],\n [0, 3]])\n\nscaled_points = apply_transformation(points, scaling)\nprint(\"\\nScaled (x*2, y*3):\")\nprint(scaled_points)\n\n# Shear transformation\nshear = np.array([[1, 0.5],\n [0, 1]])\n\nsheared_points = apply_transformation(points, shear)\nprint(\"\\nSheared:\")\nprint(sheared_points)\n\n# Visualize transformations\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n# Original\naxes[0, 0].scatter(points[:, 0], points[:, 1], c='blue', s=100, alpha=0.7)\naxes[0, 0].plot([0, 0], [0, 2], 'b--', alpha=0.3)\naxes[0, 0].plot([0, 2], [0, 0], 'b--', alpha=0.3)\naxes[0, 0].set_title('Original Points')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(-2, 3)\naxes[0, 0].set_ylim(-2, 3)\naxes[0, 0].axis('equal')\n\n# Rotated\naxes[0, 1].scatter(rotated_points[:, 0], rotated_points[:, 1], c='red', s=100, alpha=0.7)\naxes[0, 1].plot([0, 0], [-2, 2], 'r--', alpha=0.3)\naxes[0, 1].plot([-2, 2], [0, 0], 'r--', alpha=0.3)\naxes[0, 1].set_title('Rotated 90\u00b0')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(-2, 3)\naxes[0, 1].set_ylim(-2, 3)\naxes[0, 1].axis('equal')\n\n# Scaled\naxes[1, 0].scatter(scaled_points[:, 0], scaled_points[:, 1], c='green', s=100, alpha=0.7)\naxes[1, 0].plot([0, 0], [0, 3], 'g--', alpha=0.3)\naxes[1, 0].plot([0, 4], [0, 0], 'g--', alpha=0.3)\naxes[1, 0].set_title('Scaled (x*2, y*3)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(-1, 5)\naxes[1, 0].set_ylim(-1, 4)\naxes[1, 0].axis('equal')\n\n# Sheared\naxes[1, 1].scatter(sheared_points[:, 0], sheared_points[:, 1], c='orange', s=100, alpha=0.7)\naxes[1, 1].plot([0, 0], [0, 2], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].plot([0, 3], [0, 0], 'orange', linestyle='--', alpha=0.3)\naxes[1, 1].set_title('Sheared')\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].set_xlim(-1, 4)\naxes[1, 1].set_ylim(-1, 2)\naxes[1, 1].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Transformation matrices applied and visualized!\")\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return (transformation_matrix @ points.T).T\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/07_eigenvalue_analysis_large_matrices.ipynb",
      "status": "passed",
      "execution_time": 1.7968618869781494,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/08_ml_parameter_experiments.ipynb",
      "status": "passed",
      "execution_time": 1.7281758785247803,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/computing_determinants_and_inverse_matrices_computationally.ipynb",
      "status": "passed",
      "execution_time": 1.250795841217041,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/experimenting_with_changes_in_ml_model_parameters_and_observing_changes_in_model.ipynb",
      "status": "passed",
      "execution_time": 1.4739208221435547,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/implementing_substitutionelimination_techniques_for_solving_linear_equations.ipynb",
      "status": "passed",
      "execution_time": 1.5167617797851562,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/performing_vector_and_matrix_operations_using_pythonnumpy.ipynb",
      "status": "passed",
      "execution_time": 1.4907021522521973,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/solving_eigenvalue_problems_programmatically_and_applying_eigenvalue_analysis_on.ipynb",
      "status": "passed",
      "execution_time": 1.2384860515594482,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit1-linear-algebra/examples/writing_code_to_apply_transformation_matrices_and_compute_orthogonal_basis_sets.ipynb",
      "status": "passed",
      "execution_time": 1.3105578422546387,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit1-linear-algebra",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/01_derivatives_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8471601009368896,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/02_gradients_multivariable.ipynb",
      "status": "passed",
      "execution_time": 0.8642148971557617,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/03_gradient_descent.ipynb",
      "status": "passed",
      "execution_time": 0.8715941905975342,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/04_backpropagation_neural_networks.ipynb",
      "status": "passed",
      "execution_time": 1.0943410396575928,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/05_function_approximation_ml.ipynb",
      "status": "failed",
      "execution_time": 1.5325798988342285,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Taylor Series Approximation\")\nprint(\"=\" * 60)\n\n# Taylor series: f(x) \u2248 f(a) + f'(a)(x-a) + f''(a)(x-a)\u00b2/2! + ...\n\ndef exp_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of exp(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # f^(n)(a) = exp(a) for all n\n result += (np.exp(a) * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\ndef sin_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of sin(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # Derivatives of sin cycle: sin, cos, -sin, -cos\n derivatives = [np.sin(a), np.cos(a), -np.sin(a), -np.cos(a)]\n result += (derivatives[n % 4] * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\n# Visualize approximations\nx = np.linspace(-2, 2, 100)\n\nplt.figure(figsize=(14, 5))\n# Exponential approximation\nplt.subplot(1, 2, 1)\nplt.plot(x, np.exp(x), 'b-', label='exp(x)', linewidth=2)\nfor n in [1, 2, 3, 5, 10]:\n y_approx = [exp_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of exp(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1, 8)\n\n# Sine approximation\nplt.subplot(1, 2, 2)\nplt.plot(x, np.sin(x), 'r-', label='sin(x)', linewidth=2)\nfor n in [1, 3, 5, 7, 9]:\n y_approx = [sin_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of sin(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1.5, 1.5)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Taylor series approximations visualized!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Taylor Series Approximation\")\nprint(\"=\" * 60)\n\n# Taylor series: f(x) \u2248 f(a) + f'(a)(x-a) + f''(a)(x-a)\u00b2/2! + ...\n\ndef exp_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of exp(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # f^(n)(a) = exp(a) for all n\n result += (np.exp(a) * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\ndef sin_taylor(x, a=0, n_terms=5):\n \n    \n    \n    \"\"\"Taylor series approximation of sin(x) around point a\"\"\"\n result = 0\n x_minus_a = x - afor n in range(n_terms):\n # Derivatives of sin cycle: sin, cos, -sin, -cos\n derivatives = [np.sin(a), np.cos(a), -np.sin(a), -np.cos(a)]\n result += (derivatives[n % 4] * (x_minus_a)**n)\nnp.math.factorial(n)\n return result\n\n# Visualize approximations\nx = np.linspace(-2, 2, 100)\n\nplt.figure(figsize=(14, 5))\n# Exponential approximation\nplt.subplot(1, 2, 1)\nplt.plot(x, np.exp(x), 'b-', label='exp(x)', linewidth=2)\nfor n in [1, 2, 3, 5, 10]:\n y_approx = [exp_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of exp(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1, 8)\n\n# Sine approximation\nplt.subplot(1, 2, 2)\nplt.plot(x, np.sin(x), 'r-', label='sin(x)', linewidth=2)\nfor n in [1, 3, 5, 7, 9]:\n y_approx = [sin_taylor(xi, a=0, n_terms=n) for xi in x]\n plt.plot(x, y_approx, '--', label=f'Taylor (n={n})', alpha=0.7)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Taylor Series Approximation of sin(x)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(-1.5, 1.5)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 Taylor series approximations visualized!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/applying_function_approximation_on_real_world_ml_models.ipynb",
      "status": "passed",
      "execution_time": 1.2835781574249268,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/implementing_gradient_computations_for_multivariate_functions.ipynb",
      "status": "passed",
      "execution_time": 1.5445868968963623,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/programming_backpropagation_in_neural_networks_using_differentiation_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.416778802871704,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit2-calculus/examples/solving_differentiation_problems_using_symbolic_computation_tools.ipynb",
      "status": "passed",
      "execution_time": 1.36745285987854,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit2-calculus",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/01_optimizers_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.9864747524261475,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/02_loss_functions.ipynb",
      "status": "passed",
      "execution_time": 0.9621648788452148,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/03_statistical_measures.ipynb",
      "status": "passed",
      "execution_time": 1.0292720794677734,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/04_regression_real_datasets.ipynb",
      "status": "failed",
      "execution_time": 0.6318609714508057,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing \nimport StandardScaler, PolynomialFeatures\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.datasets \nimport load_boston, fetch_california_housing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Regression Techniques to Real Datasets\")\nprint(\"=\" * 60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing \nimport StandardScaler, PolynomialFeatures\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.datasets \nimport load_boston, fetch_california_housing\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nApplying Regression Techniques to Real Datasets\")\nprint(\"=\" * 60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/05_image_similarity_measures.ipynb",
      "status": "passed",
      "execution_time": 1.790747880935669,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/applying_regression_techniques_to_fit_models_on_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.5114970207214355,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/implementing_gradient_descent_for_optimization_problems.ipynb",
      "status": "passed",
      "execution_time": 1.4861769676208496,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/implementing_projection_and_dimensionality_reduction_techniques_in_ml.ipynb",
      "status": "passed",
      "execution_time": 1.7737457752227783,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/representing_images_as_vectors_and_computing_angles_and_distances_between_them.ipynb",
      "status": "passed",
      "execution_time": 1.4990129470825195,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit3-optimization/examples/writing_code_to_compute_basic_statistical_properties_of_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.3054206371307373,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit3-optimization",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/01_pca_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.7256441116333008,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/02_curse_dimensionality.ipynb",
      "status": "passed",
      "execution_time": 0.7425868511199951,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/03_feature_selection.ipynb",
      "status": "passed",
      "execution_time": 0.8878881931304932,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/04_svd_implementation.ipynb",
      "status": "passed",
      "execution_time": 1.4080438613891602,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/05_tsne_visualization.ipynb",
      "status": "passed",
      "execution_time": 2.3900318145751953,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/06_dimensionality_reduction_real_world_datasets.ipynb",
      "status": "passed",
      "execution_time": 3.0229580402374268,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/implementing_pca_using_python_for_dimensionality_reduction_of_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.5868279933929443,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit4-dimensionality-reduction/examples/writing_code_to_apply_these_dimensionality_reduction_techniques_on_real_world_da.ipynb",
      "status": "passed",
      "execution_time": 1.5947589874267578,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit4-dimensionality-reduction",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/01_probability_distributions.ipynb",
      "status": "passed",
      "execution_time": 0.8831238746643066,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/02_statistical_inference.ipynb",
      "status": "passed",
      "execution_time": 0.6946289539337158,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/03_bayesian_inference.ipynb",
      "status": "passed",
      "execution_time": 1.0359790325164795,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/04_central_limit_theorem_simulations.ipynb",
      "status": "passed",
      "execution_time": 2.107287883758545,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/05_sampling_point_estimation.ipynb",
      "status": "passed",
      "execution_time": 1.7705559730529785,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/06_maximum_likelihood_estimation.ipynb",
      "status": "failed",
      "execution_time": 1.206578016281128,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: MLE for Gaussian Distribution\")\nprint(\"=\" * 60)\n\n# Generate data from Gaussian distribution\nnp.random.seed(42)\ntrue_mu = 5.0\ntrue_sigma = 2.0\ndata = np.random.normal(true_mu, true_sigma, 100)\n\nprint(f\"\\nTrue parameters:\")\nprint(f\" \u03bc (mean): {true_mu}\")\nprint(f\" \u03c3 (std): {true_sigma}\")\nprint(f\" Sample size: {len(data)}\")\n\n# MLE for Gaussian: sample mean and sample std\nmle_mu = np.mean(data)\nmle_sigma = np.std(data, ddof=0) # MLE uses N, not N-1\n\nprint(f\"\\nMLE estimates:\")\nprint(f\" \u03bc_MLE (sample mean): {mle_mu:.4f}\")\nprint(f\" \u03c3_MLE (sample std): {mle_sigma:.4f}\")\n\n# Negative log-likelihood function (we minimize this)\ndef neg_log_likelihood_gaussian(params, data):\n \n    \n    \n    \"\"\"Negative log-likelihood for Gaussian distribution\"\"\"\n mu, sigma = paramsif sigma <= 0:\n return np.inf\n n = len(data)\n log_likelihood = -n * np.log(sigma * np.sqrt(2 * np.pi)) - np.sum((data - mu)**2)\n(2 * sigma**2)\n return -log_likelihood # Return negative for minimization\n\n# Optimize using scipy\nresult = minimize(lambda p: neg_log_likelihood_gaussian(p, data), \n x0=[mle_mu, mle_sigma], \n method='BFGS')\nmle_mu_opt = result.x[0]\nmle_sigma_opt = result.x[1]\n\nprint(f\"\\nMLE from optimization:\")\nprint(f\" \u03bc_MLE: {mle_mu_opt:.4f}\")\nprint(f\" \u03c3_MLE: {mle_sigma_opt:.4f}\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(data, bins=20, density=True, alpha=0.7, color='blue', label='Data')\nx = np.linspace(data.min(), data.max(), 100)\nplt.plot(x, stats.norm.pdf(x, true_mu, true_sigma), 'r-', linewidth=2, label=f'True (\u03bc={true_mu}, \u03c3={true_sigma})')\nplt.plot(x, stats.norm.pdf(x, mle_mu, mle_sigma), 'g--', linewidth=2, label=f'MLE (\u03bc={mle_mu:.2f}, \u03c3={mle_sigma:.2f})')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Gaussian Distribution MLE')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nmu_range = np.linspace(3, 7, 100)\nlog_likelihoods = [-neg_log_likelihood_gaussian([mu, mle_sigma], data) for mu in mu_range]\nplt.plot(mu_range, log_likelihoods, 'b-', linewidth=2)\nplt.axvline(true_mu, color='r', linestyle='--', label=f'True \u03bc={true_mu}')\nplt.axvline(mle_mu, color='g', linestyle='--', label=f'MLE \u03bc={mle_mu:.2f}')\nplt.xlabel('\u03bc (mean)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 MLE for Gaussian distribution implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:30\u001b[0;36m\u001b[0m\n\u001b[0;31m    mu, sigma = paramsif sigma <= 0:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: MLE for Gaussian Distribution\")\nprint(\"=\" * 60)\n\n# Generate data from Gaussian distribution\nnp.random.seed(42)\ntrue_mu = 5.0\ntrue_sigma = 2.0\ndata = np.random.normal(true_mu, true_sigma, 100)\n\nprint(f\"\\nTrue parameters:\")\nprint(f\" \u03bc (mean): {true_mu}\")\nprint(f\" \u03c3 (std): {true_sigma}\")\nprint(f\" Sample size: {len(data)}\")\n\n# MLE for Gaussian: sample mean and sample std\nmle_mu = np.mean(data)\nmle_sigma = np.std(data, ddof=0) # MLE uses N, not N-1\n\nprint(f\"\\nMLE estimates:\")\nprint(f\" \u03bc_MLE (sample mean): {mle_mu:.4f}\")\nprint(f\" \u03c3_MLE (sample std): {mle_sigma:.4f}\")\n\n# Negative log-likelihood function (we minimize this)\ndef neg_log_likelihood_gaussian(params, data):\n \n    \n    \n    \"\"\"Negative log-likelihood for Gaussian distribution\"\"\"\n mu, sigma = paramsif sigma <= 0:\n return np.inf\n n = len(data)\n log_likelihood = -n * np.log(sigma * np.sqrt(2 * np.pi)) - np.sum((data - mu)**2)\n(2 * sigma**2)\n return -log_likelihood # Return negative for minimization\n\n# Optimize using scipy\nresult = minimize(lambda p: neg_log_likelihood_gaussian(p, data), \n x0=[mle_mu, mle_sigma], \n method='BFGS')\nmle_mu_opt = result.x[0]\nmle_sigma_opt = result.x[1]\n\nprint(f\"\\nMLE from optimization:\")\nprint(f\" \u03bc_MLE: {mle_mu_opt:.4f}\")\nprint(f\" \u03c3_MLE: {mle_sigma_opt:.4f}\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(data, bins=20, density=True, alpha=0.7, color='blue', label='Data')\nx = np.linspace(data.min(), data.max(), 100)\nplt.plot(x, stats.norm.pdf(x, true_mu, true_sigma), 'r-', linewidth=2, label=f'True (\u03bc={true_mu}, \u03c3={true_sigma})')\nplt.plot(x, stats.norm.pdf(x, mle_mu, mle_sigma), 'g--', linewidth=2, label=f'MLE (\u03bc={mle_mu:.2f}, \u03c3={mle_sigma:.2f})')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title('Gaussian Distribution MLE')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nmu_range = np.linspace(3, 7, 100)\nlog_likelihoods = [-neg_log_likelihood_gaussian([mu, mle_sigma], data) for mu in mu_range]\nplt.plot(mu_range, log_likelihoods, 'b-', linewidth=2)\nplt.axvline(true_mu, color='r', linestyle='--', label=f'True \u03bc={true_mu}')\nplt.axvline(mle_mu, color='g', linestyle='--', label=f'MLE \u03bc={mle_mu:.2f}')\nplt.xlabel('\u03bc (mean)')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2705 MLE for Gaussian distribution implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:30\u001b[0;36m\u001b[0m\n\u001b[0;31m    mu, sigma = paramsif sigma <= 0:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/07_hypothesis_testing_procedures.ipynb",
      "status": "passed",
      "execution_time": 1.3086647987365723,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/08_pvalues_confidence_intervals.ipynb",
      "status": "passed",
      "execution_time": 1.359598159790039,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/09_probability_ml_connections.ipynb",
      "status": "passed",
      "execution_time": 1.9571549892425537,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/applying_central_limit_theorem_with_simulations.ipynb",
      "status": "passed",
      "execution_time": 1.366508960723877,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/computing_p_values_and_confidence_intervals.ipynb",
      "status": "passed",
      "execution_time": 1.4963469505310059,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/connecting_probability_theory_to_ml_model_implementations.ipynb",
      "status": "passed",
      "execution_time": 1.3643841743469238,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/implementing_hypothesis_testing_procedures.ipynb",
      "status": "passed",
      "execution_time": 1.562114953994751,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/implementing_maximum_likelihood_estimation_mle_for_different_distributions.ipynb",
      "status": "passed",
      "execution_time": 1.4942419528961182,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 03/unit5-probability/examples/performing_sampling_and_point_estimation.ipynb",
      "status": "passed",
      "execution_time": 1.2648651599884033,
      "error": null,
      "error_traceback": null,
      "course": "Course 03",
      "unit": "unit5-probability",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/01_data_loading_exploration.ipynb",
      "status": "failed",
      "execution_time": 1.304584264755249,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world US Crime Statistics dataset (GDI-themed)\n# This is REAL government data about crime statistics by US state - relevant to security/intelligence analysis\n# Source: Public dataset (USArrests - well-known dataset for ML education)\n# Theme: Security/Crime Statistics - Intelligence Analysis (GDI context)\nprint(\"\ud83d\udce5 Loading real-world US Crime Statistics dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062c\u0631\u064a\u0645\u0629 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629...\")\n\n# Load from local file - US Crime Statistics by State\n# pd.read_csv(): Reads CSV file from local path\n# Returns DataFrame with real-world crime statistics data\n# This dataset contains crime statistics for US states\n\n# Load the dataset from the datasets folder\n# '../../datasets/raw/crime_statistics.csv' - relative path from notebook location\ndf = # File not found: ../../datasets/raw/crime_statistics.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n\n# Actual columns in this dataset (USArrests):\n# - State: US state name (categorical)\n# - Murder: Murder arrests per 100,000 (numerical)\n# - Assault: Assault arrests per 100,000 (numerical)\n# - UrbanPop: Urban population percentage (numerical)\n# - Rape: Rape arrests per 100,000 (numerical)\nprint(\"\\n\u2705 Real-world US Crime Statistics dataset loaded!\")\nprint(\" \ud83d\udcca This is REAL government data about crime statistics by US state\")\nprint(f\" \ud83d\udcc8 Contains {len(df)} US states with {len(df.columns)} features\")\nprint(f\" \ud83d\udd0d Columns: {', '.join(df.columns)}\")\nprint(\" \ud83c\udfaf Domain: Security/Crime Statistics - Relevant to GDI Intelligence Analysis\")\nprint(\" \u2705 Real-world data: Crime arrest rates per 100,000 by US state\")\nprint(\"\\n\ud83d\udca1 Why this dataset for GDI work?\")\nprint(\" - Crime statistics are directly relevant to security/intelligence analysis\")\nprint(\" - Understanding crime patterns by state helps with threat assessment\")\nprint(\" - Real government data structure (similar to intelligence reports)\")\nprint(\" - Perfect for learning data exploration with security context\")\nprint(\" - State-level analysis supports regional security planning\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = # File not found: ../../datasets/raw/crime_statistics.csv\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world US Crime Statistics dataset (GDI-themed)\n# This is REAL government data about crime statistics by US state - relevant to security/intelligence analysis\n# Source: Public dataset (USArrests - well-known dataset for ML education)\n# Theme: Security/Crime Statistics - Intelligence Analysis (GDI context)\nprint(\"\ud83d\udce5 Loading real-world US Crime Statistics dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062c\u0631\u064a\u0645\u0629 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629...\")\n\n# Load from local file - US Crime Statistics by State\n# pd.read_csv(): Reads CSV file from local path\n# Returns DataFrame with real-world crime statistics data\n# This dataset contains crime statistics for US states\n\n# Load the dataset from the datasets folder\n# '../../datasets/raw/crime_statistics.csv' - relative path from notebook location\ndf = # File not found: ../../datasets/raw/crime_statistics.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n\n# Actual columns in this dataset (USArrests):\n# - State: US state name (categorical)\n# - Murder: Murder arrests per 100,000 (numerical)\n# - Assault: Assault arrests per 100,000 (numerical)\n# - UrbanPop: Urban population percentage (numerical)\n# - Rape: Rape arrests per 100,000 (numerical)\nprint(\"\\n\u2705 Real-world US Crime Statistics dataset loaded!\")\nprint(\" \ud83d\udcca This is REAL government data about crime statistics by US state\")\nprint(f\" \ud83d\udcc8 Contains {len(df)} US states with {len(df.columns)} features\")\nprint(f\" \ud83d\udd0d Columns: {', '.join(df.columns)}\")\nprint(\" \ud83c\udfaf Domain: Security/Crime Statistics - Relevant to GDI Intelligence Analysis\")\nprint(\" \u2705 Real-world data: Crime arrest rates per 100,000 by US state\")\nprint(\"\\n\ud83d\udca1 Why this dataset for GDI work?\")\nprint(\" - Crime statistics are directly relevant to security/intelligence analysis\")\nprint(\" - Understanding crime patterns by state helps with threat assessment\")\nprint(\" - Real government data structure (similar to intelligence reports)\")\nprint(\" - Perfect for learning data exploration with security context\")\nprint(\" - State-level analysis supports regional security planning\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = # File not found: ../../datasets/raw/crime_statistics.csv\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/02_data_cleaning.ipynb",
      "status": "passed",
      "execution_time": 2.2168900966644287,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/03_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 0.5300443172454834,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us preprocess data for machine learning import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nfrom sklearn.preprocessing import (, LabelEncoder\n StandardScaler, # For standardization (mean=0, std=1) MinMaxScaler, # For normalization (range 0-1) LabelEncoder, # For ordinal encoding OneHotEncoder # For nominal encoding)\nfrom sklearn.model_selection import train_test_split # For splitting data print(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda What each preprocessing tool does:\")\nprint(\" - StandardScaler: Scale features to mean=0, std=1 (z-score)\")\nprint(\" - MinMaxScaler: Scale features to range [0, 1]\")\nprint(\" - LabelEncoder: Convert categories to numbers (ordinal)\")\nprint(\" - OneHotEncoder: Convert categories to binary columns (nominal)\")\nprint(\" - train_test_split: Split data into train/test sets\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing import (, LabelEncoder\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us preprocess data for machine learning import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nfrom sklearn.preprocessing import (, LabelEncoder\n StandardScaler, # For standardization (mean=0, std=1) MinMaxScaler, # For normalization (range 0-1) LabelEncoder, # For ordinal encoding OneHotEncoder # For nominal encoding)\nfrom sklearn.model_selection import train_test_split # For splitting data print(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda What each preprocessing tool does:\")\nprint(\" - StandardScaler: Scale features to mean=0, std=1 (z-score)\")\nprint(\" - MinMaxScaler: Scale features to range [0, 1]\")\nprint(\" - LabelEncoder: Convert categories to numbers (ordinal)\")\nprint(\" - OneHotEncoder: Convert categories to binary columns (nominal)\")\nprint(\" - train_test_split: Split data into train/test sets\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing import (, LabelEncoder\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/04_linear_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6661677360534668,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world financial transaction dataset (GDI-themed)\n# Using publicly available dataset - relevant to GDI financial investigations\n# Source: Online dataset (GitHub or Kaggle)\n# Theme: Financial Investigation - Transaction Pattern Analysis\n\nprint(\"\\n\ud83d\udce5 Loading real-world financial transaction dataset from online source...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0627\u0644\u0645\u0627\u0644\u064a\u0629 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629 \u0645\u0646 \u0645\u0635\u062f\u0631 \u0639\u0628\u0631 \u0627\u0644\u0625\u0646\u062a\u0631\u0646\u062a...\")\n\n# Load Credit Card Fraud dataset from local file\n# This demonstrates predicting transaction amounts based on time patterns\n\ntry:\n # Option 1: Try loading from a public financial dataset URL\n # Note: Credit Card Fraud dataset requires Kaggle account, so we'll use alternative\n \n # Option 2: Use a well-known public dataset that can be loaded directly\n # Using a dataset that simulates financial transactions\n # For educational purposes, we'll use a dataset that can be loaded from URL\n \n # Try loading from GitHub (if available)\nor use sklearn with clear GDI context\n # Since Credit Card Fraud requires Kaggle API, we'll use sklearn dataset\n # but with CLEAR financial investigation context\n \n # Load real Credit Card Fraud dataset (GDI Theme: Financial Investigations)\ndf_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n print(f\"\\n\u2705 Real-world Credit Card Fraud data loaded from local file!\")\nprint(f\" \ud83d\udcca Full dataset: {len(df_full):,} transactions\")\n \n # For learning linear regression, use a sample for faster execution\n sample_size = 5000 # Use 5k samples for faster executiondf = df_full.sample(n=min(sample_size, len(df_full)), random_state=73, replace=False).reset_index(drop=True)\nprint(f\" \ud83d\udcca Using sample: {len(df):,} transactions (for faster learning)\")\n print(f\" \ud83d\udca1 Note: Using a sample for learning convenience. In real projects, use full dataset.\")\n \n # For linear regression, we'll predict Amount (continuous target)\nfrom Time (continuous feature)\ndf_simple = df[['Time', 'Amount']].copy()\n \n print(f\"\\n\u2705 Dataset prepared for linear regression!\")\nprint(f\" \ud83d\udcca Dataset contains {len(df_simple)} transaction records\")\n print(f\" \ud83d\udcc8 Feature: Time (seconds elapsed) - predictor variable\")\n print(f\" \ud83d\udcb0 Target: Amount (transaction amount in dollars) - what we predict\")\n print(f\"\\n\ud83d\udcca Sample Data:\")\nprint(df_simple.head().round(2))\n print(f\"\\n\ud83d\udcd0 Data Shape: {df_simple.shape}\")\nprint(\"\\n\ud83d\udcca Dataset Statistics:\")\nprint(df_simple.describe().round(2))\n print(\"\\n\ud83d\udd0d Notice:\")\nprint(\" - REAL anonymized credit card transaction data\")\nprint(\" - Linear regression: Predict transaction Amount based on Time\")\nprint(\" - Perfect for learning linear regression!\")\nprint(\" \ud83c\udfaf Domain: GDI Financial Investigations - Transaction Pattern Analysis\")\nprint(\" \ud83d\udccb Note: V1-V28 are PCA-transformed features (already scaled)\")\n print(\" We'll use Time for simple regression, then add V features for multiple regression\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Local file not found. Please ensure creditcard_fraud.csv is in datasets/raw/\")\nprint(\" \ud83d\udca1 Download from: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\")\nprint(\"\\n For demonstration, creating minimal structure...\")\n # Minimal fallback (students should use real dataset)\nnp.random.seed(73)\ndf_simple = pd.DataFrame({\n 'Time': np.random.uniform(0, 172792, 200),\n 'Amount': np.random.uniform(0, 5000, 200)\n })\n print(\" \u26a0\ufe0f Using fallback data - please download real dataset from datasets/raw/!\")\nexcept Exception as e:\n print(f\"\\n\u26a0\ufe0f Error loading dataset: {e}\")\nprint(\" \ud83d\udca1 Please ensure creditcard_fraud.csv is in datasets/raw/\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    or use sklearn with clear GDI context\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 12\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world financial transaction dataset (GDI-themed)\n# Using publicly available dataset - relevant to GDI financial investigations\n# Source: Online dataset (GitHub or Kaggle)\n# Theme: Financial Investigation - Transaction Pattern Analysis\n\nprint(\"\\n\ud83d\udce5 Loading real-world financial transaction dataset from online source...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0627\u0644\u0645\u0627\u0644\u064a\u0629 \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629 \u0645\u0646 \u0645\u0635\u062f\u0631 \u0639\u0628\u0631 \u0627\u0644\u0625\u0646\u062a\u0631\u0646\u062a...\")\n\n# Load Credit Card Fraud dataset from local file\n# This demonstrates predicting transaction amounts based on time patterns\n\ntry:\n # Option 1: Try loading from a public financial dataset URL\n # Note: Credit Card Fraud dataset requires Kaggle account, so we'll use alternative\n \n # Option 2: Use a well-known public dataset that can be loaded directly\n # Using a dataset that simulates financial transactions\n # For educational purposes, we'll use a dataset that can be loaded from URL\n \n # Try loading from GitHub (if available)\nor use sklearn with clear GDI context\n # Since Credit Card Fraud requires Kaggle API, we'll use sklearn dataset\n # but with CLEAR financial investigation context\n \n # Load real Credit Card Fraud dataset (GDI Theme: Financial Investigations)\ndf_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n print(f\"\\n\u2705 Real-world Credit Card Fraud data loaded from local file!\")\nprint(f\" \ud83d\udcca Full dataset: {len(df_full):,} transactions\")\n \n # For learning linear regression, use a sample for faster execution\n sample_size = 5000 # Use 5k samples for faster executiondf = df_full.sample(n=min(sample_size, len(df_full)), random_state=73, replace=False).reset_index(drop=True)\nprint(f\" \ud83d\udcca Using sample: {len(df):,} transactions (for faster learning)\")\n print(f\" \ud83d\udca1 Note: Using a sample for learning convenience. In real projects, use full dataset.\")\n \n # For linear regression, we'll predict Amount (continuous target)\nfrom Time (continuous feature)\ndf_simple = df[['Time', 'Amount']].copy()\n \n print(f\"\\n\u2705 Dataset prepared for linear regression!\")\nprint(f\" \ud83d\udcca Dataset contains {len(df_simple)} transaction records\")\n print(f\" \ud83d\udcc8 Feature: Time (seconds elapsed) - predictor variable\")\n print(f\" \ud83d\udcb0 Target: Amount (transaction amount in dollars) - what we predict\")\n print(f\"\\n\ud83d\udcca Sample Data:\")\nprint(df_simple.head().round(2))\n print(f\"\\n\ud83d\udcd0 Data Shape: {df_simple.shape}\")\nprint(\"\\n\ud83d\udcca Dataset Statistics:\")\nprint(df_simple.describe().round(2))\n print(\"\\n\ud83d\udd0d Notice:\")\nprint(\" - REAL anonymized credit card transaction data\")\nprint(\" - Linear regression: Predict transaction Amount based on Time\")\nprint(\" - Perfect for learning linear regression!\")\nprint(\" \ud83c\udfaf Domain: GDI Financial Investigations - Transaction Pattern Analysis\")\nprint(\" \ud83d\udccb Note: V1-V28 are PCA-transformed features (already scaled)\")\n print(\" We'll use Time for simple regression, then add V features for multiple regression\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Local file not found. Please ensure creditcard_fraud.csv is in datasets/raw/\")\nprint(\" \ud83d\udca1 Download from: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\")\nprint(\"\\n For demonstration, creating minimal structure...\")\n # Minimal fallback (students should use real dataset)\nnp.random.seed(73)\ndf_simple = pd.DataFrame({\n 'Time': np.random.uniform(0, 172792, 200),\n 'Amount': np.random.uniform(0, 5000, 200)\n })\n print(\" \u26a0\ufe0f Using fallback data - please download real dataset from datasets/raw/!\")\nexcept Exception as e:\n print(f\"\\n\u26a0\ufe0f Error loading dataset: {e}\")\nprint(\" \ud83d\udca1 Please ensure creditcard_fraud.csv is in datasets/raw/\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    or use sklearn with clear GDI context\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 12\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/05_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6338119506835938,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world US Accidents dataset for Traffic Management\n# GDI Theme: Traffic Management - Understanding how visibility affects accident impact distance\n\nprint(\"\\n\ud83d\udce5 Loading US Accidents dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u062d\u0648\u0627\u062f\u062b \u0627\u0644\u0645\u0631\u0648\u0631 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\nprint(\" GDI Theme: Traffic Management - Visibility vs Accident Impact Distance\")\nprint(\" \u0627\u0644\u0645\u0648\u0636\u0648\u0639: \u0625\u062f\u0627\u0631\u0629 \u0627\u0644\u0645\u0631\u0648\u0631 - \u0627\u0644\u0631\u0624\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0645\u0633\u0627\u0641\u0629 \u062a\u0623\u062b\u064a\u0631 \u0627\u0644\u062d\u0648\u0627\u062f\u062b\")\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/us_accidents.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\ud83d\udcca Full dataset loaded: {len(df_full):,} records\")\n \n # Select relevant columns for polynomial regression\n # Feature: Visibility(mi) - visibility conditions during accident\n # Target: Distance(mi) - how far the accident impacts traffic\n cols_needed = ['Visibility(mi)', 'Distance(mi)']\n \n # Clean data: remove nulls and filter for meaningful data\n df_clean = df_full[cols_needed].dropna()\n \n # Filter for accidents with non-zero distance (more meaningful for analysis)\ndf_clean = df_clean[df_clean['Distance(mi)'] > 0].copy()\n \n # Sample for faster computation and clearer visualization\n # Using 2000 samples - good balance between data size and demonstration clarity\n sample_size = min(2000, len(df_clean))\n df = df_clean.sample(n=sample_size, random_state=73).copy().reset_index(drop=True)\n \n # Prepare features and target\n X = df[['Visibility(mi)']].values # Feature: Visibility (2D array for sklearn)\ny = df['Distance(mi)'].values # Target: Accident impact distance\n \n print(f\"\u2705 Clean data prepared: {len(df)} records\")\n print(f\" Feature: Visibility(mi) - visibility conditions (miles)\")\n print(f\" Target: Distance(mi) - accident impact distance (miles)\")\n \n print(f\"\\n\ud83d\udcca Dataset statistics:\")\nprint(df.describe())\n print(\"\\n\ud83d\udd0d Notice:\")\nprint(\" - This is REAL-WORLD traffic accident data!\")\nprint(\" - Relationship: Visibility vs Accident Impact Distance\")\nprint(\" - Hypothesis: Lower visibility \u2192 Longer impact distances (curved relationship)\")\n print(\" - This relationship is CURVED (non-linear), not a straight line!\")\n print(\" - At high visibility: Impact distances are small and stable\")\nprint(\" - At low visibility: Impact distances increase exponentially\")\nprint(\" - Linear regression will struggle with this CURVED pattern\")\nprint(\" - Polynomial regression will fit much better because it can model curves!\")\nprint(\"\\n\ud83d\udca1 GDI Traffic Management Context:\")\nprint(\" - Understanding this relationship helps in:\")\nprint(\" \u2022 Traffic flow prediction during poor visibility\")\nprint(\" \u2022 Emergency response planning\")\nprint(\" \u2022 Resource allocation for accident management\")\nprint(\" \u2022 Traffic safety assessment\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected location: ../../datasets/raw/us_accidents.csv\")\nprint(\" \ud83d\udca1 Please ensure the dataset is downloaded (see DOWNLOAD_INSTRUCTIONS.md)\")\n print(\"\\n Creating minimal synthetic data for demonstration...\")\n \n # Fallback: Create synthetic data with similar characteristics\n np.random.seed(73)\nn_samples = 200\n visibility = np.random.uniform(0.2, 10.0, n_samples)\n # Curved relationship: distance = a/visibility + noise\n distance = 0.1\n(visibility + 0.5) + np.random.normal(0, 0.02, n_samples)\ndistance = np.maximum(distance, 0.001) # Ensure positive\n \n X = visibility.reshape(-1, 1)\ny = distance\n \n df = pd.DataFrame({\n 'Visibility(mi)': visibility, 'Distance(mi)': distance\n })\n \n print(f\" \u26a0\ufe0f Using synthetic data ({n_samples} samples) - please use real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/us_accidents.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world US Accidents dataset for Traffic Management\n# GDI Theme: Traffic Management - Understanding how visibility affects accident impact distance\n\nprint(\"\\n\ud83d\udce5 Loading US Accidents dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u062d\u0648\u0627\u062f\u062b \u0627\u0644\u0645\u0631\u0648\u0631 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\nprint(\" GDI Theme: Traffic Management - Visibility vs Accident Impact Distance\")\nprint(\" \u0627\u0644\u0645\u0648\u0636\u0648\u0639: \u0625\u062f\u0627\u0631\u0629 \u0627\u0644\u0645\u0631\u0648\u0631 - \u0627\u0644\u0631\u0624\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0645\u0633\u0627\u0641\u0629 \u062a\u0623\u062b\u064a\u0631 \u0627\u0644\u062d\u0648\u0627\u062f\u062b\")\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/us_accidents.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\ud83d\udcca Full dataset loaded: {len(df_full):,} records\")\n \n # Select relevant columns for polynomial regression\n # Feature: Visibility(mi) - visibility conditions during accident\n # Target: Distance(mi) - how far the accident impacts traffic\n cols_needed = ['Visibility(mi)', 'Distance(mi)']\n \n # Clean data: remove nulls and filter for meaningful data\n df_clean = df_full[cols_needed].dropna()\n \n # Filter for accidents with non-zero distance (more meaningful for analysis)\ndf_clean = df_clean[df_clean['Distance(mi)'] > 0].copy()\n \n # Sample for faster computation and clearer visualization\n # Using 2000 samples - good balance between data size and demonstration clarity\n sample_size = min(2000, len(df_clean))\n df = df_clean.sample(n=sample_size, random_state=73).copy().reset_index(drop=True)\n \n # Prepare features and target\n X = df[['Visibility(mi)']].values # Feature: Visibility (2D array for sklearn)\ny = df['Distance(mi)'].values # Target: Accident impact distance\n \n print(f\"\u2705 Clean data prepared: {len(df)} records\")\n print(f\" Feature: Visibility(mi) - visibility conditions (miles)\")\n print(f\" Target: Distance(mi) - accident impact distance (miles)\")\n \n print(f\"\\n\ud83d\udcca Dataset statistics:\")\nprint(df.describe())\n print(\"\\n\ud83d\udd0d Notice:\")\nprint(\" - This is REAL-WORLD traffic accident data!\")\nprint(\" - Relationship: Visibility vs Accident Impact Distance\")\nprint(\" - Hypothesis: Lower visibility \u2192 Longer impact distances (curved relationship)\")\n print(\" - This relationship is CURVED (non-linear), not a straight line!\")\n print(\" - At high visibility: Impact distances are small and stable\")\nprint(\" - At low visibility: Impact distances increase exponentially\")\nprint(\" - Linear regression will struggle with this CURVED pattern\")\nprint(\" - Polynomial regression will fit much better because it can model curves!\")\nprint(\"\\n\ud83d\udca1 GDI Traffic Management Context:\")\nprint(\" - Understanding this relationship helps in:\")\nprint(\" \u2022 Traffic flow prediction during poor visibility\")\nprint(\" \u2022 Emergency response planning\")\nprint(\" \u2022 Resource allocation for accident management\")\nprint(\" \u2022 Traffic safety assessment\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected location: ../../datasets/raw/us_accidents.csv\")\nprint(\" \ud83d\udca1 Please ensure the dataset is downloaded (see DOWNLOAD_INSTRUCTIONS.md)\")\n print(\"\\n Creating minimal synthetic data for demonstration...\")\n \n # Fallback: Create synthetic data with similar characteristics\n np.random.seed(73)\nn_samples = 200\n visibility = np.random.uniform(0.2, 10.0, n_samples)\n # Curved relationship: distance = a/visibility + noise\n distance = 0.1\n(visibility + 0.5) + np.random.normal(0, 0.02, n_samples)\ndistance = np.maximum(distance, 0.001) # Ensure positive\n \n X = visibility.reshape(-1, 1)\ny = distance\n \n df = pd.DataFrame({\n 'Visibility(mi)': visibility, 'Distance(mi)': distance\n })\n \n print(f\" \u26a0\ufe0f Using synthetic data ({n_samples} samples) - please use real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/us_accidents.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/06_ridge_lasso_regression.ipynb",
      "status": "failed",
      "execution_time": 1.6150448322296143,
      "error": "An error occurred while executing the following cell:\n------------------\n# Generate sample data with multiple features_np.random.seed(42)\nn_samples = 100\n\n# Create features with some correlation_X = np.random.randn(n_samples, 5)\n# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for regularization)\nscaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\nX_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\nX_test_scaled = scaler.transform(X_test)\nprint(f\"Training set: {X_train_scaled.shape}\")\nprint(f\"Test set: {X_test_scaled.shape}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Generate sample data with multiple features_np.random.seed(42)\nn_samples = 100\n\n# Create features with some correlation_X = np.random.randn(n_samples, 5)\n# Target: linear combination with noise_y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 0.5 * np.random.randn(n_samples)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for regularization)\nscaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\nX_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\nX_test_scaled = scaler.transform(X_test)\nprint(f\"Training set: {X_train_scaled.shape}\")\nprint(f\"Test set: {X_test_scaled.shape}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/07_svr_decision_tree_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5888099670410156,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.svm \nimport SVR\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.metrics \nimport mean_squared_error, r2_score\nfrom sklearn.preprocessing \nimport StandardScaler_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.svm \nimport SVR\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.metrics \nimport mean_squared_error, r2_score\nfrom sklearn.preprocessing \nimport StandardScaler_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/comparing_regression_algorithms_on_real_datasets.ipynb",
      "status": "failed",
      "execution_time": 0.6300621032714844,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/implementing_decision_tree_and_random_forest_regression.ipynb",
      "status": "failed",
      "execution_time": 0.7773158550262451,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/examples/visualizing_regression_results_and_residuals.ipynb",
      "status": "failed",
      "execution_time": 0.7272250652313232,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "example"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5202820301055908,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plti_mport seaborn as sn\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plti_mport seaborn as sn\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plti_mport seaborn as sn\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plti_mport seaborn as sn\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.597524881362915,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_03_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 1.727060317993164,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 3: Polynomial Regression Practice\n\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\n\nInstructions:\n1. Load the provided dataset_2. Create polynomial regression models with different degrees_3. Detect overfitting by comparing train vs test performance_4. Find the optimal polynomial degree_5. Visualize the results_6. Understand the bias-variance tradeoff\n\nUse the provided dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample non-linear data_np.random.seed(123)\nX = np.linspace(0, 10, 200).reshape(-1, 1)\n# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\n\ndf = pd.DataFrame({'x': X.flatten(), 'y': y})\n\nprint(\"Dataset Info:\")\nprint(f\"Shape: {df.shape}\")\nprint(df.head())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train polynomial regression with degree 1 (linear)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Polynomial Regression (degree=1)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=1\n# Train LinearRegression\n# Evaluate on both train and test\n# Your code here...\n\n# Task 3: Train polynomial regression with degree 2_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Polynomial Regression (degree=2)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=2\n# Train and evaluate\n# Your code here...\n\n# Task 4: Train polynomial regression with degree 5_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Polynomial Regression (degree=5)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=5\n# Train and evaluate\n# Notice overfitting (high train accuracy, lower test accuracy)\n# Your code here...\n\n# Task 5: Find optimal degree using validation_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Find optimal polynomial degree\")\nprint(\"=\"*60)\n# Test degrees from 1 to 10\n# Plot degree vs MSE (both train and test)\n# Find degree with best test performance\n# Your code here...\n\n# Task 6: Visualize results_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize polynomial fits\")\nprint(\"=\"*60)\n# Plot original data\n# Plot polynomial fits for different degrees\n# Show how higher degrees can overfit\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Info:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1 - Exercise 3: Polynomial Regression Practice\n\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\n\nInstructions:\n1. Load the provided dataset_2. Create polynomial regression models with different degrees_3. Detect overfitting by comparing train vs test performance_4. Find the optimal polynomial degree_5. Visualize the results_6. Understand the bias-variance tradeoff\n\nUse the provided dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample non-linear data_np.random.seed(123)\nX = np.linspace(0, 10, 200).reshape(-1, 1)\n# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\n\ndf = pd.DataFrame({'x': X.flatten(), 'y': y})\n\nprint(\"Dataset Info:\")\nprint(f\"Shape: {df.shape}\")\nprint(df.head())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train polynomial regression with degree 1 (linear)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Polynomial Regression (degree=1)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=1\n# Train LinearRegression\n# Evaluate on both train and test\n# Your code here...\n\n# Task 3: Train polynomial regression with degree 2_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Polynomial Regression (degree=2)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=2\n# Train and evaluate\n# Your code here...\n\n# Task 4: Train polynomial regression with degree 5_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Polynomial Regression (degree=5)\")\nprint(\"=\"*60)\n# Use PolynomialFeatures with degree=5\n# Train and evaluate\n# Notice overfitting (high train accuracy, lower test accuracy)\n# Your code here...\n\n# Task 5: Find optimal degree using validation_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Find optimal polynomial degree\")\nprint(\"=\"*60)\n# Test degrees from 1 to 10\n# Plot degree vs MSE (both train and test)\n# Find degree with best test performance\n# Your code here...\n\n# Task 6: Visualize results_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize polynomial fits\")\nprint(\"=\"*60)\n# Plot original data\n# Plot polynomial fits for different degrees\n# Show how higher degrees can overfit\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noise_y = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Info:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/exercises/exercise_04_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 1.6250009536743164,
      "error": "An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 1.5367069244384766,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 1: Data Processing Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062aInstructions:1. Load the sample dataset provided below2. Explore the data (shape, info, statistics)3. Handle missing values appropriately4. Remove any duplicates5. Create visualizations (at least 2 different plots)\nDataset: Sales data for a retail stor_e\"\"\"\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dataset: Sales data for a retail stor_e\"\"\"\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 3)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 1: Data Processing Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 1: \u0645\u0645\u0627\u0631\u0633\u0629 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062aInstructions:1. Load the sample dataset provided below2. Explore the data (shape, info, statistics)3. Handle missing values appropriately4. Remove any duplicates5. Create visualizations (at least 2 different plots)\nDataset: Sales data for a retail stor_e\"\"\"\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Dataset: Sales data for a retail stor_e\"\"\"\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 3)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.5269796848297119,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_03_polynomial_regression.ipynb",
      "status": "failed",
      "execution_time": 0.7304871082305908,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 3: Polynomial Regression Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062fInstructions:1. Load the provided dataset2. Create polynomial regression models with different degrees3. Detect overfitting by comparing train vs test performance4. Find the optimal polynomial degree5. Visualize the results6. Understand the bias-variance tradeoffUse the provided dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score# Generate sample non-linear datanp.random.seed(123)X = np.linspace(0, 10, 200).reshape(-1, 1)# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noisey = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)df = pd.DataFrame({'x': X.flatten(), 'y': y})print(\"Dataset Info:\")print(f\"Shape: {df.shape}\")print(df.head())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train polynomial regression with degree 1 (linear)print(\"\\n\" + \"=\"*60)print(\"Task 2: Polynomial Regression (degree=1)\")print(\"=\"*60)# Use PolynomialFeatures with degree=1# Train LinearRegression# Evaluate on both train and test# Your code here...\n# Task 3: Train polynomial regression with degree 2\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Polynomial Regression (degree=5)\")print(\"=\"*60)# Use PolynomialFeatures with degree=5# Train and evaluate# Notice overfitting (high train accuracy, lower test accuracy)# Your code here...# Task 5: Find optimal degree using validation\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Find optimal polynomial degree\")print(\"=\"*60)# Test degrees from 1 to 10# Plot degree vs MSE (both train and test)# Find degree with best test performance# Your code here...# Task 6: Visualize results\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize polynomial fits\")print(\"=\"*60)# Plot original data# Plot polynomial fits for different degrees# Show how higher degrees can overfit# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 1 - Exercise 3: Polynomial Regression Practice\u0623\u0633\u0627\u0644\u064a\u0628 \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062fInstructions:1. Load the provided dataset2. Create polynomial regression models with different degrees3. Detect overfitting by comparing train vs test performance4. Find the optimal polynomial degree5. Visualize the results6. Understand the bias-variance tradeoffUse the provided dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score# Generate sample non-linear datanp.random.seed(123)X = np.linspace(0, 10, 200).reshape(-1, 1)# Create non-linear relationship: y = 2*x^2 - 3*x + 1 + noisey = 2 * X.flatten()**2 - 3 * X.flatten() + 1 + np.random.normal(0, 2, 200)df = pd.DataFrame({'x': X.flatten(), 'y': y})print(\"Dataset Info:\")print(f\"Shape: {df.shape}\")print(df.head())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train polynomial regression with degree 1 (linear)print(\"\\n\" + \"=\"*60)print(\"Task 2: Polynomial Regression (degree=1)\")print(\"=\"*60)# Use PolynomialFeatures with degree=1# Train LinearRegression# Evaluate on both train and test# Your code here...\n# Task 3: Train polynomial regression with degree 2\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Polynomial Regression (degree=5)\")print(\"=\"*60)# Use PolynomialFeatures with degree=5# Train and evaluate# Notice overfitting (high train accuracy, lower test accuracy)# Your code here...# Task 5: Find optimal degree using validation\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Find optimal polynomial degree\")print(\"=\"*60)# Test degrees from 1 to 10# Plot degree vs MSE (both train and test)# Find degree with best test performance# Your code here...# Task 6: Visualize results\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize polynomial fits\")print(\"=\"*60)# Plot original data# Plot polynomial fits for different degrees# Show how higher degrees can overfit# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\n\" + \"=\"*60)print(\"Task 3: Polynomial Regression (degree=2)\")print(\"=\"*60)# Use PolynomialFeatures with degree=2# Train and evaluate# Your code here...# Task 4: Train polynomial regression with degree 5\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit1-data-processing/solutions/solution_04_data_preprocessing.ipynb",
      "status": "failed",
      "execution_time": 1.4962408542633057,
      "error": "An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Set random seed for reproducibility_np.random.seed(73)\n\n# Generate sample financial transaction data (GDI Theme: Financial Investigations)\nprint(\"\ud83d\udce5 Generating sample financial transaction data...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0645\u0627\u0644\u064a\u0629 \u0646\u0645\u0648\u0630\u062c\u064a\u0629...\")\nprint(\"   GDI Theme: Financial Investigations\nTerrorism Financing Detection\\n\")\n\n# Create sample dataset with mixed data types_n_samples = 500_data = {\n    'transaction_amount': np.random.uniform(10, 10000, n_samples),\n    'transaction_time': np.random.uniform(0, 24, n_samples),\n    'merchant_category': np.random.choice(['Retail', 'Online', 'Gas', 'Restaurant', 'Travel'], n_samples),\n    'payment_method': np.random.choice(['Credit', 'Debit', 'Cash', 'Digital'], n_samples),\n    'transaction_region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_samples),\n    'customer_age': np.random.randint(18, 80, n_samples),\n    'account_balance': np.random.uniform(100, 50000, n_samples),\n    'risk_level': np.random.choice(['Low', 'Medium', 'High'], n_samples)  # Categorical target\n}\n\ndf = pd.DataFrame(data)\n\nprint(f\"\u2705 Sample dataset created!\")\nprint(f\"   \ud83d\udcca Shape: {df.shape}\")\nprint(f\"   \ud83d\udcca Columns: {list(df.columns)}\")\nprint(f\"\\n\ud83d\udccb Data Types:\")\nprint(df.dtypes)\nprint(f\"\\n\ud83d\udccb First few rows:\")\nprint(df.head())\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"   GDI Theme: Financial Investigations\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "Course 04/unit2-regression/examples/01_ridge_lasso_regression.ipynb",
      "status": "failed",
      "execution_time": 1.621455192565918,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world Credit Card Fraud dataset for Terrorism Financing Detection\n# GDI Theme: Terrorism Financing - Predicting transaction amounts from patterns\n# This dataset has many features (V1-V28, Time) - perfect for regularization!\n\nprint(\"\\n\ud83d\udce5 Loading Credit Card Fraud dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u062d\u062a\u064a\u0627\u0644 \u0627\u0644\u0628\u0637\u0627\u0642\u0627\u062a \u0627\u0644\u0627\u0626\u062a\u0645\u0627\u0646\u064a\u0629...\")\nprint(\" GDI Theme: Terrorism Financing Detection\")\nprint(\" \u0627\u0644\u0645\u0648\u0636\u0648\u0639: \u0643\u0634\u0641 \u062a\u0645\u0648\u064a\u0644 \u0627\u0644\u0625\u0631\u0647\u0627\u0628\")\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\ud83d\udcca Full dataset loaded: {len(df_full):,} records\")\n \n # For Ridge/Lasso regression: Use many features to predict Amount\n # Features: V1-V28, Time (29 features) - many features = risk of overfitting\n # Target: Amount (transaction amount)\n \n # Select features (V1-V28, Time)\nand target (Amount)\nfeature_cols = ['Time'] + [f'V{i}' for i in range(1, 29)] # 29 features total\n target_col = 'Amount'\n \n # Prepare data\n df = df_full[feature_cols + [target_col]].copy()\n \n # Remove any rows with null values\n df = df.dropna()\n \n # Sample for faster computation (Ridge/Lasso can handle larger datasets, but sample for learning)\nsample_size = min(10000, len(df))\n df = df.sample(n=sample_size, random_state=73).copy().reset_index(drop=True)\nprint(f\"\u2705 Dataset prepared: {len(df)} records\")\n print(f\" \ud83d\udcc8 Features: {len(feature_cols)} features (Time, V1-V28)\")\n print(f\" \ud83d\udcb0 Target: Amount (transaction amount in dollars)\")\n print(f\"\\n\ud83d\udd0d Notice:\")\nprint(\" - Many features (29) \u2192 risk of overfitting \u2192 need regularization!\")\n print(\" - Some V features may be correlated \u2192 multicollinearity \u2192 Ridge handles this\")\nprint(\" - Lasso can select most important features (feature selection)\")\n print(\" - Ridge/Lasso will handle this better than regular linear regression\")\nprint(\"\\n\ud83d\udca1 GDI Terrorism Financing Context:\")\nprint(\" - Predict transaction amounts from transaction patterns\")\nprint(\" - Identify unusual transactions that may indicate terrorism financing\")\nprint(\" - Regularization helps build robust models that generalize to new transactions\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected location: ../../datasets/raw/creditcard_fraud.csv\")\nprint(\" \ud83d\udca1 Please ensure the dataset is downloaded\")\nprint(\"\\n For demonstration, creating minimal structure...\")\n # Minimal fallback\n import numpy as np\n np.random.seed(73)\nn_samples = 1000\n n_features = 29\n X = np.random.randn(n_samples, n_features)\ny = np.random.randn(n_samples) * 100 + 100\n df = pd.DataFrame(X, columns=['Time'] + [f'V{i}' for i in range(1, 29)])\n df['Amount'] = y\n print(f\" \u26a0\ufe0f Using synthetic data ({n_samples} samples) - please use real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world Credit Card Fraud dataset for Terrorism Financing Detection\n# GDI Theme: Terrorism Financing - Predicting transaction amounts from patterns\n# This dataset has many features (V1-V28, Time) - perfect for regularization!\n\nprint(\"\\n\ud83d\udce5 Loading Credit Card Fraud dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u062d\u062a\u064a\u0627\u0644 \u0627\u0644\u0628\u0637\u0627\u0642\u0627\u062a \u0627\u0644\u0627\u0626\u062a\u0645\u0627\u0646\u064a\u0629...\")\nprint(\" GDI Theme: Terrorism Financing Detection\")\nprint(\" \u0627\u0644\u0645\u0648\u0636\u0648\u0639: \u0643\u0634\u0641 \u062a\u0645\u0648\u064a\u0644 \u0627\u0644\u0625\u0631\u0647\u0627\u0628\")\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\ud83d\udcca Full dataset loaded: {len(df_full):,} records\")\n \n # For Ridge/Lasso regression: Use many features to predict Amount\n # Features: V1-V28, Time (29 features) - many features = risk of overfitting\n # Target: Amount (transaction amount)\n \n # Select features (V1-V28, Time)\nand target (Amount)\nfeature_cols = ['Time'] + [f'V{i}' for i in range(1, 29)] # 29 features total\n target_col = 'Amount'\n \n # Prepare data\n df = df_full[feature_cols + [target_col]].copy()\n \n # Remove any rows with null values\n df = df.dropna()\n \n # Sample for faster computation (Ridge/Lasso can handle larger datasets, but sample for learning)\nsample_size = min(10000, len(df))\n df = df.sample(n=sample_size, random_state=73).copy().reset_index(drop=True)\nprint(f\"\u2705 Dataset prepared: {len(df)} records\")\n print(f\" \ud83d\udcc8 Features: {len(feature_cols)} features (Time, V1-V28)\")\n print(f\" \ud83d\udcb0 Target: Amount (transaction amount in dollars)\")\n print(f\"\\n\ud83d\udd0d Notice:\")\nprint(\" - Many features (29) \u2192 risk of overfitting \u2192 need regularization!\")\n print(\" - Some V features may be correlated \u2192 multicollinearity \u2192 Ridge handles this\")\nprint(\" - Lasso can select most important features (feature selection)\")\n print(\" - Ridge/Lasso will handle this better than regular linear regression\")\nprint(\"\\n\ud83d\udca1 GDI Terrorism Financing Context:\")\nprint(\" - Predict transaction amounts from transaction patterns\")\nprint(\" - Identify unusual transactions that may indicate terrorism financing\")\nprint(\" - Regularization helps build robust models that generalize to new transactions\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected location: ../../datasets/raw/creditcard_fraud.csv\")\nprint(\" \ud83d\udca1 Please ensure the dataset is downloaded\")\nprint(\"\\n For demonstration, creating minimal structure...\")\n # Minimal fallback\n import numpy as np\n np.random.seed(73)\nn_samples = 1000\n n_features = 29\n X = np.random.randn(n_samples, n_features)\ny = np.random.randn(n_samples) * 100 + 100\n df = pd.DataFrame(X, columns=['Time'] + [f'V{i}' for i in range(1, 29)])\n df['Amount'] = y\n print(f\" \u26a0\ufe0f Using synthetic data ({n_samples} samples) - please use real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/02_cross_validation.ipynb",
      "status": "passed",
      "execution_time": 2.4666900634765625,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/03_bias_variance_learning_curves.ipynb",
      "status": "failed",
      "execution_time": 0.5380358695983887,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve, validation_curve\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.preprocessing \nimport PolynomialFeatures\nfrom sklearn.pipeline \nimport Pipeline\nfrom sklearn.metrics \nimport mean_squared_error_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve, validation_curve\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.preprocessing \nimport PolynomialFeatures\nfrom sklearn.pipeline \nimport Pipeline\nfrom sklearn.metrics \nimport mean_squared_error_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/04_regression_evaluation_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.6152191162109375,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport mean_squared_error, mean_absolute_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRegression Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nMSE (Mean Squared Error):\")\nprint(\"  - Average squared differences\")\nprint(\"  - Penalizes large errors\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nRMSE (Root Mean Squared Error):\")\nprint(\"  - Square root of MSE\")\nprint(\"  - Same units as target\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nMAE (Mean Absolute Error):\")\nprint(\"  - Average absolute differences\")\nprint(\"  - Less sensitive to outliers\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nR\u00b2 (Coefficient of Determination):\")\nprint(\"  - Proportion of variance explained\")\nprint(\"  - Range: -\u221e to 1\")\nprint(\"  - Higher is better (closer to 1)\")\n\nprint(\"\\n\u2705 Regression metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport mean_squared_error, mean_absolute_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nRegression Evaluation Metrics\")\nprint(\"=\" * 60)\n\nprint(\"\\nMSE (Mean Squared Error):\")\nprint(\"  - Average squared differences\")\nprint(\"  - Penalizes large errors\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nRMSE (Root Mean Squared Error):\")\nprint(\"  - Square root of MSE\")\nprint(\"  - Same units as target\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nMAE (Mean Absolute Error):\")\nprint(\"  - Average absolute differences\")\nprint(\"  - Less sensitive to outliers\")\nprint(\"  - Lower is better\")\n\nprint(\"\\nR\u00b2 (Coefficient of Determination):\")\nprint(\"  - Proportion of variance explained\")\nprint(\"  - Range: -\u221e to 1\")\nprint(\"  - Higher is better (closer to 1)\")\n\nprint(\"\\n\u2705 Regression metrics concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/05_leave_one_out_stratified_cv.ipynb",
      "status": "failed",
      "execution_time": 0.7402591705322266,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport LeaveOneOut, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model \nimport LinearRegression_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nLeave-One-Out and Stratified Cross-Validation\")\nprint(\"=\" * 60)\n\nprint(\"\\nLeave-One-Out CV:\")\nprint(\"  - Each sample as test set\")\nprint(\"  - Maximum data usage\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nStratified Cross-Validation:\")\nprint(\"  - Preserves class distribution\")\nprint(\"  - Important for imbalanced data\")\nprint(\"  - Better for classification\")\n\nprint(\"\\n\u2705 Advanced CV concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport LeaveOneOut, StratifiedKFold, cross_val_score\nfrom sklearn.linear_model \nimport LinearRegression_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nLeave-One-Out and Stratified Cross-Validation\")\nprint(\"=\" * 60)\n\nprint(\"\\nLeave-One-Out CV:\")\nprint(\"  - Each sample as test set\")\nprint(\"  - Maximum data usage\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nStratified Cross-Validation:\")\nprint(\"  - Preserves class distribution\")\nprint(\"  - Important for imbalanced data\")\nprint(\"  - Better for classification\")\n\nprint(\"\\n\u2705 Advanced CV concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/06_overfitting_underfitting_handling.ipynb",
      "status": "failed",
      "execution_time": 0.605816125869751,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve\nfrom sklearn.linear_model \nimport LinearRegression, Ridge\nfrom sklearn.tree \nimport DecisionTreeRegressor_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nIdentifying and Handling Overfitting/Underfitting\")\nprint(\"=\" * 60)\n\nprint(\"\\nOverfitting Signs:\")\nprint(\"  - High training accuracy, low validation accuracy\")\nprint(\"  - Large gap between train/test performance\")\nprint(\"  - Model too complex\")\n\nprint(\"\\nUnderfitting Signs:\")\nprint(\"  - Low training accuracy\")\nprint(\"  - Low validation accuracy\")\nprint(\"  - Model too simple\")\n\nprint(\"\\nSolutions:\")\nprint(\"  - Regularization (L1, L2)\")\nprint(\"  - Cross-validation\")\nprint(\"  - Feature selection\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 Overfitting/underfitting concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection \nimport learning_curve\nfrom sklearn.linear_model \nimport LinearRegression, Ridge\nfrom sklearn.tree \nimport DecisionTreeRegressor_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nIdentifying and Handling Overfitting/Underfitting\")\nprint(\"=\" * 60)\n\nprint(\"\\nOverfitting Signs:\")\nprint(\"  - High training accuracy, low validation accuracy\")\nprint(\"  - Large gap between train/test performance\")\nprint(\"  - Model too complex\")\n\nprint(\"\\nUnderfitting Signs:\")\nprint(\"  - Low training accuracy\")\nprint(\"  - Low validation accuracy\")\nprint(\"  - Model too simple\")\n\nprint(\"\\nSolutions:\")\nprint(\"  - Regularization (L1, L2)\")\nprint(\"  - Cross-validation\")\nprint(\"  - Feature selection\")\nprint(\"  - Early stopping\")\n\nprint(\"\\n\u2705 Overfitting/underfitting concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/07_optimal_model_complexity.ipynb",
      "status": "failed",
      "execution_time": 0.7394449710845947,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport validation_curve, GridSearchCV\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.linear_model \nimport Ridge_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSelecting Optimal Model Complexity\")\nprint(\"=\" * 60)\n\nprint(\"\\nValidation Sets:\")\nprint(\"  - Separate from training/test\")\nprint(\"  - Used for hyperparameter tuning\")\nprint(\"  - Prevents overfitting\")\n\nprint(\"\\nComplexity Tuning:\")\nprint(\"  - Tree depth\")\nprint(\"  - Regularization strength\")\nprint(\"  - Number of features\")\nprint(\"  - Model architecture\")\n\nprint(\"\\nMethods:\")\nprint(\"  - Validation curves\")\nprint(\"  - Grid search\")\nprint(\"  - Random search\")\nprint(\"  - Cross-validation\")\n\nprint(\"\\n\u2705 Model complexity selection concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport validation_curve, GridSearchCV\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.linear_model \nimport Ridge_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSelecting Optimal Model Complexity\")\nprint(\"=\" * 60)\n\nprint(\"\\nValidation Sets:\")\nprint(\"  - Separate from training/test\")\nprint(\"  - Used for hyperparameter tuning\")\nprint(\"  - Prevents overfitting\")\n\nprint(\"\\nComplexity Tuning:\")\nprint(\"  - Tree depth\")\nprint(\"  - Regularization strength\")\nprint(\"  - Number of features\")\nprint(\"  - Model architecture\")\n\nprint(\"\\nMethods:\")\nprint(\"  - Validation curves\")\nprint(\"  - Grid search\")\nprint(\"  - Random search\")\nprint(\"  - Cross-validation\")\n\nprint(\"\\n\u2705 Model complexity selection concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/08_comparing_model_performance.ipynb",
      "status": "failed",
      "execution_time": 0.6461718082427979,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Model Performance Across Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nComparison Metrics:\")\nprint(\"  - Cross-validation scores\")\nprint(\"  - Training time\")\nprint(\"  - Prediction time\")\nprint(\"  - Model complexity\")\n\nprint(\"\\nVisualization:\")\nprint(\"  - Bar charts\")\nprint(\"  - Box plots\")\nprint(\"  - Performance tables\")\nprint(\"  - Statistical tests\")\n\nprint(\"\\n\u2705 Model comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Model Performance Across Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nComparison Metrics:\")\nprint(\"  - Cross-validation scores\")\nprint(\"  - Training time\")\nprint(\"  - Prediction time\")\nprint(\"  - Model complexity\")\n\nprint(\"\\nVisualization:\")\nprint(\"  - Bar charts\")\nprint(\"  - Box plots\")\nprint(\"  - Performance tables\")\nprint(\"  - Statistical tests\")\n\nprint(\"\\n\u2705 Model comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/08_decision_tree_random_forest_regression.ipynb",
      "status": "passed",
      "execution_time": 1.6559100151062012,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/09_comparing_regression_algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.732428789138794,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Regression Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nAlgorithms to Compare:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Ridge Regression\")\nprint(\"  - Lasso Regression\")\nprint(\"  - Decision Tree\")\nprint(\"  - Random Forest\")\n\nprint(\"\\nEvaluation Metrics:\")\nprint(\"  - MSE (Mean Squared Error)\")\nprint(\"  - RMSE (Root Mean Squared Error)\")\nprint(\"  - MAE (Mean Absolute Error)\")\nprint(\"  - R\u00b2 (Coefficient of Determination)\")\n\nprint(\"\\n\u2705 Regression comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model \nimport LinearRegression, Ridge, Lasso\nfrom sklearn.tree \nimport DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestRegressor\nfrom sklearn.model_selection \nimport cross_val_score\nfrom sklearn.metrics \nimport mean_squared_error, r2_score, mean_absolute_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nComparing Regression Algorithms\")\nprint(\"=\" * 60)\n\nprint(\"\\nAlgorithms to Compare:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Ridge Regression\")\nprint(\"  - Lasso Regression\")\nprint(\"  - Decision Tree\")\nprint(\"  - Random Forest\")\n\nprint(\"\\nEvaluation Metrics:\")\nprint(\"  - MSE (Mean Squared Error)\")\nprint(\"  - RMSE (Root Mean Squared Error)\")\nprint(\"  - MAE (Mean Absolute Error)\")\nprint(\"  - R\u00b2 (Coefficient of Determination)\")\n\nprint(\"\\n\u2705 Regression comparison concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/10_visualizing_regression_results_residuals.ipynb",
      "status": "failed",
      "execution_time": 0.523792028427124,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.metrics \nimport mean_squared_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nVisualizing Regression Results and Residuals\")\nprint(\"=\" * 60)\n\nprint(\"\\nVisualizations:\")\nprint(\"  - Predicted vs Actual scatter plot\")\nprint(\"  - Residual plots\")\nprint(\"  - Residual distribution\")\nprint(\"  - Q-Q plots for normality\")\n\nprint(\"\\nResidual Analysis:\")\nprint(\"  - Check for patterns\")\nprint(\"  - Identify outliers\")\nprint(\"  - Verify assumptions\")\nprint(\"  - Diagnose model issues\")\n\nprint(\"\\n\u2705 Visualization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model \nimport LinearRegression\nfrom sklearn.metrics \nimport mean_squared_error, r2_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nVisualizing Regression Results and Residuals\")\nprint(\"=\" * 60)\n\nprint(\"\\nVisualizations:\")\nprint(\"  - Predicted vs Actual scatter plot\")\nprint(\"  - Residual plots\")\nprint(\"  - Residual distribution\")\nprint(\"  - Q-Q plots for normality\")\n\nprint(\"\\nResidual Analysis:\")\nprint(\"  - Check for patterns\")\nprint(\"  - Identify outliers\")\nprint(\"  - Verify assumptions\")\nprint(\"  - Diagnose model issues\")\n\nprint(\"\\n\u2705 Visualization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/comparing_model_performance_across_different_algorithms.ipynb",
      "status": "failed",
      "execution_time": 0.7275457382202148,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/computing_regression_evaluation_metrics_mse_rmse_mae_r\u00b2.ipynb",
      "status": "failed",
      "execution_time": 0.7356870174407959,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/identifying_and_handling_overfittingunderfitting.ipynb",
      "status": "failed",
      "execution_time": 0.7240760326385498,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/performing_leave_one_out_and_stratified_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.5977139472961426,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/examples/selecting_optimal_model_complexity_using_validation_sets.ipynb",
      "status": "failed",
      "execution_time": 0.7244400978088379,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "example"
    },
    {
      "path": "Course 04/unit2-regression/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.8311660289764404,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lassof\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.model_selection import rom train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lassof\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import rom train_test_split\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit2-regression/exercises/exercise_02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.5612471103668213,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 2: Cross-Validation Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\n\nInstructions:\n1. Load the provided dataset_2. Implement K-Fold cross-validation manually_3. Use sklearn's KFold for cross-validation_4. Compare single train-test split vs K-Fold CV_5. Calculate mean and std of CV scores_6. Understand why CV gives more reliable estimates\n\nDataset: Regression dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample regression data_np.random.seed(123)\nX = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ny = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Single train-test split (baseline)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Single train-test split\")\nprint(\"=\"*60)\n# Split data 80/20\n# Train Linear Regression\n# Evaluate on test set\n# Print MSE and R\u00b2\n# Your code here...\n\n# Task 2: Manual K-Fold cross-validation (K=5)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Manual K-Fold CV (K=5)\")\nprint(\"=\"*60)\n# Split data into 5 folds manually\n# For each fold:\n#   - Train on 4 folds, test on 1 fold\n#   - Calculate MSE and R\u00b2\n# Store all scores\n# Print mean and std of scores\n# Your code here...\n\n# Task 3: Use sklearn's KFold_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: sklearn KFold\")\nprint(\"=\"*60)\n# Use KFold(n_splits=5, shuffle=True, random_state=123)\n# Implement CV loop using KFold\n# Calculate mean and std of scores\n# Your code here...\n\n# Task 4: Use cross_val_score_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: cross_val_score\")\nprint(\"=\"*60)\n# Use sklearn's cross_val_score function\n# Much simpler than manual implementation!\n# Print mean and std\n# Your code here...\n\n# Task 5: Compare single split vs CV_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare single split vs CV\")\nprint(\"=\"*60)\n# Show that CV gives more reliable estimate\n# Single split: One score (might be lucky/unlucky)\n# CV: Multiple scores, mean gives better estimate\n# Your code here...\n\n# Task 6: Visualize CV score distribution_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize CV scores\")\nprint(\"=\"*60)\n# Plot histogram of CV scores\n# Show mean and std\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2 - Exercise 2: Cross-Validation Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639\n\nInstructions:\n1. Load the provided dataset_2. Implement K-Fold cross-validation manually_3. Use sklearn's KFold for cross-validation_4. Compare single train-test split vs K-Fold CV_5. Calculate mean and std of CV scores_6. Understand why CV gives more reliable estimates\n\nDataset: Regression dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate sample regression data_np.random.seed(123)\nX = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ny = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Single train-test split (baseline)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Single train-test split\")\nprint(\"=\"*60)\n# Split data 80/20\n# Train Linear Regression\n# Evaluate on test set\n# Print MSE and R\u00b2\n# Your code here...\n\n# Task 2: Manual K-Fold cross-validation (K=5)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Manual K-Fold CV (K=5)\")\nprint(\"=\"*60)\n# Split data into 5 folds manually\n# For each fold:\n#   - Train on 4 folds, test on 1 fold\n#   - Calculate MSE and R\u00b2\n# Store all scores\n# Print mean and std of scores\n# Your code here...\n\n# Task 3: Use sklearn's KFold_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: sklearn KFold\")\nprint(\"=\"*60)\n# Use KFold(n_splits=5, shuffle=True, random_state=123)\n# Implement CV loop using KFold\n# Calculate mean and std of scores\n# Your code here...\n\n# Task 4: Use cross_val_score_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: cross_val_score\")\nprint(\"=\"*60)\n# Use sklearn's cross_val_score function\n# Much simpler than manual implementation!\n# Print mean and std\n# Your code here...\n\n# Task 5: Compare single split vs CV_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare single split vs CV\")\nprint(\"=\"*60)\n# Show that CV gives more reliable estimate\n# Single split: One score (might be lucky/unlucky)\n# CV: Multiple scores, mean gives better estimate\n# Your code here...\n\n# Task 6: Visualize CV score distribution_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Visualize CV scores\")\nprint(\"=\"*60)\n# Plot histogram of CV scores\n# Show mean and std\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.randn(300, 5)_y =  2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit2-regression/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7917327880859375,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "Course 04/unit2-regression/solutions/solution_02_cross_validation.ipynb",
      "status": "failed",
      "execution_time": 0.5320799350738525,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 2 - Exercise 2: Cross-Validation Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639Instructions:1. Load the provided dataset2. Implement K-Fold cross-validation manually3. Use sklearn's KFold for cross-validation4. Compare single train-test split vs K-Fold CV5. Calculate mean and std of CV scores6. Understand why CV gives more reliable estimatesDataset: Regression dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Generate sample regression datanp.random.seed(123)X = np.random.randn(300, 5)y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: sklearn KFold\")print(\"=\"*60)# Use KFold(n_splits=5, shuffle=True, random_state=123)# Implement CV loop using KFold# Calculate mean and std of scores# Your code here...# Task 4: Use cross_val_score\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: cross_val_score\")print(\"=\"*60)# Use sklearn's cross_val_score function# Much simpler than manual implementation!# Print mean and std# Your code here...# Task 5: Compare single split vs CV\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare single split vs CV\")print(\"=\"*60)# Show that CV gives more reliable estimate# Single split: One score (might be lucky/unlucky)# CV: Multiple scores, mean gives better estimate# Your code here...# Task 6: Visualize CV score distribution\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize CV scores\")print(\"=\"*60)# Plot histogram of CV scores# Show mean and std# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 2 - Exercise 2: Cross-Validation Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u062a\u062d\u0642\u0642 \u0627\u0644\u0645\u062a\u0642\u0627\u0637\u0639Instructions:1. Load the provided dataset2. Implement K-Fold cross-validation manually3. Use sklearn's KFold for cross-validation4. Compare single train-test split vs K-Fold CV5. Calculate mean and std of CV scores6. Understand why CV gives more reliable estimatesDataset: Regression dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Generate sample regression datanp.random.seed(123)X = np.random.randn(300, 5)y = 2 * X[:, 0] + 1.5 * X[:, 1] - X[:, 2] + 3 * X[:, 3] + np.random.normal(0, 0.5, 300)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(5)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: sklearn KFold\")print(\"=\"*60)# Use KFold(n_splits=5, shuffle=True, random_state=123)# Implement CV loop using KFold# Calculate mean and std of scores# Your code here...# Task 4: Use cross_val_score\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: cross_val_score\")print(\"=\"*60)# Use sklearn's cross_val_score function# Much simpler than manual implementation!# Print mean and std# Your code here...# Task 5: Compare single split vs CV\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare single split vs CV\")print(\"=\"*60)# Show that CV gives more reliable estimate# Single split: One score (might be lucky/unlucky)# CV: Multiple scores, mean gives better estimate# Your code here...# Task 6: Visualize CV score distribution\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Visualize CV scores\")print(\"=\"*60)# Plot histogram of CV scores# Show mean and std# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Single train-test split (baseline)print(\"\\n\" + \"=\"*60)print(\"Task 1: Single train-test split\")print(\"=\"*60)# Split data 80/20# Train Linear Regression# Evaluate on test set# Print MSE and R\u00b2# Your code here...# Task 2: Manual K-Fold cross-validation (K=5)print(\"\\n\" + \"=\"*60)print(\"Task 2: Manual K-Fold CV (K=5)\")print(\"=\"*60)# Split data into 5 folds manually# For each fold:#   - Train on 4 folds, test on 1 fold#   - Calculate MSE and R\u00b2# Store all scores# Print mean and std of scores# Your code here...# Task 3: Use sklearn's KFold\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/examples/01_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 1.556227207183838,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load Credit Card Fraud dataset (GDI Theme: Terrorism Financing Detection)\n# This is a real-world financial dataset for binary classification\n# Domain: Financial Investigations\nCounter-Espionage - Terrorism Financing Detection\n# Binary classification = predicting one of two classes (0 or 1)\n# This dataset has 30 numerical features (Time, V1-V28, Amount)\nand 284,807 samples\n# We'll sample it for faster learning (10,000 samples)\nprint(\"\\n\ud83d\udce5 Loading Credit Card Fraud dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062d\u062a\u064a\u0627\u0644 \u0641\u064a \u0628\u0637\u0627\u0642\u0627\u062a \u0627\u0644\u0627\u0626\u062a\u0645\u0627\u0646...\")\nprint(\" GDI Theme: Terrorism Financing Detection\")\nprint(\" (Binary classification: Class 0 = Legitimate, Class 1 = Fraud/Terrorism Financing)\")\n\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n # Use balanced sampling for better learning\n # WHY? The dataset is highly imbalanced (99.83% legitimate, 0.17% fraud)\n # Problem: Random sampling would give us too few fraud cases (e.g., 30 out of 10,000)\n # Result: Only 6 fraud cases in test set \u2192 metrics are unreliable!\n # Solution: Use ALL fraud cases (492) + sample legitimate cases (5,000)\n # Benefit: ~98 fraud cases in test set \u2192 meaningful evaluation metrics!\n # This is REAL data - we're just sampling intelligently for learning purposes\n \n df_fraud = df_full[df_full['Class'] == 1].copy()\n df_legitimate = df_full[df_full['Class'] == 0].copy()\n \n # Use all fraud cases and sample 5,000 legitimate cases\n legitimate_sample_size = 5000\n df_legitimate_sample = df_legitimate.sample(\n n=min(legitimate_sample_size, len(df_legitimate)), random_state=73, \n replace=False\n )\n \n # Combine and shuffle\n df = pd.concat([df_legitimate_sample, df_fraud], ignore_index=True)\ndf = df.sample(frac=1, random_state=73).reset_index(drop=True) # Shuffle\n \n print(f\"\\n\u2705 Credit Card Fraud dataset loaded!\")\nprint(f\" \ud83d\udcca Full dataset: {len(df_full):,} samples (REAL financial transaction data)\")\n print(f\" \ud83d\udcca Using balanced sample: {len(df):,} samples\")\n print(f\" - Legitimate: {(df['Class']==0).sum():,} ({(df['Class']==0).mean()*100:.1f}%)\")\n print(f\" - Fraud: {(df['Class']==1).sum():,} ({(df['Class']==1).mean()*100:.1f}%)\")\n print(f\"\\n\ud83d\udca1 Why Balanced Sampling?\")\nprint(f\" - Original dataset: 99.83% legitimate, 0.17% fraud (highly imbalanced!)\")\n print(f\" - Problem: Random sampling \u2192 too few fraud cases \u2192 unreliable metrics\")\nprint(f\" - Solution: Use ALL fraud cases + sample legitimate \u2192 enough fraud for evaluation\")\nprint(f\" - Result: Meaningful metrics (Precision, Recall, F1)\nfor fraud detection!\")\n print(f\"\\n\ud83d\udcc8 Features: All numerical (30 features: Time, V1-V28, Amount)\")\n print(f\" - Time: Transaction timestamp\")\nprint(f\" - Amount: Transaction amount\")\nprint(f\" - V1-V28: Anonymized features from PCA (capturing transaction patterns)\")\n print(f\"\\n\ud83c\udfaf Target: Binary classification\")\nprint(f\" - Class 0 = Legitimate transaction\")\nprint(f\" - Class 1 = Fraud/Terrorism Financing (suspicious transaction)\")\n print(f\"\\n\ud83d\udd0d For CS Students - Focus on Structure:\")\nprint(f\" - Data shape: {df.shape[0]} rows \u00d7 {df.shape[1]} columns\")\nprint(f\" - Feature type: All numerical (no encoding needed)\")\n print(f\" - Target type: Binary (0 or 1) - categorical classification\")\n print(f\" - Task: Predict class based on {len(df.columns)-1} features\")\n print(f\" - Class distribution: Imbalanced (9% fraud, 91% legitimate) - realistic for fraud data!\")\n print(f\"\\n\ud83c\udf0d Real-World GDI Context:\")\nprint(f\" - Domain: Financial Investigations\nCounter-Espionage\")\nprint(f\" - Application: Terrorism financing detection through transaction analysis\")\nprint(f\" - Real Data: Actual credit card transactions (anonymized for privacy)\")\n print(f\" - Practical: This is what GDI investigators use - detecting suspicious patterns!\")\nprint(f\" - Perfect for learning binary classification with real-world relevance!\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected: ../../datasets/raw/creditcard_fraud.csv\")\nprint(\" Please ensure the dataset is downloaded.\")\nraiseexcept Exception as e:\n print(f\"\\n\u274c Error loading dataset: {e}\")\nraise\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    Counter-Espionage - Terrorism Financing Detection\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load Credit Card Fraud dataset (GDI Theme: Terrorism Financing Detection)\n# This is a real-world financial dataset for binary classification\n# Domain: Financial Investigations\nCounter-Espionage - Terrorism Financing Detection\n# Binary classification = predicting one of two classes (0 or 1)\n# This dataset has 30 numerical features (Time, V1-V28, Amount)\nand 284,807 samples\n# We'll sample it for faster learning (10,000 samples)\nprint(\"\\n\ud83d\udce5 Loading Credit Card Fraud dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062d\u062a\u064a\u0627\u0644 \u0641\u064a \u0628\u0637\u0627\u0642\u0627\u062a \u0627\u0644\u0627\u0626\u062a\u0645\u0627\u0646...\")\nprint(\" GDI Theme: Terrorism Financing Detection\")\nprint(\" (Binary classification: Class 0 = Legitimate, Class 1 = Fraud/Terrorism Financing)\")\n\ntry:\n # Load the dataset\n df_full = # File not found: ../../datasets/raw/creditcard_fraud.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n # Use balanced sampling for better learning\n # WHY? The dataset is highly imbalanced (99.83% legitimate, 0.17% fraud)\n # Problem: Random sampling would give us too few fraud cases (e.g., 30 out of 10,000)\n # Result: Only 6 fraud cases in test set \u2192 metrics are unreliable!\n # Solution: Use ALL fraud cases (492) + sample legitimate cases (5,000)\n # Benefit: ~98 fraud cases in test set \u2192 meaningful evaluation metrics!\n # This is REAL data - we're just sampling intelligently for learning purposes\n \n df_fraud = df_full[df_full['Class'] == 1].copy()\n df_legitimate = df_full[df_full['Class'] == 0].copy()\n \n # Use all fraud cases and sample 5,000 legitimate cases\n legitimate_sample_size = 5000\n df_legitimate_sample = df_legitimate.sample(\n n=min(legitimate_sample_size, len(df_legitimate)), random_state=73, \n replace=False\n )\n \n # Combine and shuffle\n df = pd.concat([df_legitimate_sample, df_fraud], ignore_index=True)\ndf = df.sample(frac=1, random_state=73).reset_index(drop=True) # Shuffle\n \n print(f\"\\n\u2705 Credit Card Fraud dataset loaded!\")\nprint(f\" \ud83d\udcca Full dataset: {len(df_full):,} samples (REAL financial transaction data)\")\n print(f\" \ud83d\udcca Using balanced sample: {len(df):,} samples\")\n print(f\" - Legitimate: {(df['Class']==0).sum():,} ({(df['Class']==0).mean()*100:.1f}%)\")\n print(f\" - Fraud: {(df['Class']==1).sum():,} ({(df['Class']==1).mean()*100:.1f}%)\")\n print(f\"\\n\ud83d\udca1 Why Balanced Sampling?\")\nprint(f\" - Original dataset: 99.83% legitimate, 0.17% fraud (highly imbalanced!)\")\n print(f\" - Problem: Random sampling \u2192 too few fraud cases \u2192 unreliable metrics\")\nprint(f\" - Solution: Use ALL fraud cases + sample legitimate \u2192 enough fraud for evaluation\")\nprint(f\" - Result: Meaningful metrics (Precision, Recall, F1)\nfor fraud detection!\")\n print(f\"\\n\ud83d\udcc8 Features: All numerical (30 features: Time, V1-V28, Amount)\")\n print(f\" - Time: Transaction timestamp\")\nprint(f\" - Amount: Transaction amount\")\nprint(f\" - V1-V28: Anonymized features from PCA (capturing transaction patterns)\")\n print(f\"\\n\ud83c\udfaf Target: Binary classification\")\nprint(f\" - Class 0 = Legitimate transaction\")\nprint(f\" - Class 1 = Fraud/Terrorism Financing (suspicious transaction)\")\n print(f\"\\n\ud83d\udd0d For CS Students - Focus on Structure:\")\nprint(f\" - Data shape: {df.shape[0]} rows \u00d7 {df.shape[1]} columns\")\nprint(f\" - Feature type: All numerical (no encoding needed)\")\n print(f\" - Target type: Binary (0 or 1) - categorical classification\")\n print(f\" - Task: Predict class based on {len(df.columns)-1} features\")\n print(f\" - Class distribution: Imbalanced (9% fraud, 91% legitimate) - realistic for fraud data!\")\n print(f\"\\n\ud83c\udf0d Real-World GDI Context:\")\nprint(f\" - Domain: Financial Investigations\nCounter-Espionage\")\nprint(f\" - Application: Terrorism financing detection through transaction analysis\")\nprint(f\" - Real Data: Actual credit card transactions (anonymized for privacy)\")\n print(f\" - Practical: This is what GDI investigators use - detecting suspicious patterns!\")\nprint(f\" - Perfect for learning binary classification with real-world relevance!\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Expected: ../../datasets/raw/creditcard_fraud.csv\")\nprint(\" Please ensure the dataset is downloaded.\")\nraiseexcept Exception as e:\n print(f\"\\n\u274c Error loading dataset: {e}\")\nraise\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    Counter-Espionage - Terrorism Financing Detection\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/02_decision_trees.ipynb",
      "status": "failed",
      "execution_time": 1.6248629093170166,
      "error": "An error occurred while executing the following cell:\n------------------\n# Solve the non-linear problem from Notebook 01!\n# We'll use the SAME circular dataset that Logistic Regression failed on\n# Decision Trees will show they can handle non-linear boundaries!\n\nfrom sklearn.datasets import make_circles\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Solving the Non-Linear Problem from Notebook 01\")\nprint(\"\u062d\u0644 \u0627\u0644\u0645\u0634\u0643\u0644\u0629 \u063a\u064a\u0631 \u0627\u0644\u062e\u0637\u064a\u0629 \u0645\u0646 \u0627\u0644\u062f\u0641\u062a\u0631 01\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udce5 Generating the SAME non-linear dataset from Notebook 01...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0646\u0641\u0633 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u063a\u064a\u0631 \u0627\u0644\u062e\u0637\u064a\u0629 \u0645\u0646 \u0627\u0644\u062f\u0641\u062a\u0631 01...\")\nprint(\"\\n\ud83d\udca1 Remember: Logistic Regression got ~50-70% accuracy on this data \u274c\")\nprint(\" Decision Trees should solve it with 85-90% accuracy! \u2705\")\n\n# Create the SAME circular (non-linear)\nclassification data from Notebook 01\n# This is the EXACT dataset that Logistic Regression failed on!\nX_nonlinear, y_nonlinear = make_circles(\n n_samples=500, # Same as Notebook 01\n noise=0.1, # Same as Notebook 01\n factor=0.5, # Same as Notebook 01\n random_state=123 # Any number works - just for reproducibility. Same random_state ensures SAME data!\n)\nprint(f\"\\n\u2705 Non-linear dataset loaded (SAME as Notebook 01)!\")\nprint(f\" \ud83d\udcca Shape: {X_nonlinear.shape}\")\nprint(f\" \ud83c\udfaf Classes: {len(np.unique(y_nonlinear))} (binary classification)\")\nprint(f\" \ud83d\udcc8 Pattern: Two concentric circles (non-linear!)\")\nprint(f\"\\n\ud83d\udd0d This is the EXACT problem Logistic Regression failed on:\")\nprint(f\" - Circular boundaries (can't separate with straight line)\")\nprint(f\" - Logistic Regression accuracy: ~50-70% \u274c\")\nprint(f\" - Expected Decision Trees accuracy: 85-90% \u2705\")\n\n# Split the data (same random_state for consistency)\nX_nl_train, X_nl_test, y_nl_train, y_nl_test = train_test_split(\n X_nonlinear, y_nonlinear, test_size=0.2, random_state=123, stratify=y_nonlinear # Any number works - just for reproducibility\n)\nprint(f\"\\n\u2705 Data split!\")\nprint(f\" Training samples: {len(X_nl_train)}\")\nprint(f\" Test samples: {len(X_nl_test)}\")\nprint(f\"\\n\ud83d\udca1 Note: Trees don't require feature scaling (unlike Logistic Regression)!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    classification data from Notebook 01\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Solve the non-linear problem from Notebook 01!\n# We'll use the SAME circular dataset that Logistic Regression failed on\n# Decision Trees will show they can handle non-linear boundaries!\n\nfrom sklearn.datasets import make_circles\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Solving the Non-Linear Problem from Notebook 01\")\nprint(\"\u062d\u0644 \u0627\u0644\u0645\u0634\u0643\u0644\u0629 \u063a\u064a\u0631 \u0627\u0644\u062e\u0637\u064a\u0629 \u0645\u0646 \u0627\u0644\u062f\u0641\u062a\u0631 01\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udce5 Generating the SAME non-linear dataset from Notebook 01...\")\nprint(\"\u0625\u0646\u0634\u0627\u0621 \u0646\u0641\u0633 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u063a\u064a\u0631 \u0627\u0644\u062e\u0637\u064a\u0629 \u0645\u0646 \u0627\u0644\u062f\u0641\u062a\u0631 01...\")\nprint(\"\\n\ud83d\udca1 Remember: Logistic Regression got ~50-70% accuracy on this data \u274c\")\nprint(\" Decision Trees should solve it with 85-90% accuracy! \u2705\")\n\n# Create the SAME circular (non-linear)\nclassification data from Notebook 01\n# This is the EXACT dataset that Logistic Regression failed on!\nX_nonlinear, y_nonlinear = make_circles(\n n_samples=500, # Same as Notebook 01\n noise=0.1, # Same as Notebook 01\n factor=0.5, # Same as Notebook 01\n random_state=123 # Any number works - just for reproducibility. Same random_state ensures SAME data!\n)\nprint(f\"\\n\u2705 Non-linear dataset loaded (SAME as Notebook 01)!\")\nprint(f\" \ud83d\udcca Shape: {X_nonlinear.shape}\")\nprint(f\" \ud83c\udfaf Classes: {len(np.unique(y_nonlinear))} (binary classification)\")\nprint(f\" \ud83d\udcc8 Pattern: Two concentric circles (non-linear!)\")\nprint(f\"\\n\ud83d\udd0d This is the EXACT problem Logistic Regression failed on:\")\nprint(f\" - Circular boundaries (can't separate with straight line)\")\nprint(f\" - Logistic Regression accuracy: ~50-70% \u274c\")\nprint(f\" - Expected Decision Trees accuracy: 85-90% \u2705\")\n\n# Split the data (same random_state for consistency)\nX_nl_train, X_nl_test, y_nl_train, y_nl_test = train_test_split(\n X_nonlinear, y_nonlinear, test_size=0.2, random_state=123, stratify=y_nonlinear # Any number works - just for reproducibility\n)\nprint(f\"\\n\u2705 Data split!\")\nprint(f\" Training samples: {len(X_nl_train)}\")\nprint(f\" Test samples: {len(X_nl_test)}\")\nprint(f\"\\n\ud83d\udca1 Note: Trees don't require feature scaling (unlike Logistic Regression)!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    classification data from Notebook 01\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/03_svm.ipynb",
      "status": "failed",
      "execution_time": 1.7490100860595703,
      "error": "An error occurred while executing the following cell:\n------------------\n# Demonstrate SVM's optimal margin advantage\n# We'll use the CICIDS2017 cybersecurity dataset to show SVM's generalization\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Finding Optimal Margin Boundaries with SVM\")\nprint(\"\u0625\u064a\u062c\u0627\u062f \u062d\u062f\u0648\u062f \u0627\u0644\u0647\u0627\u0645\u0634 \u0627\u0644\u0623\u0645\u062b\u0644 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 SVM\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udca1 Remember from Decision Trees notebook:\")\nprint(\" - Decision Trees can overfit (train 100%, test 75-80%)\")\nprint(\" - Decision Trees don't always create optimal margin boundaries\")\nprint(\" - SVM finds optimal margin boundaries for better generalization! \u2705\")\n\n# Load real-world CICIDS2017 cybersecurity dataset\n# This is REAL network traffic data for binary classification (Benign vs Attack)\n# Perfect for demonstrating SVM's optimal margin and kernels for GDI Cyber Threats!\n\nprint(\"\\n\ud83d\udce5 Loading CICIDS2017 Cybersecurity Dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0623\u0645\u0646 \u0627\u0644\u0633\u064a\u0628\u0631\u0627\u0646\u064a CICIDS2017...\")\ntry:\n # Load CICIDS2017 dataset\n df_full = # File not found: ../../datasets/raw/cicids2017.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n # Sample dataset for faster computation (SVM can be slow on large datasets)\n # Using 10,000 samples for learning convenience\n sample_size = 10000\n if len(df_full) > sample_size:\n df = df_full.sample(n=sample_size, random_state=73, replace=False).reset_index(drop=True)\nprint(f\"\\n\ud83d\udcca Full dataset has {len(df_full):,} rows\")\n print(f\" Using {sample_size:,} samples for faster computation (learning convenience)\")\n print(f\" \ud83d\udca1 In real projects, use the full dataset for best performance!\")\nelse:\n df = df_full.copy()\n \n # Prepare features and target\n # Target column is ' Label' (with space) - BENIGN = Normal, Others = Attack\n feature_cols = [col for col in df.columns if col.strip() != ' Label']\n \n # Create binary target: BENIGN = 0 (Normal), Attacks = 1 (Malicious)\ndf['target'] = (df[' Label'] != 'BENIGN').astype(int)\n \n # Select numeric features only (SVM requires numeric features)\n # Remove any non-numeric columns\n numeric_cols = []\n for col in feature_cols:\n if df[col].dtype in ['int64', 'float64']:\n numeric_cols.append(col)\n \n # Use first 30 numeric features for consistency with original notebook structure\n # (CICIDS2017 has 78 features, but we'll use 30 for comparison)\nif len(numeric_cols) > 30:\n numeric_cols = numeric_cols[:30]\n print(f\"\\n Using first 30 numeric features (out of {len([c for c in feature_cols if df[c].dtype in ['int64', 'float64']])} total)\")\n print(f\" \ud83d\udca1 In real projects, use all relevant features!\")\n \n # Create feature matrix\n X_data = df[numeric_cols].valuesy_data = df['target'].values\n \n # Handle missing values (NaN)\nand infinity - required for SVM and PCA\n # Check for NaN and infinity values\n nan_count = np.isnan(X_data).sum()\n inf_count = np.isinf(X_data).sum()\n if nan_count > 0 or inf_count > 0:\n print(f\"\\n\u26a0\ufe0f Found {nan_count} NaN values and {inf_count} infinity values in features\")\nprint(f\" Handling missing/invalid values by dropping rows...\")\n # Create mask for rows without NaN or infinity\n valid_rows = ~(np.isnan(X_data).any(axis=1) | np.isinf(X_data).any(axis=1))\n X_data = X_data[valid_rows]\n y_data = y_data[valid_rows]\n print(f\" \u2705 After removing NaN/infinity: {len(X_data):,} samples remaining\")\n \n print(f\"\\n\u2705 Real-world CICIDS2017 cybersecurity dataset loaded!\")\nprint(f\" \ud83d\udcca This is REAL network traffic data from Canadian Institute for Cybersecurity\")\nprint(f\" \ud83d\udcc8 Contains {len(df)} samples with {len(numeric_cols)} features\")\n print(f\" \ud83c\udfaf Target: Binary classification (0 = Benign/Normal, 1 = Attack/Malicious)\")\n print(f\" \ud83c\udfaf GDI Theme: Cyber Threats - Network Attack Detection\")\nprint(f\"\\n\ud83d\udd0d Notice:\")\nprint(\" - This is REAL network traffic data (cybersecurity)\")\n print(\" - Features are network flow characteristics (packets, bytes, duration, etc.)\")\n print(\" - We'll use {len(numeric_cols)} features for model training (best performance)\") print(\" - For visualization, we'll use PCA to reduce to 2D (decision boundaries)\")\n print(\" - Perfect for comparing Linear, RBF, and Polynomial kernels!\")\nprint(\" - Perfect for GDI cyber threat detection applications!\")\nexcept FileNotFoundError:\n print(\"\\n\u274c Error: CICIDS2017 dataset not found!\")\nprint(\" Please ensure 'cicids2017.csv' is in '../../datasets/raw/'\")\nprint(\" Or download from: https://www.unb.ca/cic/datasets/ids-2017.html\")\nraise\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/cicids2017.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Demonstrate SVM's optimal margin advantage\n# We'll use the CICIDS2017 cybersecurity dataset to show SVM's generalization\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Finding Optimal Margin Boundaries with SVM\")\nprint(\"\u0625\u064a\u062c\u0627\u062f \u062d\u062f\u0648\u062f \u0627\u0644\u0647\u0627\u0645\u0634 \u0627\u0644\u0623\u0645\u062b\u0644 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 SVM\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udca1 Remember from Decision Trees notebook:\")\nprint(\" - Decision Trees can overfit (train 100%, test 75-80%)\")\nprint(\" - Decision Trees don't always create optimal margin boundaries\")\nprint(\" - SVM finds optimal margin boundaries for better generalization! \u2705\")\n\n# Load real-world CICIDS2017 cybersecurity dataset\n# This is REAL network traffic data for binary classification (Benign vs Attack)\n# Perfect for demonstrating SVM's optimal margin and kernels for GDI Cyber Threats!\n\nprint(\"\\n\ud83d\udce5 Loading CICIDS2017 Cybersecurity Dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0623\u0645\u0646 \u0627\u0644\u0633\u064a\u0628\u0631\u0627\u0646\u064a CICIDS2017...\")\ntry:\n # Load CICIDS2017 dataset\n df_full = # File not found: ../../datasets/raw/cicids2017.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n # Sample dataset for faster computation (SVM can be slow on large datasets)\n # Using 10,000 samples for learning convenience\n sample_size = 10000\n if len(df_full) > sample_size:\n df = df_full.sample(n=sample_size, random_state=73, replace=False).reset_index(drop=True)\nprint(f\"\\n\ud83d\udcca Full dataset has {len(df_full):,} rows\")\n print(f\" Using {sample_size:,} samples for faster computation (learning convenience)\")\n print(f\" \ud83d\udca1 In real projects, use the full dataset for best performance!\")\nelse:\n df = df_full.copy()\n \n # Prepare features and target\n # Target column is ' Label' (with space) - BENIGN = Normal, Others = Attack\n feature_cols = [col for col in df.columns if col.strip() != ' Label']\n \n # Create binary target: BENIGN = 0 (Normal), Attacks = 1 (Malicious)\ndf['target'] = (df[' Label'] != 'BENIGN').astype(int)\n \n # Select numeric features only (SVM requires numeric features)\n # Remove any non-numeric columns\n numeric_cols = []\n for col in feature_cols:\n if df[col].dtype in ['int64', 'float64']:\n numeric_cols.append(col)\n \n # Use first 30 numeric features for consistency with original notebook structure\n # (CICIDS2017 has 78 features, but we'll use 30 for comparison)\nif len(numeric_cols) > 30:\n numeric_cols = numeric_cols[:30]\n print(f\"\\n Using first 30 numeric features (out of {len([c for c in feature_cols if df[c].dtype in ['int64', 'float64']])} total)\")\n print(f\" \ud83d\udca1 In real projects, use all relevant features!\")\n \n # Create feature matrix\n X_data = df[numeric_cols].valuesy_data = df['target'].values\n \n # Handle missing values (NaN)\nand infinity - required for SVM and PCA\n # Check for NaN and infinity values\n nan_count = np.isnan(X_data).sum()\n inf_count = np.isinf(X_data).sum()\n if nan_count > 0 or inf_count > 0:\n print(f\"\\n\u26a0\ufe0f Found {nan_count} NaN values and {inf_count} infinity values in features\")\nprint(f\" Handling missing/invalid values by dropping rows...\")\n # Create mask for rows without NaN or infinity\n valid_rows = ~(np.isnan(X_data).any(axis=1) | np.isinf(X_data).any(axis=1))\n X_data = X_data[valid_rows]\n y_data = y_data[valid_rows]\n print(f\" \u2705 After removing NaN/infinity: {len(X_data):,} samples remaining\")\n \n print(f\"\\n\u2705 Real-world CICIDS2017 cybersecurity dataset loaded!\")\nprint(f\" \ud83d\udcca This is REAL network traffic data from Canadian Institute for Cybersecurity\")\nprint(f\" \ud83d\udcc8 Contains {len(df)} samples with {len(numeric_cols)} features\")\n print(f\" \ud83c\udfaf Target: Binary classification (0 = Benign/Normal, 1 = Attack/Malicious)\")\n print(f\" \ud83c\udfaf GDI Theme: Cyber Threats - Network Attack Detection\")\nprint(f\"\\n\ud83d\udd0d Notice:\")\nprint(\" - This is REAL network traffic data (cybersecurity)\")\n print(\" - Features are network flow characteristics (packets, bytes, duration, etc.)\")\n print(\" - We'll use {len(numeric_cols)} features for model training (best performance)\") print(\" - For visualization, we'll use PCA to reduce to 2D (decision boundaries)\")\n print(\" - Perfect for comparing Linear, RBF, and Polynomial kernels!\")\nprint(\" - Perfect for GDI cyber threat detection applications!\")\nexcept FileNotFoundError:\n print(\"\\n\u274c Error: CICIDS2017 dataset not found!\")\nprint(\" Please ensure 'cicids2017.csv' is in '../../datasets/raw/'\")\nprint(\" Or download from: https://www.unb.ca/cic/datasets/ids-2017.html\")\nraise\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_full = # File not found: ../../datasets/raw/cicids2017.csv\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/04_knn.ipynb",
      "status": "failed",
      "execution_time": 0.5845270156860352,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build KNN classification models import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.neighbors import KNeighborsClassifier # KNN classifier\nfrom sklearn.preprocessing import StandardScaler # CRITICAL for KNN! Must scale features\nfrom sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda Key KNN Concepts:\")\nprint(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\nprint(\" - K parameter: Number of neighbors to consider (critical hyperparameter)\")\nprint(\" - Distance metrics: Euclidean (default), Manhattan, etc.\")\nprint(\" - Lazy learning: No training phase, just prediction\")\nprint(\"\\n \u26a0\ufe0f IMPORTANT: KNN requires feature scaling! Always use StandardScaler!\")\nprint(\" \ud83d\udca1 Why? Distance calculations are affected by feature scales!\")\nprint(\"\\n \ud83c\udfaf GDI Theme: Financial Investigations & Administrative Crimes Detection\")\nprint(\" \ud83d\udca1 We'll use credit card fraud data to detect fraudulent transactions!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us build KNN classification models import pandas as pd # For data manipulation\nimport numpy as np # For numerical operations\nimport matplotlib.pyplot as plt # For visualizations\nimport seaborn as sns # For beautiful plots\nfrom sklearn.model_selection import train_test_split # For splitting data\nfrom sklearn.neighbors import KNeighborsClassifier # KNN classifier\nfrom sklearn.preprocessing import StandardScaler # CRITICAL for KNN! Must scale features\nfrom sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda Key KNN Concepts:\")\nprint(\" - KNeighborsClassifier: KNN classifier (finds K nearest neighbors)\")\nprint(\" - K parameter: Number of neighbors to consider (critical hyperparameter)\")\nprint(\" - Distance metrics: Euclidean (default), Manhattan, etc.\")\nprint(\" - Lazy learning: No training phase, just prediction\")\nprint(\"\\n \u26a0\ufe0f IMPORTANT: KNN requires feature scaling! Always use StandardScaler!\")\nprint(\" \ud83d\udca1 Why? Distance calculations are affected by feature scales!\")\nprint(\"\\n \ud83c\udfaf GDI Theme: Financial Investigations & Administrative Crimes Detection\")\nprint(\" \ud83d\udca1 We'll use credit card fraud data to detect fraudulent transactions!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, # Classification accuracy classification_report, # Comprehensive metrics confusion_matrix, # Confusion matrix roc_auc_score, # AUC scoreroc_curve # ROC curve)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/05_random_forest_naive_bayes.ipynb",
      "status": "failed",
      "execution_time": 1.4706718921661377,
      "error": "An error occurred while executing the following cell:\n------------------\n# Generate classification dataset\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n                          n_redundant=5, n_classes=2, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\nrf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\nrf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\nrf_pred_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"=\" * 60)\nprint(\"Random Forest Classifier:\")\nprint(\"=\" * 60)\nprint(f\"Accuracy: {rf.score(X_test, y_test):.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, rf_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, rf_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Generate classification dataset\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n                          n_redundant=5, n_classes=2, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest Classifier_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\nrf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\nrf_pred = rf.predict(X_test)_rf_pred_proba =  rf.predict_proba(X_test)[:, 1]\nrf_pred_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"=\" * 60)\nprint(\"Random Forest Classifier:\")\nprint(\"=\" * 60)\nprint(f\"Accuracy: {rf.score(X_test, y_test):.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, rf_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, rf_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    rf.fit(X_train, y_train)_rf_pred =  rf.predict(X_test)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/06_ensemble_methods_bagging_boosting.ipynb",
      "status": "failed",
      "execution_time": 0.7291572093963623,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.datasets \nimport make_classification\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.tree \nimport DecisionTreeClassifier\nfrom sklearn.ensemble \nimport BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics \nimport accuracy_score, classification_report_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.datasets \nimport make_classification\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.tree \nimport DecisionTreeClassifier\nfrom sklearn.ensemble \nimport BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics \nimport accuracy_score, classification_report_\nprint(\"\u2705 Libraries imported successfully!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/07_svm_kernels_comparison.ipynb",
      "status": "passed",
      "execution_time": 1.6096069812774658,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/08_classification_evaluation_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.6148033142089844,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/evaluating_classification_models_using_confusion_matrices_roc_curves_and_analyzi.ipynb",
      "status": "failed",
      "execution_time": 0.6507809162139893,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/examples/using_svm_with_different_kernels_linear_polynomial_rbf_to_handle_complex_classif.ipynb",
      "status": "failed",
      "execution_time": 0.7470860481262207,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "example"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.7258210182189941,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, classification_report,\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\nfrom sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (accuracy_score, classification_report,\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_02_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 1.8734049797058105,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 2: Logistic Regression Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\nInstructions:\n1. Load the provided dataset_2. Train a Logistic Regression classifier_3. Calculate and display all classification metrics (accuracy, precision, recall, F1)\n4. Create and visualize a confusion matrix_5. Create and visualize an ROC curve_6. Experiment with different thresholds_7. Handle class imbalance using class weights\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_curve, roc_auc_score, classification_report\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=1000, n_features=10,\n    n_informative=6,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20, use stratify)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Scale the features (important for logistic regression!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Scale features\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 3: Train a Logistic Regression model (default parameters)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train Logistic Regression model\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 4: Make predictions and calculate metrics_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Calculate classification metrics\")\nprint(\"=\"*60)\n# Calculate: accuracy, precision, recall, F1-score\n# Your code here...\n\n# Task 5: Create and visualize confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create confusion matrix and visualize it with seaborn heatmap\n# Your code here...\n\n# Task 6: Get prediction probabilities and create ROC curve_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: ROC Curve\")\nprint(\"=\"*60)\n# Get probabilities using .predict_proba()\n# Calculate ROC curve (fpr, tpr, thresholds)\n# Calculate AUC score\n# Plot ROC curve with AUC value\n# Your code here...\n\n# Task 7: Train model with class weights to handle imbalance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Handle class imbalance with class weights\")\nprint(\"=\"*60)\n# Train new model with class_weight='balanced'\n# Compare metrics with previous model\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     27\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     28\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 35\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 2: Logistic Regression Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\nInstructions:\n1. Load the provided dataset_2. Train a Logistic Regression classifier_3. Calculate and display all classification metrics (accuracy, precision, recall, F1)\n4. Create and visualize a confusion matrix_5. Create and visualize an ROC curve_6. Experiment with different thresholds_7. Handle class imbalance using class weights\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_curve, roc_auc_score, classification_report\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=1000, n_features=10,\n    n_informative=6,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data into train and test sets (80/20, use stratify)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Scale the features (important for logistic regression!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Scale features\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 3: Train a Logistic Regression model (default parameters)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train Logistic Regression model\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 4: Make predictions and calculate metrics_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Calculate classification metrics\")\nprint(\"=\"*60)\n# Calculate: accuracy, precision, recall, F1-score\n# Your code here...\n\n# Task 5: Create and visualize confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create confusion matrix and visualize it with seaborn heatmap\n# Your code here...\n\n# Task 6: Get prediction probabilities and create ROC curve_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: ROC Curve\")\nprint(\"=\"*60)\n# Get probabilities using .predict_proba()\n# Calculate ROC curve (fpr, tpr, thresholds)\n# Calculate AUC score\n# Plot ROC curve with AUC value\n# Your code here...\n\n# Task 7: Train model with class weights to handle imbalance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Handle class imbalance with class weights\")\nprint(\"=\"*60)\n# Train new model with class_weight='balanced'\n# Compare metrics with previous model\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     27\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     28\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 35\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_03_svm.ipynb",
      "status": "failed",
      "execution_time": 1.729133129119873,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 3: Support Vector Machine (SVM) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)\n\nInstructions:\n1. Load the provided dataset_2. Train SVM models with different kernels (Linear, RBF, Polynomial)\n3. Compare their performance_4. Tune hyperparameters (C and gamma for RBF)\n5. Visualize decision boundaries (if 2D) or compare metrics_6. Find the best kernel and hyperparameters\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score\n)\n\n# Generate sample classification data_np.random.seed(123)\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=500, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data and scale features (CRITICAL for SVM!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split and scale data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Linear SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Linear SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='linear', C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Train RBF SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train RBF SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='rbf', C=1.0, gamma='scale'\n# Evaluate and print metrics\n# Your code here...\n\n# Task 4: Train Polynomial SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train Polynomial SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='poly', degree=3, C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 5: Compare all three kernels_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare kernels\")\nprint(\"=\"*60)\n# Create a comparison table or visualization\n# Show which kernel performs best\n# Your code here...\n\n# Task 6: Tune C parameter for RBF kernel_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Tune C parameter for RBF\")\nprint(\"=\"*60)\n# Try different C values: [0.1, 1.0, 10.0, 100.0]\n# Find the best C value\n# Your code here...\n\n# Task 7: (Optional) Tune gamma parameter for RBF_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: (Optional) Tune gamma parameter\")\nprint(\"=\"*60)\n# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]\n# Find the best gamma value\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     28\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 3: Support Vector Machine (SVM) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)\n\nInstructions:\n1. Load the provided dataset_2. Train SVM models with different kernels (Linear, RBF, Polynomial)\n3. Compare their performance_4. Tune hyperparameters (C and gamma for RBF)\n5. Visualize decision boundaries (if 2D) or compare metrics_6. Find the best kernel and hyperparameters\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score\n)\n\n# Generate sample classification data_np.random.seed(123)\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=500, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data and scale features (CRITICAL for SVM!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split and scale data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Linear SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Linear SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='linear', C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Train RBF SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train RBF SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='rbf', C=1.0, gamma='scale'\n# Evaluate and print metrics\n# Your code here...\n\n# Task 4: Train Polynomial SVM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train Polynomial SVM\")\nprint(\"=\"*60)\n# Train SVM with kernel='poly', degree=3, C=1.0\n# Evaluate and print metrics\n# Your code here...\n\n# Task 5: Compare all three kernels_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare kernels\")\nprint(\"=\"*60)\n# Create a comparison table or visualization\n# Show which kernel performs best\n# Your code here...\n\n# Task 6: Tune C parameter for RBF kernel_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Tune C parameter for RBF\")\nprint(\"=\"*60)\n# Try different C values: [0.1, 1.0, 10.0, 100.0]\n# Find the best C value\n# Your code here...\n\n# Task 7: (Optional) Tune gamma parameter for RBF_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: (Optional) Tune gamma parameter\")\nprint(\"=\"*60)\n# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]\n# Find the best gamma value\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 3 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     28\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/exercises/exercise_04_knn.ipynb",
      "status": "failed",
      "execution_time": 1.55259108543396,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)\n\nInstructions:\n1. Load the provided dataset_2. Scale the features (CRITICAL for KNN!)\n3. Train KNN models with different K values_4. Find the optimal K value using validation_5. Evaluate the final model with optimal K_6. Compare KNN with and without feature scaling (demonstrate importance)\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=800, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Demonstrate why scaling is critical_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Compare KNN with and without scaling\")\nprint(\"=\"*60)\n# Train KNN WITHOUT scaling (use original data)\n# Train KNN WITH scaling (use StandardScaler)\n# Compare accuracies - show the difference!\n# Your code here...\n\n# Task 3: Find optimal K value_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Find optimal K value\")\nprint(\"=\"*60)\n# Test K values from 1 to 30 (odd numbers only)\n# Plot K vs Accuracy (both train and test)\n# Find the K with best test accuracy\n# Your code here...\n\n# Task 4: Train final KNN model with optimal K_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train final model with optimal K\")\nprint(\"=\"*60)\n# Train KNN with the best K value found\n# Evaluate with all metrics (accuracy, precision, recall, F1)\n# Your code here...\n\n# Task 5: Create confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create and visualize confusion matrix\n# Your code here...\n\n# Task 6: (Optional) Compare KNN with other classifiers_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: (Optional) Compare with other classifiers\")\nprint(\"=\"*60)\n# Compare KNN with Logistic Regression or Decision Tree\n# Show which performs better on this dataset\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 4 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     26\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     27\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\n\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)\n\nInstructions:\n1. Load the provided dataset_2. Scale the features (CRITICAL for KNN!)\n3. Train KNN models with different K values_4. Find the optimal K value using validation_5. Evaluate the final model with optimal K_6. Compare KNN with and without feature scaling (demonstrate importance)\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix\n)\nfrom sklearn.datasets import make_classification\n\n# Generate sample classification data_np.random.seed(123)\nX, y = make_classification(\n    n_samples=800, n_features=8,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=2,\n    random_state=123\n)\n\ndf = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Demonstrate why scaling is critical_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Compare KNN with and without scaling\")\nprint(\"=\"*60)\n# Train KNN WITHOUT scaling (use original data)\n# Train KNN WITH scaling (use StandardScaler)\n# Compare accuracies - show the difference!\n# Your code here...\n\n# Task 3: Find optimal K value_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Find optimal K value\")\nprint(\"=\"*60)\n# Test K values from 1 to 30 (odd numbers only)\n# Plot K vs Accuracy (both train and test)\n# Find the K with best test accuracy\n# Your code here...\n\n# Task 4: Train final KNN model with optimal K_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train final model with optimal K\")\nprint(\"=\"*60)\n# Train KNN with the best K value found\n# Evaluate with all metrics (accuracy, precision, recall, F1)\n# Your code here...\n\n# Task 5: Create confusion matrix_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Confusion Matrix\")\nprint(\"=\"*60)\n# Create and visualize confusion matrix\n# Your code here...\n\n# Task 6: (Optional) Compare KNN with other classifiers_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: (Optional) Compare with other classifiers\")\nprint(\"=\"*60)\n# Compare KNN with Logistic Regression or Decision Tree\n# Show which performs better on this dataset\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 4 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(\n\u001b[1;32m     26\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     27\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)])\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5223278999328613,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom from sklearn.tree import train_test_split\nfrom from sklearn.ensemble import DecisionTreeClassifier\nfrom from sklearn.metrics import RandomForestClassifier_from(accuracy_score, classification_report,from sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom from sklearn.tree import train_test_split\nfrom from sklearn.ensemble import DecisionTreeClassifier\nfrom from sklearn.metrics import RandomForestClassifier_from(accuracy_score, classification_report,from sklearn.datasets import make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_02_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.7465178966522217,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 2: Logistic Regression Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064aInstructions:1. Load the provided dataset2. Train a Logistic Regression classifier3. Calculate and display all classification metrics (accuracy, precision, recall, F1)4. Create and visualize a confusion matrix5. Create and visualize an ROC curve6. Experiment with different thresholds7. Handle class imbalance using class weightsDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=1000,    n_features=10,    n_informative=6,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Calculate classification metrics\")print(\"=\"*60)# Calculate: accuracy, precision, recall, F1-score# Your code here...# Task 5: Create and visualize confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create confusion matrix and visualize it with seaborn heatmap# Your code here...# Task 6: Get prediction probabilities and create ROC curve\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: ROC Curve\")print(\"=\"*60)# Get probabilities using .predict_proba()# Calculate ROC curve (fpr, tpr, thresholds)# Calculate AUC score# Plot ROC curve with AUC value# Your code here...# Task 7: Train model with class weights to handle imbalance\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Handle class imbalance with class weights\")print(\"=\"*60)# Train new model with class_weight='balanced'# Compare metrics with previous model# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 2: Logistic Regression Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064aInstructions:1. Load the provided dataset2. Train a Logistic Regression classifier3. Calculate and display all classification metrics (accuracy, precision, recall, F1)4. Create and visualize a confusion matrix5. Create and visualize an ROC curve6. Experiment with different thresholds7. Handle class imbalance using class weightsDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=1000,    n_features=10,    n_informative=6,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data into train and test sets (80/20, use stratify)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Scale the features (important for logistic regression!)print(\"\\n\" + \"=\"*60)print(\"Task 2: Scale features\")print(\"=\"*60)# Your code here...# Task 3: Train a Logistic Regression model (default parameters)print(\"\\n\" + \"=\"*60)print(\"Task 3: Train Logistic Regression model\")print(\"=\"*60)# Your code here...# Task 4: Make predictions and calculate metrics\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Calculate classification metrics\")print(\"=\"*60)# Calculate: accuracy, precision, recall, F1-score# Your code here...# Task 5: Create and visualize confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create confusion matrix and visualize it with seaborn heatmap# Your code here...# Task 6: Get prediction probabilities and create ROC curve\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: ROC Curve\")print(\"=\"*60)# Get probabilities using .predict_proba()# Calculate ROC curve (fpr, tpr, thresholds)# Calculate AUC score# Plot ROC curve with AUC value# Your code here...# Task 7: Train model with class weights to handle imbalance\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Handle class imbalance with class weights\")print(\"=\"*60)# Train new model with class_weight='balanced'# Compare metrics with previous model# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_curve, roc_auc_score, classification_report)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_03_svm.ipynb",
      "status": "failed",
      "execution_time": 0.8091080188751221,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 3: Support Vector Machine (SVM) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)Instructions:1. Load the provided dataset2. Train SVM models with different kernels (Linear, RBF, Polynomial)3. Compare their performance4. Tune hyperparameters (C and gamma for RBF)5. Visualize decision boundaries (if 2D)\nor compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score)\n# Generate sample classification datanp.random.seed(123)from sklearn.datasets import make_classificationX, y = make_classification(    n_samples=500,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Train Linear SVM\")print(\"=\"*60)# Train SVM with kernel='linear', C=1.0# Evaluate and print metrics# Your code here...# Task 3: Train RBF SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train RBF SVM\")print(\"=\"*60)# Train SVM with kernel='rbf', C=1.0, gamma='scale'# Evaluate and print metrics# Your code here...# Task 4: Train Polynomial SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train Polynomial SVM\")print(\"=\"*60)# Train SVM with kernel='poly', degree=3, C=1.0# Evaluate and print metrics# Your code here...# Task 5: Compare all three kernels\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare kernels\")print(\"=\"*60)# Create a comparison table or visualization# Show which kernel performs best# Your code here...# Task 6: Tune C parameter for RBF kernel\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Tune C parameter for RBF\")print(\"=\"*60)# Try different C values: [0.1, 1.0, 10.0, 100.0]# Find the best C value# Your code here...# Task 7: (Optional) Tune gamma parameter for RBF\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: (Optional) Tune gamma parameter\")print(\"=\"*60)# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]# Find the best gamma value# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    or compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\u001b[0m\n\u001b[0m                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 18)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 3: Support Vector Machine (SVM) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 3: \u0645\u0645\u0627\u0631\u0633\u0629 \u0622\u0644\u0627\u062a \u0646\u0627\u0642\u0644\u0627\u062a \u0627\u0644\u062f\u0639\u0645 (SVM)Instructions:1. Load the provided dataset2. Train SVM models with different kernels (Linear, RBF, Polynomial)3. Compare their performance4. Tune hyperparameters (C and gamma for RBF)5. Visualize decision boundaries (if 2D)\nor compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score)\n# Generate sample classification datanp.random.seed(123)from sklearn.datasets import make_classificationX, y = make_classification(    n_samples=500,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data and scale features (CRITICAL for SVM!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Split and scale data\")print(\"=\"*60)# Your code here...# Task 2: Train Linear SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Train Linear SVM\")print(\"=\"*60)# Train SVM with kernel='linear', C=1.0# Evaluate and print metrics# Your code here...# Task 3: Train RBF SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train RBF SVM\")print(\"=\"*60)# Train SVM with kernel='rbf', C=1.0, gamma='scale'# Evaluate and print metrics# Your code here...# Task 4: Train Polynomial SVM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train Polynomial SVM\")print(\"=\"*60)# Train SVM with kernel='poly', degree=3, C=1.0# Evaluate and print metrics# Your code here...# Task 5: Compare all three kernels\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare kernels\")print(\"=\"*60)# Create a comparison table or visualization# Show which kernel performs best# Your code here...# Task 6: Tune C parameter for RBF kernel\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Tune C parameter for RBF\")print(\"=\"*60)# Try different C values: [0.1, 1.0, 10.0, 100.0]# Find the best C value# Your code here...# Task 7: (Optional) Tune gamma parameter for RBF\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: (Optional) Tune gamma parameter\")print(\"=\"*60)# Try different gamma values: ['scale', 'auto', 0.01, 0.1, 1.0]# Find the best gamma value# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 3 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 3!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    or compare metrics6. Find the best kernel and hyperparametersDataset: Binary classification dataset\"\"\"\u001b[0m\n\u001b[0m                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 18)\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit3-classification/solutions/solution_04_knn.ipynb",
      "status": "failed",
      "execution_time": 0.7980737686157227,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)Instructions:1. Load the provided dataset2. Scale the features (CRITICAL for KNN!)3. Train KNN models with different K values4. Find the optimal K value using validation5. Evaluate the final model with optimal K6. Compare KNN with and without feature scaling (demonstrate importance)Dataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=800,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Demonstrate why scaling is critical\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Compare KNN with and without scaling\")print(\"=\"*60)# Train KNN WITHOUT scaling (use original data)# Train KNN WITH scaling (use StandardScaler)# Compare accuracies - show the difference!# Your code here...# Task 3: Find optimal K value\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Find optimal K value\")print(\"=\"*60)# Test K values from 1 to 30 (odd numbers only)# Plot K vs Accuracy (both train and test)# Find the K with best test accuracy# Your code here...# Task 4: Train final KNN model with optimal K\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train final model with optimal K\")print(\"=\"*60)# Train KNN with the best K value found# Evaluate with all metrics (accuracy, precision, recall, F1)# Your code here...# Task 5: Create confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create and visualize confusion matrix# Your code here...# Task 6: (Optional) Compare KNN with other classifiers\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: (Optional) Compare with other classifiers\")print(\"=\"*60)# Compare KNN with Logistic Regression or Decision Tree# Show which performs better on this dataset# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 4 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 3 - Exercise 4: K-Nearest Neighbors (KNN) Practice\u062a\u0642\u0646\u064a\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u062a\u0642\u062f\u0645\u0629 - \u062a\u0645\u0631\u064a\u0646 4: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062c\u064a\u0631\u0627\u0646 \u0627\u0644\u0623\u0642\u0631\u0628 (KNN)Instructions:1. Load the provided dataset2. Scale the features (CRITICAL for KNN!)3. Train KNN models with different K values4. Find the optimal K value using validation5. Evaluate the final model with optimal K6. Compare KNN with and without feature scaling (demonstrate importance)Dataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\n# Generate sample classification datanp.random.seed(123)X, y = make_classification(    n_samples=800,    n_features=8,    n_informative=5,    n_redundant=2,    n_classes=2,   random_state=123)df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(8)])df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Demonstrate why scaling is critical\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Compare KNN with and without scaling\")print(\"=\"*60)# Train KNN WITHOUT scaling (use original data)# Train KNN WITH scaling (use StandardScaler)# Compare accuracies - show the difference!# Your code here...# Task 3: Find optimal K value\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Find optimal K value\")print(\"=\"*60)# Test K values from 1 to 30 (odd numbers only)# Plot K vs Accuracy (both train and test)# Find the K with best test accuracy# Your code here...# Task 4: Train final KNN model with optimal K\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train final model with optimal K\")print(\"=\"*60)# Train KNN with the best K value found# Evaluate with all metrics (accuracy, precision, recall, F1)# Your code here...# Task 5: Create confusion matrix\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Confusion Matrix\")print(\"=\"*60)# Create and visualize confusion matrix# Your code here...# Task 6: (Optional) Compare KNN with other classifiers\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: (Optional) Compare with other classifiers\")print(\"=\"*60)# Compare KNN with Logistic Regression or Decision Tree# Show which performs better on this dataset# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 4 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 4!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix)from sklearn.datasets import make_classification\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "Course 04/unit4-clustering/examples/01_kmeans_clustering.ipynb",
      "status": "failed",
      "execution_time": 1.6647508144378662,
      "error": "An error occurred while executing the following cell:\n------------------\n# Load real-world US Crime Statistics dataset\n# This is REAL state crime data for Internal Intelligence analysis\n# K-Means will identify states with similar crime patterns!\n\nprint(\"\\n\ud83d\udce5 Loading US Crime Statistics Dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062c\u0631\u064a\u0645\u0629 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\ntry:\n # Load crime statistics dataset\n df = # File not found: ../../datasets/raw/crime_statistics.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\u2705 Real-world Crime Statistics dataset loaded!\")\nprint(f\" \ud83d\udcca This is REAL crime data (UCI Communities and Crime dataset)\")\n print(f\" \ud83d\udcc8 Contains {len(df)} communities with 4 crime metrics\")\n print(f\" \ud83c\udfaf Features: Murder, Assault, UrbanPop, Rape\")\nprint(f\" \ud83d\udca1 GDI Application: Internal Intelligence - identifying communities with similar crime patterns\")\nprint(f\"\\n\ud83d\udd0d Important: Understanding Unsupervised Learning\")\nprint(\" \u26a0\ufe0f The 'State' column is NOT a label - it's just an identifier (like row ID)\")\n print(\" \u2705 Unsupervised learning means: NO TARGET VARIABLE (no 'correct' clusters)\")\n print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\nfor clustering\")\n print(\" \u2705 The State/Community names are EXCLUDED from clustering (just for reference)\")\n print(\" \u2705 Clustering finds patterns WITHOUT knowing the 'correct' answer\")\nprint(\"\\n\ud83d\udcca Dataset Structure:\")\nprint(\" - State/Community: Identifier only (NOT used for clustering)\")\n print(\" - Murder, Assault, UrbanPop, Rape: Features used for clustering\")\nprint(\" - NO TARGET VARIABLE: This is why it's unsupervised!\")\nprint(\" - Clustering will discover groups automatically (no labels to learn from)\")\n \n # Prepare features for clustering\n # IMPORTANT: Exclude State column - it's just an identifier, NOT a feature or label!\n # In unsupervised learning:\n # - NO labels/targets (no \"correct\" clusters to learn)\n # - Only features (Murder, Assault, UrbanPop, Rape)\n # - State column is just for identification (like row numbers)\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n X_all = df[feature_cols].values # Only use the 4 features, exclude State column\n \n # Use 2 features for 2D visualization (Murder, Assault - most important crime metrics)\n X_2d = df[['Murder', 'Assault']].values\n \n print(f\"\\n\ud83d\udcca Data Preparation:\")\nprint(f\" - X_2d: 2 features for visualization (Murder, Assault)\")\n print(f\" - X_all: All 4 features for clustering (Murder, Assault, UrbanPop, Rape)\")\n print(f\" - We'll use X_all for clustering, X_2d for visualization\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Please ensure 'crime_statistics.csv' is in '../../datasets/raw/'\")\nprint(\" Creating minimal structure for demonstration...\")\n # Fallback: Create minimal structure\n X_all = np.random.randn(50, 4)\n X_2d = X_all[:, [0, 1]]\n df = pd.DataFrame(X_all, columns=['Murder', 'Assault', 'UrbanPop', 'Rape'])\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n print(\" \u26a0\ufe0f Using synthetic data - please download the real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 21)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Load real-world US Crime Statistics dataset\n# This is REAL state crime data for Internal Intelligence analysis\n# K-Means will identify states with similar crime patterns!\n\nprint(\"\\n\ud83d\udce5 Loading US Crime Statistics Dataset...\")\nprint(\"\u062a\u062d\u0645\u064a\u0644 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0625\u062d\u0635\u0627\u0626\u064a\u0627\u062a \u0627\u0644\u062c\u0631\u064a\u0645\u0629 \u0627\u0644\u0623\u0645\u0631\u064a\u0643\u064a\u0629...\")\ntry:\n # Load crime statistics dataset\n df = # File not found: ../../datasets/raw/crime_statistics.csv\n# Using synthetic data instead\npd.DataFrame({'col1': range(100), 'col2': range(100, 200)})\n \n print(f\"\\n\u2705 Real-world Crime Statistics dataset loaded!\")\nprint(f\" \ud83d\udcca This is REAL crime data (UCI Communities and Crime dataset)\")\n print(f\" \ud83d\udcc8 Contains {len(df)} communities with 4 crime metrics\")\n print(f\" \ud83c\udfaf Features: Murder, Assault, UrbanPop, Rape\")\nprint(f\" \ud83d\udca1 GDI Application: Internal Intelligence - identifying communities with similar crime patterns\")\nprint(f\"\\n\ud83d\udd0d Important: Understanding Unsupervised Learning\")\nprint(\" \u26a0\ufe0f The 'State' column is NOT a label - it's just an identifier (like row ID)\")\n print(\" \u2705 Unsupervised learning means: NO TARGET VARIABLE (no 'correct' clusters)\")\n print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\nfor clustering\")\n print(\" \u2705 The State/Community names are EXCLUDED from clustering (just for reference)\")\n print(\" \u2705 Clustering finds patterns WITHOUT knowing the 'correct' answer\")\nprint(\"\\n\ud83d\udcca Dataset Structure:\")\nprint(\" - State/Community: Identifier only (NOT used for clustering)\")\n print(\" - Murder, Assault, UrbanPop, Rape: Features used for clustering\")\nprint(\" - NO TARGET VARIABLE: This is why it's unsupervised!\")\nprint(\" - Clustering will discover groups automatically (no labels to learn from)\")\n \n # Prepare features for clustering\n # IMPORTANT: Exclude State column - it's just an identifier, NOT a feature or label!\n # In unsupervised learning:\n # - NO labels/targets (no \"correct\" clusters to learn)\n # - Only features (Murder, Assault, UrbanPop, Rape)\n # - State column is just for identification (like row numbers)\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n X_all = df[feature_cols].values # Only use the 4 features, exclude State column\n \n # Use 2 features for 2D visualization (Murder, Assault - most important crime metrics)\n X_2d = df[['Murder', 'Assault']].values\n \n print(f\"\\n\ud83d\udcca Data Preparation:\")\nprint(f\" - X_2d: 2 features for visualization (Murder, Assault)\")\n print(f\" - X_all: All 4 features for clustering (Murder, Assault, UrbanPop, Rape)\")\n print(f\" - We'll use X_all for clustering, X_2d for visualization\")\nexcept FileNotFoundError:\n print(\"\\n\u26a0\ufe0f Dataset file not found!\")\nprint(\" Please ensure 'crime_statistics.csv' is in '../../datasets/raw/'\")\nprint(\" Creating minimal structure for demonstration...\")\n # Fallback: Create minimal structure\n X_all = np.random.randn(50, 4)\n X_2d = X_all[:, [0, 1]]\n df = pd.DataFrame(X_all, columns=['Murder', 'Assault', 'UrbanPop', 'Rape'])\nfeature_cols = ['Murder', 'Assault', 'UrbanPop', 'Rape']\n print(\" \u26a0\ufe0f Using synthetic data - please download the real dataset!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" \u2705 We ONLY use the 4 features (Murder, Assault, UrbanPop, Rape)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 21)\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/02_hierarchical_clustering.ipynb",
      "status": "passed",
      "execution_time": 3.1814050674438477,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/03_pca.ipynb",
      "status": "passed",
      "execution_time": 2.766376256942749,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/04_lda_tsne_umap.ipynb",
      "status": "failed",
      "execution_time": 0.7292580604553223,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets \nimport make_classification, load_iris\nfrom sklearn.discriminant_analysis \nimport LinearDiscriminantAnalysis\nfrom sklearn.decomposition \nimport PCA\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom sklearn.metrics \nimport accuracy_score\n\n# Try importing t-SNE and UMAP\ntry:\n    from sklearn.manifold \nimport TSNE_HAS_TSNE = True\nexcept ImportError:\n    HAS_TSNE = False_\nprint(\"\u26a0\ufe0f  t-SNE not available (install scikit-learn)\")\n\ntry:\n    import umap_HAS_UMAP = True\nexcept ImportError:\n    HAS_UMAP = False_\nprint(\"\u26a0\ufe0f  UMAP not available (install with: pip install umap-learn)\")\n\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets \nimport make_classification, load_iris\nfrom sklearn.discriminant_analysis \nimport LinearDiscriminantAnalysis\nfrom sklearn.decomposition \nimport PCA\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom sklearn.metrics \nimport accuracy_score\n\n# Try importing t-SNE and UMAP\ntry:\n    from sklearn.manifold \nimport TSNE_HAS_TSNE = True\nexcept ImportError:\n    HAS_TSNE = False_\nprint(\"\u26a0\ufe0f  t-SNE not available (install scikit-learn)\")\n\ntry:\n    import umap_HAS_UMAP = True\nexcept ImportError:\n    HAS_UMAP = False_\nprint(\"\u26a0\ufe0f  UMAP not available (install with: pip install umap-learn)\")\n\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/05_elbow_method_silhouette_score.ipynb",
      "status": "failed",
      "execution_time": 0.7242450714111328,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.metrics \nimport silhouette_score\nfrom sklearn.datasets \nimport make_blobs_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nElbow Method and Silhouette Score\")\nprint(\"=\" * 60)\n\nprint(\"\\nElbow Method:\")\nprint(\"  - Plot within-cluster sum of squares (WCSS)\")\nprint(\"  - Look for 'elbow' in the curve\")\nprint(\"  - Indicates optimal k\")\n\nprint(\"\\nSilhouette Score:\")\nprint(\"  - Measures cluster quality\")\nprint(\"  - Range: -1 to 1\")\nprint(\"  - Higher is better\")\nprint(\"  - Compare across different k values\")\n\nprint(\"\\n\u2705 Cluster optimization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.metrics \nimport silhouette_score\nfrom sklearn.datasets \nimport make_blobs_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nElbow Method and Silhouette Score\")\nprint(\"=\" * 60)\n\nprint(\"\\nElbow Method:\")\nprint(\"  - Plot within-cluster sum of squares (WCSS)\")\nprint(\"  - Look for 'elbow' in the curve\")\nprint(\"  - Indicates optimal k\")\n\nprint(\"\\nSilhouette Score:\")\nprint(\"  - Measures cluster quality\")\nprint(\"  - Range: -1 to 1\")\nprint(\"  - Higher is better\")\nprint(\"  - Compare across different k values\")\n\nprint(\"\\n\u2705 Cluster optimization concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/06_evaluating_clustering_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.5448529720306396,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nfrom sklearn.metrics \nimport davies_bouldin_score, calinski_harabasz_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nEvaluating Clustering Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nClustering Metrics:\")\nprint(\"  - Silhouette Score: Cohesion and separation\")\nprint(\"  - Adjusted Rand Index: Agreement with ground truth\")\nprint(\"  - Normalized Mutual Information: Information shared\")\nprint(\"  - Davies-Bouldin Index: Average similarity ratio\")\nprint(\"  - Calinski-Harabasz Index: Ratio of between/within cluster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Silhouette: General quality assessment\")\nprint(\"  - ARI/NMI: When ground truth available\")\nprint(\"  - DB Index: Lower is better\")\nprint(\"  - CH Index: Higher is better\")\n\nprint(\"\\n\u2705 Clustering evaluation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.metrics \nimport silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nfrom sklearn.metrics \nimport davies_bouldin_score, calinski_harabasz_score_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nEvaluating Clustering Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nClustering Metrics:\")\nprint(\"  - Silhouette Score: Cohesion and separation\")\nprint(\"  - Adjusted Rand Index: Agreement with ground truth\")\nprint(\"  - Normalized Mutual Information: Information shared\")\nprint(\"  - Davies-Bouldin Index: Average similarity ratio\")\nprint(\"  - Calinski-Harabasz Index: Ratio of between/within cluster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Silhouette: General quality assessment\")\nprint(\"  - ARI/NMI: When ground truth available\")\nprint(\"  - DB Index: Lower is better\")\nprint(\"  - CH Index: Higher is better\")\n\nprint(\"\\n\u2705 Clustering evaluation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/evaluating_clustering_models_using_appropriate_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.8112480640411377,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/examples/using_elbow_method_and_silhouette_score_to_determine_optimal_number_of_clusters.ipynb",
      "status": "failed",
      "execution_time": 0.6152141094207764,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "example"
    },
    {
      "path": "Course 04/unit4-clustering/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.5994229316711426,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.cluster import rom KMeans, AgglomerativeClusteringf\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster import rom KMeans, AgglomerativeClusteringf\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pltf\nfrom sklearn.cluster import rom KMeans, AgglomerativeClusteringf\nfrom sklearn.preprocessing import rom StandardScaler\nfrom sklearn.metrics import silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster import rom KMeans, AgglomerativeClusteringf\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit4-clustering/exercises/exercise_02_pca.ipynb",
      "status": "failed",
      "execution_time": 0.5483419895172119,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\n\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)\n\nInstructions:\n1. Load the provided dataset_2. Apply PCA to reduce dimensionality_3. Analyze explained variance_4. Choose optimal number of components_5. Visualize data in reduced dimensions_6. Compare original vs PCA-transformed data\n\nDataset: Multi-dimensional dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n\n# Load Iris dataset (4 features, 3 classes)\niris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\nX = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Features: {feature_names}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Scale the data (CRITICAL for PCA!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Scale data\")\nprint(\"=\"*60)\n# Use StandardScaler\n# Your code here...\n\n# Task 2: Apply PCA with all components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Apply PCA (all components)\")\nprint(\"=\"*60)\n# Create PCA object\n# Fit and transform the data\n# Your code here...\n\n# Task 3: Analyze explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Explained variance analysis\")\nprint(\"=\"*60)\n# Get explained_variance_ratio_ for each component\n# Calculate cumulative explained variance\n# Print: Each component's variance, cumulative variance\n# Your code here...\n\n# Task 4: Visualize explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Visualize explained variance\")\nprint(\"=\"*60)\n# Plot: Component number vs Explained variance\n# Plot: Component number vs Cumulative explained variance\n# Your code here...\n\n# Task 5: Reduce to 2D for visualization_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Reduce to 2D\")\nprint(\"=\"*60)\n# Apply PCA with n_components=2\n# Transform data to 2D\n# Visualize in 2D (color by original class labels)\n# Your code here...\n\n# Task 6: Find optimal number of components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Find optimal number of components\")\nprint(\"=\"*60)\n# Find number of components that explain 95% of variance\n# Find number of components that explain 99% of variance\n# Your code here...\n\n# Task 7: Compare original vs PCA-transformed_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Compare original vs PCA\")\nprint(\"=\"*60)\n# Show: Original has 4 features, PCA can reduce to 2-3\n# Show: PCA preserves most information with fewer features\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    iris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\n\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)\n\nInstructions:\n1. Load the provided dataset_2. Apply PCA to reduce dimensionality_3. Analyze explained variance_4. Choose optimal number of components_5. Visualize data in reduced dimensions_6. Compare original vs PCA-transformed data\n\nDataset: Multi-dimensional dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n\n# Load Iris dataset (4 features, 3 classes)\niris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\nX = iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Features: {feature_names}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Scale the data (CRITICAL for PCA!)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Scale data\")\nprint(\"=\"*60)\n# Use StandardScaler\n# Your code here...\n\n# Task 2: Apply PCA with all components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Apply PCA (all components)\")\nprint(\"=\"*60)\n# Create PCA object\n# Fit and transform the data\n# Your code here...\n\n# Task 3: Analyze explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Explained variance analysis\")\nprint(\"=\"*60)\n# Get explained_variance_ratio_ for each component\n# Calculate cumulative explained variance\n# Print: Each component's variance, cumulative variance\n# Your code here...\n\n# Task 4: Visualize explained variance_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Visualize explained variance\")\nprint(\"=\"*60)\n# Plot: Component number vs Explained variance\n# Plot: Component number vs Cumulative explained variance\n# Your code here...\n\n# Task 5: Reduce to 2D for visualization_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Reduce to 2D\")\nprint(\"=\"*60)\n# Apply PCA with n_components=2\n# Transform data to 2D\n# Visualize in 2D (color by original class labels)\n# Your code here...\n\n# Task 6: Find optimal number of components_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Find optimal number of components\")\nprint(\"=\"*60)\n# Find number of components that explain 95% of variance\n# Find number of components that explain 99% of variance\n# Your code here...\n\n# Task 7: Compare original vs PCA-transformed_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Compare original vs PCA\")\nprint(\"=\"*60)\n# Show: Original has 4 features, PCA can reduce to 2-3\n# Show: PCA preserves most information with fewer features\n# Your code here... print(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    iris = load_iris()_X =  iris.data_y = iris.target_feature_names = iris.feature_names_df = pd.DataFrame(X, columns=feature_names)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit4-clustering/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7287170886993408,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.cluster import plt\nfrom KMeans, from sklearn.preprocessing import AgglomerativeClustering\nfrom from sklearn.metrics import StandardScaler\nfrom silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.cluster import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.cluster import plt\nfrom KMeans, from sklearn.preprocessing import AgglomerativeClustering\nfrom from sklearn.metrics import StandardScaler\nfrom silhouette_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.cluster import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "Course 04/unit4-clustering/solutions/solution_02_pca.ipynb",
      "status": "failed",
      "execution_time": 0.5995030403137207,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)Instructions:1. Load the provided dataset2. Apply PCA to reduce dimensionality3. Analyze explained variance4. Choose optimal number of components5. Visualize data in reduced dimensions6. Compare original vs PCA-transformed dataDataset: Multi-dimensional dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n# Load Iris dataset (4 features, 3 classes)iris = load_iris()X = iris.datay = iris.targetfeature_names = iris.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Apply PCA (all components)\")print(\"=\"*60)# Create PCA object# Fit and transform the data# Your code here...# Task 3: Analyze explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Explained variance analysis\")print(\"=\"*60)# Get explained_variance_ratio_ for each component# Calculate cumulative explained variance# Print: Each component's variance, cumulative variance# Your code here...# Task 4: Visualize explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Visualize explained variance\")print(\"=\"*60)# Plot: Component number vs Explained variance# Plot: Component number vs Cumulative explained variance# Your code here...# Task 5: Reduce to 2D for visualization\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Reduce to 2D\")print(\"=\"*60)# Apply PCA with n_components=2# Transform data to 2D# Visualize in 2D (color by original class labels)# Your code here...# Task 6: Find optimal number of components\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Find optimal number of components\")print(\"=\"*60)# Find number of components that explain 95% of variance# Find number of components that explain 99% of variance# Your code here...# Task 7: Compare original vs PCA-transformed\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Compare original vs PCA\")print(\"=\"*60)# Show: Original has 4 features, PCA can reduce to 2-3# Show: PCA preserves most information with fewer features# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 4 - Exercise 2: Principal Component Analysis (PCA) Practice\u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0648\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062a\u062d\u0644\u064a\u0644 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 (PCA)Instructions:1. Load the provided dataset2. Apply PCA to reduce dimensionality3. Analyze explained variance4. Choose optimal number of components5. Visualize data in reduced dimensions6. Compare original vs PCA-transformed dataDataset: Multi-dimensional dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\n# Load Iris dataset (4 features, 3 classes)iris = load_iris()X = iris.datay = iris.targetfeature_names = iris.feature_namesdf = pd.DataFrame(X, columns=feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\nprint(\"\\n\" + \"=\"*60)print(\"Task 2: Apply PCA (all components)\")print(\"=\"*60)# Create PCA object# Fit and transform the data# Your code here...# Task 3: Analyze explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Explained variance analysis\")print(\"=\"*60)# Get explained_variance_ratio_ for each component# Calculate cumulative explained variance# Print: Each component's variance, cumulative variance# Your code here...# Task 4: Visualize explained variance\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Visualize explained variance\")print(\"=\"*60)# Plot: Component number vs Explained variance# Plot: Component number vs Cumulative explained variance# Your code here...# Task 5: Reduce to 2D for visualization\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Reduce to 2D\")print(\"=\"*60)# Apply PCA with n_components=2# Transform data to 2D# Visualize in 2D (color by original class labels)# Your code here...# Task 6: Find optimal number of components\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Find optimal number of components\")print(\"=\"*60)# Find number of components that explain 95% of variance# Find number of components that explain 99% of variance# Your code here...# Task 7: Compare original vs PCA-transformed\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Compare original vs PCA\")print(\"=\"*60)# Show: Original has 4 features, PCA can reduce to 2-3# Show: PCA preserves most information with fewer features# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"Features: {feature_names}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Scale the data (CRITICAL for PCA!)print(\"\\n\" + \"=\"*60)print(\"Task 1: Scale data\")print(\"=\"*60)# Use StandardScaler# Your code here...# Task 2: Apply PCA with all components\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/01_grid_search.ipynb",
      "status": "passed",
      "execution_time": 54.50902795791626,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/02_boosting.ipynb",
      "status": "passed",
      "execution_time": 2.236504077911377,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/03_cross_validation_hyperparameter_tuning.ipynb",
      "status": "failed",
      "execution_time": 0.7341010570526123,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport cross_val_score, KFold\nfrom sklearn.model_selection \nimport validation_curve\nfrom sklearn.ensemble \nimport RandomForestClassifier_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nCross-Validation and Hyperparameter Tuning\")\nprint(\"=\" * 60)\n\nprint(\"\\nCross-Validation:\")\nprint(\"  - k-fold CV: Split into k folds\")\nprint(\"  - Stratified CV: Preserve class distribution\")\nprint(\"  - Leave-one-out: Each sample as test\")\n\nprint(\"\\nHyperparameter Tuning:\")\nprint(\"  - Grid Search: Exhaustive search\")\nprint(\"  - Random Search: Random sampling\")\nprint(\"  - Validation curves: Visualize parameter impact\")\nprint(\"  - Nested CV: Avoid overfitting\")\n\nprint(\"\\n\u2705 CV and hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport cross_val_score, KFold\nfrom sklearn.model_selection \nimport validation_curve\nfrom sklearn.ensemble \nimport RandomForestClassifier_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nCross-Validation and Hyperparameter Tuning\")\nprint(\"=\" * 60)\n\nprint(\"\\nCross-Validation:\")\nprint(\"  - k-fold CV: Split into k folds\")\nprint(\"  - Stratified CV: Preserve class distribution\")\nprint(\"  - Leave-one-out: Each sample as test\")\n\nprint(\"\\nHyperparameter Tuning:\")\nprint(\"  - Grid Search: Exhaustive search\")\nprint(\"  - Random Search: Random sampling\")\nprint(\"  - Validation curves: Visualize parameter impact\")\nprint(\"  - Nested CV: Avoid overfitting\")\n\nprint(\"\\n\u2705 CV and hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/04_grid_search_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.6661858558654785,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint, uniform_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nGrid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search over parameter grid\")\nprint(\"  - Guarantees finding best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling of parameters\")\nprint(\"  - More efficient for large spaces\")\nprint(\"  - Often finds good solutions faster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Grid Search: Small parameter spaces\")\nprint(\"  - Random Search: Large parameter spaces\")\nprint(\"  - Both use cross-validation\")\n\nprint(\"\\n\u2705 Search strategies concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint, uniform_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nGrid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search over parameter grid\")\nprint(\"  - Guarantees finding best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling of parameters\")\nprint(\"  - More efficient for large spaces\")\nprint(\"  - Often finds good solutions faster\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Grid Search: Small parameter spaces\")\nprint(\"  - Random Search: Large parameter spaces\")\nprint(\"  - Both use cross-validation\")\n\nprint(\"\\n\u2705 Search strategies concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/05_comparing_boosting_traditional_methods.ipynb",
      "status": "passed",
      "execution_time": 1.539806842803955,
      "error": null,
      "error_traceback": null,
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/applying_confusion_matrices_plotting_roc_curves_for_classification_models.ipynb",
      "status": "failed",
      "execution_time": 0.663074254989624,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/comparing_performance_with_traditional_methods.ipynb",
      "status": "failed",
      "execution_time": 0.6382091045379639,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/evaluating_models_on_real_datasets_using_performance_metrics.ipynb",
      "status": "failed",
      "execution_time": 0.7727587223052979,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/implementing_cross_validation_and_hyperparameter_tuning_using_python.ipynb",
      "status": "failed",
      "execution_time": 0.5344409942626953,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/implementing_final_project_applying_learned_techniques_on_real_dataset_evaluatin.ipynb",
      "status": "failed",
      "execution_time": 0.6661288738250732,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/tuning_models_for_optimal_performance_and_documenting_improvements.ipynb",
      "status": "failed",
      "execution_time": 0.6360650062561035,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/examples/using_grid_search_and_random_search_in_scikit_learn_to_optimize_parameters.ipynb",
      "status": "failed",
      "execution_time": 0.5328271389007568,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "example"
    },
    {
      "path": "Course 04/unit5-model-selection/exercises/exercise_01.ipynb",
      "status": "failed",
      "execution_time": 0.6501891613006592,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_reportf\nfrom sklearn.datasets import rom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import rom make_classification\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_reportf\nfrom sklearn.datasets import rom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import rom make_classification\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit5-model-selection/exercises/exercise_02_boosting.ipynb",
      "status": "failed",
      "execution_time": 1.9114019870758057,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Exercise 2: Boosting Algorithms Practice\n\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632\n\nInstructions:\n1. Load the provided dataset_2. Train XGBoost model (if available)\n3. Train LightGBM model (if available)\n4. Compare with Random Forest (bagging)\n5. Compare boosting algorithms with each other_6. Interpret feature importance_7. Understand boosting vs bagging\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve\n)\nfrom sklearn.datasets import load_breast_cancer\n\n# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\nX = cancer_data.data_y = cancer_data.target_df = pd.DataFrame(X, columns=cancer_data.feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Random Forest (bagging - for comparison)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Random Forest (bagging)\")\nprint(\"=\"*60)\n# Train RandomForestClassifier\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Try to import and train XGBoost_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train XGBoost (if available)\")\nprint(\"=\"*60)\n# Try: import xgboost as xgb\n# If available: Train XGBClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 4: Try to import and train LightGBM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train LightGBM (if available)\")\nprint(\"=\"*60)\n# Try: import lightgbm as lgb\n# If available: Train LGBMClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 5: Compare all models_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare models\")\nprint(\"=\"*60)\n# Create comparison table\n# Show: Random Forest vs XGBoost vs LightGBM\n# Show which performs best\n# Your code here...\n\n# Task 6: Feature importance comparison_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Feature importance\")\nprint(\"=\"*60)\n# Get feature importance from all models\n# Visualize and compare\n# Show which features are most important\n# Your code here...\n\n# Task 7: Understand boosting vs bagging_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Boosting vs Bagging\")\nprint(\"=\"*60)\n# Explain the difference:\n# - Bagging (RF): Models trained in parallel, then averaged\n# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_breast_cancer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mtarget_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mcancer_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'X' is not defined\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 5 - Exercise 2: Boosting Algorithms Practice\n\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632\n\nInstructions:\n1. Load the provided dataset_2. Train XGBoost model (if available)\n3. Train LightGBM model (if available)\n4. Compare with Random Forest (bagging)\n5. Compare boosting algorithms with each other_6. Interpret feature importance_7. Understand boosting vs bagging\n\nDataset: Binary classification dataset\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, roc_auc_score, roc_curve\n)\nfrom sklearn.datasets import load_breast_cancer\n\n# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\nX = cancer_data.data_y = cancer_data.target_df = pd.DataFrame(X, columns=cancer_data.feature_names)\ndf['target'] = y_\nprint(\"Dataset loaded!\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nClass distribution:\")\nprint(df['target'].value_counts())\n\n# TODO: Write your code here\n# TODO: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627\n\n# Task 1: Split the data_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 1: Split data\")\nprint(\"=\"*60)\n# Your code here...\n\n# Task 2: Train Random Forest (bagging - for comparison)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 2: Train Random Forest (bagging)\")\nprint(\"=\"*60)\n# Train RandomForestClassifier\n# Evaluate and print metrics\n# Your code here...\n\n# Task 3: Try to import and train XGBoost_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 3: Train XGBoost (if available)\")\nprint(\"=\"*60)\n# Try: import xgboost as xgb\n# If available: Train XGBClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 4: Try to import and train LightGBM_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 4: Train LightGBM (if available)\")\nprint(\"=\"*60)\n# Try: import lightgbm as lgb\n# If available: Train LGBMClassifier\n# Evaluate and print metrics\n# If not available: Print installation instructions\n# Your code here...\n\n# Task 5: Compare all models_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 5: Compare models\")\nprint(\"=\"*60)\n# Create comparison table\n# Show: Random Forest vs XGBoost vs LightGBM\n# Show which performs best\n# Your code here...\n\n# Task 6: Feature importance comparison_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 6: Feature importance\")\nprint(\"=\"*60)\n# Get feature importance from all models\n# Visualize and compare\n# Show which features are most important\n# Your code here...\n\n# Task 7: Understand boosting vs bagging_\nprint(\"\\n\" + \"=\"*60)\nprint(\"Task 7: Boosting vs Bagging\")\nprint(\"=\"*60)\n# Explain the difference:\n# - Bagging (RF): Models trained in parallel, then averaged\n# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes\n# Your code here...\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Exercise 2 Complete!\")\nprint(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")\nprint(\"=\"*60)\n\n\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_breast_cancer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load real-world Breast Cancer dataset_cancer_data = load_breast_cancer()\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m cancer_data\u001b[38;5;241m.\u001b[39mtarget_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mcancer_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mNameError\u001b[0m: name 'X' is not defined\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "exercise"
    },
    {
      "path": "Course 04/unit5-model-selection/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7299258708953857,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom train_test_split, from sklearn.ensemble import GridSearchCV\nfrom from sklearn.metrics import RandomForestClassifier\nfrom accuracy_score, from sklearn.datasets import classification_report\nfrom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as from sklearn.model_selection import np\nfrom train_test_split, from sklearn.ensemble import GridSearchCV\nfrom from sklearn.metrics import RandomForestClassifier\nfrom accuracy_score, from sklearn.datasets import classification_report\nfrom make_classification\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as from sklearn.model_selection import np\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "Course 04/unit5-model-selection/solutions/solution_02_boosting.ipynb",
      "status": "failed",
      "execution_time": 0.6531398296356201,
      "error": "An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 5 - Exercise 2: Boosting Algorithms Practice\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632Instructions:1. Load the provided dataset2. Train XGBoost model (if available)3. Train LightGBM model (if available)4. Compare with Random Forest (bagging)5. Compare boosting algorithms with each other6. Interpret feature importance7. Understand boosting vs baggingDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\n# Load real-world Breast Cancer datasetcancer_data = load_breast_cancer()X = cancer_data.datay = cancer_data.targetdf = pd.DataFrame(X, columns=cancer_data.feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train Random Forest (bagging - for comparison)print(\"\\n\" + \"=\"*60)print(\"Task 2: Train Random Forest (bagging)\")print(\"=\"*60)# Train RandomForestClassifier# Evaluate and print metrics# Your code here...# Task 3: Try to import and train XGBoost\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train XGBoost (if available)\")print(\"=\"*60)# Try: import xgboost as xgb# If available: Train XGBClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 4: Try to import and train LightGBM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train LightGBM (if available)\")print(\"=\"*60)# Try: import lightgbm as lgb# If available: Train LGBMClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 5: Compare all models\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare models\")print(\"=\"*60)# Create comparison table# Show: Random Forest vs XGBoost vs LightGBM# Show which performs best# Your code here...# Task 6: Feature importance comparison\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Feature importance\")print(\"=\"*60)# Get feature importance from all models# Visualize and compare# Show which features are most important# Your code here...# Task 7: Understand boosting vs bagging\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Boosting vs Bagging\")print(\"=\"*60)# Explain the difference:# - Bagging (RF): Models trained in parallel, then averaged# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\u001b[0m\n\u001b[0m                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Complete solution:\n# \"\"\"Unit 5 - Exercise 2: Boosting Algorithms Practice\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0648\u0627\u0644\u062a\u0639\u0632\u064a\u0632 - \u062a\u0645\u0631\u064a\u0646 2: \u0645\u0645\u0627\u0631\u0633\u0629 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a \u0627\u0644\u062a\u0639\u0632\u064a\u0632Instructions:1. Load the provided dataset2. Train XGBoost model (if available)3. Train LightGBM model (if available)4. Compare with Random Forest (bagging)5. Compare boosting algorithms with each other6. Interpret feature importance7. Understand boosting vs baggingDataset: Binary classification dataset\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\n# Load real-world Breast Cancer datasetcancer_data = load_breast_cancer()X = cancer_data.datay = cancer_data.targetdf = pd.DataFrame(X, columns=cancer_data.feature_names)df['target'] = y\nprint(\"Dataset loaded!\")print(f\"Shape: {df.shape}\")print(f\"\\nClass distribution:\")print(df['target'].value_counts())# # SOLUTION: Write # SOLUTION here# # SOLUTION: \u0627\u0643\u062a\u0628 \u0627\u0644\u0643\u0648\u062f \u0627\u0644\u062e\u0627\u0635 \u0628\u0643 \u0647\u0646\u0627# Task 1: Split the data\nprint(\"\\n\" + \"=\"*60)print(\"Task 1: Split data\")print(\"=\"*60)# Your code here...# Task 2: Train Random Forest (bagging - for comparison)print(\"\\n\" + \"=\"*60)print(\"Task 2: Train Random Forest (bagging)\")print(\"=\"*60)# Train RandomForestClassifier# Evaluate and print metrics# Your code here...# Task 3: Try to import and train XGBoost\nprint(\"\\n\" + \"=\"*60)print(\"Task 3: Train XGBoost (if available)\")print(\"=\"*60)# Try: import xgboost as xgb# If available: Train XGBClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 4: Try to import and train LightGBM\nprint(\"\\n\" + \"=\"*60)print(\"Task 4: Train LightGBM (if available)\")print(\"=\"*60)# Try: import lightgbm as lgb# If available: Train LGBMClassifier# Evaluate and print metrics# If not available: Print installation instructions# Your code here...\n# Task 5: Compare all models\nprint(\"\\n\" + \"=\"*60)print(\"Task 5: Compare models\")print(\"=\"*60)# Create comparison table# Show: Random Forest vs XGBoost vs LightGBM# Show which performs best# Your code here...# Task 6: Feature importance comparison\nprint(\"\\n\" + \"=\"*60)print(\"Task 6: Feature importance\")print(\"=\"*60)# Get feature importance from all models# Visualize and compare# Show which features are most important# Your code here...# Task 7: Understand boosting vs bagging\nprint(\"\\n\" + \"=\"*60)print(\"Task 7: Boosting vs Bagging\")print(\"=\"*60)# Explain the difference:# - Bagging (RF): Models trained in parallel, then averaged# - Boosting (XGBoost/LightGBM): Models trained sequentially, each learns from mistakes# Your code here...print(\"\\n\" + \"=\"*60)print(\"Exercise 2 Complete!\")print(\"\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u0645\u0631\u064a\u0646 2!\")print(\"=\"*60)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    confusion_matrix, roc_auc_score, roc_curve)from sklearn.datasets import load_breast_cancer\u001b[0m\n\u001b[0m                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "Course 05/unit1-introduction/examples/01_data_science_intro.ipynb",
      "status": "passed",
      "execution_time": 2.454681158065796,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/02_pandas_numpy_basics.ipynb",
      "status": "passed",
      "execution_time": 2.0781171321868896,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/03_cudf_introduction.ipynb",
      "status": "passed",
      "execution_time": 1.5052571296691895,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/04_python_basics_loops_conditions.ipynb",
      "status": "passed",
      "execution_time": 0.5404138565063477,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/05_jupyter_notebooks_best_practices.ipynb",
      "status": "passed",
      "execution_time": 0.5430500507354736,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/06_data_structures_lists_dictionaries.ipynb",
      "status": "passed",
      "execution_time": 0.7293131351470947,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/07_data_science_applications.ipynb",
      "status": "passed",
      "execution_time": 0.949033260345459,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/data_science_applications_working_on_small_real_world_projects_using_data_scienc.ipynb",
      "status": "failed",
      "execution_time": 0.7338950634002686,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/python_programming_executing_python_code_to_solve_basic_tasks_like_arithmetic_op.ipynb",
      "status": "failed",
      "execution_time": 0.5203671455383301,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/using_jupyter_notebooks_writing_and_executing_code_in_jupyter_notebooks_combinin.ipynb",
      "status": "failed",
      "execution_time": 0.7342910766601562,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/examples/working_with_data_structures_performing_tasks_like_indexing_slicing_and_transfor.ipynb",
      "status": "failed",
      "execution_time": 0.5212669372558594,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "example"
    },
    {
      "path": "Course 05/unit1-introduction/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 1.5501329898834229,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "exercise"
    },
    {
      "path": "Course 05/unit1-introduction/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 1.321286916732788,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit1-introduction",
      "type": "other"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/04_data_loading.ipynb",
      "status": "passed",
      "execution_time": 1.233151912689209,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/05_feature_transformation_scaling_encoding.ipynb",
      "status": "failed",
      "execution_time": 0.723444938659668,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFeature Transformation: Scaling and Encoding\")\nprint(\"=\" * 60)\n\nprint(\"\\nScaling:\")\nprint(\"  - StandardScaler: Mean 0, std 1\")\nprint(\"  - MinMaxScaler: Range [0, 1]\")\nprint(\"  - RobustScaler: Median and IQR\")\nprint(\"  - Normalization\")\n\nprint(\"\\nEncoding:\")\nprint(\"  - Label Encoding: Ordinal categories\")\nprint(\"  - One-Hot Encoding: Nominal categories\")\nprint(\"  - Target Encoding: Mean target\")\nprint(\"  - Frequency Encoding\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Scaling: Numerical features\")\nprint(\"  - Encoding: Categorical features\")\nprint(\"  - Before ML models\")\nprint(\"  - For distance-based algorithms\")\n\nprint(\"\\n\u2705 Feature transformation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFeature Transformation: Scaling and Encoding\")\nprint(\"=\" * 60)\n\nprint(\"\\nScaling:\")\nprint(\"  - StandardScaler: Mean 0, std 1\")\nprint(\"  - MinMaxScaler: Range [0, 1]\")\nprint(\"  - RobustScaler: Median and IQR\")\nprint(\"  - Normalization\")\n\nprint(\"\\nEncoding:\")\nprint(\"  - Label Encoding: Ordinal categories\")\nprint(\"  - One-Hot Encoding: Nominal categories\")\nprint(\"  - Target Encoding: Mean target\")\nprint(\"  - Frequency Encoding\")\n\nprint(\"\\nWhen to Use:\")\nprint(\"  - Scaling: Numerical features\")\nprint(\"  - Encoding: Categorical features\")\nprint(\"  - Before ML models\")\nprint(\"  - For distance-based algorithms\")\n\nprint(\"\\n\u2705 Feature transformation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/05_missing_values_duplicates.ipynb",
      "status": "passed",
      "execution_time": 1.781053066253662,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/06_eda_visualizations.ipynb",
      "status": "passed",
      "execution_time": 1.4343690872192383,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/06_outliers_transformation.ipynb",
      "status": "passed",
      "execution_time": 2.6087441444396973,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/07_cudf_import_export_gpu.ipynb",
      "status": "failed",
      "execution_time": 0.8084440231323242,
      "error": "An error occurred while executing the following cell:\n------------------\n# Try importing cuDF (requires CUDA and RAPIDS installation)\ntry:\n    import cudf\n    import pandas as pd\n    import numpy as np_HAS_CUDF = True_\nprint(\"\u2705 cuDF imported successfully!\")\nprint(f\"cuDF version: {cudf.__version__}\")\nexcept ImportError:\n    HAS_CUDF = False\n    import pandas as pd\n    import numpy as np_\nprint(\"\u26a0\ufe0f  cuDF not available. Install RAPIDS for GPU acceleration:\")\nprint(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\")\nprint(\"   Continuing with Pandas examples...\")\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_HAS_CUDF = True_\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Try importing cuDF (requires CUDA and RAPIDS installation)\ntry:\n    import cudf\n    import pandas as pd\n    import numpy as np_HAS_CUDF = True_\nprint(\"\u2705 cuDF imported successfully!\")\nprint(f\"cuDF version: {cudf.__version__}\")\nexcept ImportError:\n    HAS_CUDF = False\n    import pandas as pd\n    import numpy as np_\nprint(\"\u26a0\ufe0f  cuDF not available. Install RAPIDS for GPU acceleration:\")\nprint(\"   Note: Requires CUDA-capable GPU and RAPIDS installation\")\nprint(\"   Continuing with Pandas examples...\")\nprint(\"\u2705 Libraries imported!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_HAS_CUDF = True_\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/feature_transformation_transforming_data_eg_scaling_encoding_to_prepare_it_for_a.ipynb",
      "status": "failed",
      "execution_time": 0.5380008220672607,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit2-cleaning/examples/performing_eda_visualizing_data_distributions_and_relationships_to_discover_insi.ipynb",
      "status": "failed",
      "execution_time": 0.5307178497314453,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit2-cleaning",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/04_chart_types_matplotlib_seaborn.ipynb",
      "status": "passed",
      "execution_time": 1.3936729431152344,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/05_interactive_visualizations_plotly.ipynb",
      "status": "passed",
      "execution_time": 1.007431983947754,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/06_customizing_annotating_visualizations.ipynb",
      "status": "passed",
      "execution_time": 1.2931442260742188,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/07_matplotlib_basics.ipynb",
      "status": "passed",
      "execution_time": 1.9619128704071045,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/07_visualization_best_practices.ipynb",
      "status": "passed",
      "execution_time": 1.5397770404815674,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/08_seaborn_plots.ipynb",
      "status": "passed",
      "execution_time": 4.0055718421936035,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/09_plotly_interactive.ipynb",
      "status": "passed",
      "execution_time": 1.188905954360962,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/applying_visualization_best_practices_for_data_storytelling.ipynb",
      "status": "failed",
      "execution_time": 0.5874769687652588,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/building_interactive_visualizations_and_dashboards_with_plotly.ipynb",
      "status": "failed",
      "execution_time": 0.6052649021148682,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit3-visualization/examples/creating_various_chart_types_using_matplotlib_and_seaborn.ipynb",
      "status": "failed",
      "execution_time": 0.7283949851989746,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make results reproducible_rng = np.random.default_rng(42)\nn = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\ny = 2.0 * x + rng.normal(0, 0.6, size=n)_cat =  rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ncat = rng.choice(['A', 'B', 'C'], size=n, p=[0.4, 0.35, 0.25])\ndf = pd.DataFrame({'x': x, 'y': y, 'category': cat})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 300_x = rng.normal(0, 1, size=n)_y =  2.0 * x + rng.normal(0, 0.6, size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit3-visualization",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/05_pandas_data_manipulation.ipynb",
      "status": "passed",
      "execution_time": 0.9216790199279785,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/06_data_preparation_ml_tasks.ipynb",
      "status": "failed",
      "execution_time": 0.513272762298584,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nData Preparation for ML Tasks\")\nprint(\"=\" * 60)\n\nprint(\"\\nMissing Values:\")\nprint(\"  - Detection: isnull(), info()\")\nprint(\"  - Removal: dropna()\")\nprint(\"  - Imputation: fillna(), SimpleImputer\")\nprint(\"  - Forward/backward fill\")\n\nprint(\"\\nCategorical Encoding:\")\nprint(\"  - Label Encoding\")\nprint(\"  - One-Hot Encoding\")\nprint(\"  - Ordinal Encoding\")\nprint(\"  - Target Encoding\")\n\nprint(\"\\nData Splitting:\")\nprint(\"  - Train/Test split\")\nprint(\"  - Train/Validation/Test\")\nprint(\"  - Stratified splitting\")\nprint(\"  - Time-based splitting\")\n\nprint(\"\\n\u2705 Data preparation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing \nimport LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nData Preparation for ML Tasks\")\nprint(\"=\" * 60)\n\nprint(\"\\nMissing Values:\")\nprint(\"  - Detection: isnull(), info()\")\nprint(\"  - Removal: dropna()\")\nprint(\"  - Imputation: fillna(), SimpleImputer\")\nprint(\"  - Forward/backward fill\")\n\nprint(\"\\nCategorical Encoding:\")\nprint(\"  - Label Encoding\")\nprint(\"  - One-Hot Encoding\")\nprint(\"  - Ordinal Encoding\")\nprint(\"  - Target Encoding\")\n\nprint(\"\\nData Splitting:\")\nprint(\"  - Train/Test split\")\nprint(\"  - Train/Validation/Test\")\nprint(\"  - Stratified splitting\")\nprint(\"  - Time-based splitting\")\n\nprint(\"\\n\u2705 Data preparation concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/07_implementing_ml_models_scikit_learn.ipynb",
      "status": "failed",
      "execution_time": 0.6472718715667725,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge/Lasso Regression\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nWorkflow:\")\nprint(\"  1. Prepare data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge/Lasso Regression\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nWorkflow:\")\nprint(\"  1. Prepare data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\n\nprint(\"\\n\u2705 ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/07_implementing_ml_models_sklearn.ipynb",
      "status": "failed",
      "execution_time": 0.7297158241271973,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge, Lasso\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nScikit-learn Workflow:\")\nprint(\"  1. Import model\")\nprint(\"  2. Create instance\")\nprint(\"  3. Fit on training data\")\nprint(\"  4. Predict on test data\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\n\u2705 Scikit-learn ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LinearRegression, LogisticRegression\nfrom sklearn.tree \nimport DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble \nimport RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics \nimport accuracy_score, mean_squared_error, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nImplementing ML Models with Scikit-learn\")\nprint(\"=\" * 60)\n\nprint(\"\\nRegression Models:\")\nprint(\"  - Linear Regression\")\nprint(\"  - Decision Tree Regression\")\nprint(\"  - Random Forest Regression\")\nprint(\"  - Ridge, Lasso\")\n\nprint(\"\\nClassification Models:\")\nprint(\"  - Logistic Regression\")\nprint(\"  - Decision Tree Classifier\")\nprint(\"  - Random Forest Classifier\")\nprint(\"  - SVM, KNN\")\n\nprint(\"\\nScikit-learn Workflow:\")\nprint(\"  1. Import model\")\nprint(\"  2. Create instance\")\nprint(\"  3. Fit on training data\")\nprint(\"  4. Predict on test data\")\nprint(\"  5. Evaluate performance\")\n\nprint(\"\\n\u2705 Scikit-learn ML models concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/08_supervised_learning_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5434830188751221,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.metrics \nimport accuracy_score, confusion_matrix, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSupervised Learning: Logistic Regression\")\nprint(\"=\" * 60)\n\nprint(\"\\nSupervised Learning:\")\nprint(\"  - Uses labeled training data\")\nprint(\"  - Learns mapping from inputs to outputs\")\nprint(\"  - Can predict on new data\")\nprint(\"  - Classification and regression\")\n\nprint(\"\\nLogistic Regression:\")\nprint(\"  - Binary classification\")\nprint(\"  - Multi-class classification\")\nprint(\"  - Probabilistic output\")\nprint(\"  - Linear decision boundary\")\n\nprint(\"\\nTraining Process:\")\nprint(\"  1. Prepare labeled data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\nprint(\"  5. Make predictions\")\n\nprint(\"\\n\u2705 Supervised learning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split\nfrom sklearn.metrics \nimport accuracy_score, confusion_matrix, classification_report_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nSupervised Learning: Logistic Regression\")\nprint(\"=\" * 60)\n\nprint(\"\\nSupervised Learning:\")\nprint(\"  - Uses labeled training data\")\nprint(\"  - Learns mapping from inputs to outputs\")\nprint(\"  - Can predict on new data\")\nprint(\"  - Classification and regression\")\n\nprint(\"\\nLogistic Regression:\")\nprint(\"  - Binary classification\")\nprint(\"  - Multi-class classification\")\nprint(\"  - Probabilistic output\")\nprint(\"  - Linear decision boundary\")\n\nprint(\"\\nTraining Process:\")\nprint(\"  1. Prepare labeled data\")\nprint(\"  2. Split train/test\")\nprint(\"  3. Train model\")\nprint(\"  4. Evaluate performance\")\nprint(\"  5. Make predictions\")\n\nprint(\"\\n\u2705 Supervised learning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.linear_model\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/09_unsupervised_learning_kmeans.ipynb",
      "status": "passed",
      "execution_time": 1.695754051208496,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/10_hyperparameter_tuning_grid_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.7346150875091553,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nHyperparameter Tuning: Grid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search\")\nprint(\"  - Tests all combinations\")\nprint(\"  - Guarantees best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling\")\nprint(\"  - More efficient\")\nprint(\"  - Good for large spaces\")\nprint(\"  - Often finds good solutions\")\n\nprint(\"\\nHyperparameters:\")\nprint(\"  - Learning rate\")\nprint(\"  - Number of trees\")\nprint(\"  - Max depth\")\nprint(\"  - Regularization strength\")\n\nprint(\"\\n\u2705 Hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom sklearn.model_selection \nimport GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \nimport RandomForestClassifier\nfrom scipy.stats \nimport randint_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nHyperparameter Tuning: Grid Search and Random Search\")\nprint(\"=\" * 60)\n\nprint(\"\\nGrid Search:\")\nprint(\"  - Exhaustive search\")\nprint(\"  - Tests all combinations\")\nprint(\"  - Guarantees best in grid\")\nprint(\"  - Computationally expensive\")\n\nprint(\"\\nRandom Search:\")\nprint(\"  - Random sampling\")\nprint(\"  - More efficient\")\nprint(\"  - Good for large spaces\")\nprint(\"  - Often finds good solutions\")\n\nprint(\"\\nHyperparameters:\")\nprint(\"  - Learning rate\")\nprint(\"  - Number of trees\")\nprint(\"  - Max depth\")\nprint(\"  - Regularization strength\")\n\nprint(\"\\n\u2705 Hyperparameter tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/10_linear_regression.ipynb",
      "status": "passed",
      "execution_time": 1.945145845413208,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/11_classification.ipynb",
      "status": "passed",
      "execution_time": 2.2036921977996826,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/11_real_world_problem_solving.ipynb",
      "status": "failed",
      "execution_time": 0.7790629863739014,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nReal-World Problem Solving\")\nprint(\"=\" * 60)\n\nprint(\"\\nCombining Approaches:\")\nprint(\"  - Unsupervised: Discover patterns\")\nprint(\"  - Supervised: Predict outcomes\")\nprint(\"  - Feature engineering\")\nprint(\"  - Dimensionality reduction\")\n\nprint(\"\\nProblem-Solving Steps:\")\nprint(\"  1. Understand problem\")\nprint(\"  2. Explore data (unsupervised)\")\nprint(\"  3. Engineer features\")\nprint(\"  4. Build predictive model (supervised)\")\nprint(\"  5. Evaluate and iterate\")\n\nprint(\"\\nExample Workflow:\")\nprint(\"  - Clustering for segmentation\")\nprint(\"  - Classification for prediction\")\nprint(\"  - Dimensionality reduction\")\nprint(\"  - Feature selection\")\n\nprint(\"\\n\u2705 Real-world problem solving concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster \nimport KMeans\nfrom sklearn.linear_model \nimport LogisticRegression\nfrom sklearn.model_selection \nimport train_test_split_\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nReal-World Problem Solving\")\nprint(\"=\" * 60)\n\nprint(\"\\nCombining Approaches:\")\nprint(\"  - Unsupervised: Discover patterns\")\nprint(\"  - Supervised: Predict outcomes\")\nprint(\"  - Feature engineering\")\nprint(\"  - Dimensionality reduction\")\n\nprint(\"\\nProblem-Solving Steps:\")\nprint(\"  1. Understand problem\")\nprint(\"  2. Explore data (unsupervised)\")\nprint(\"  3. Engineer features\")\nprint(\"  4. Build predictive model (supervised)\")\nprint(\"  5. Evaluate and iterate\")\n\nprint(\"\\nExample Workflow:\")\nprint(\"  - Clustering for segmentation\")\nprint(\"  - Classification for prediction\")\nprint(\"  - Dimensionality reduction\")\nprint(\"  - Feature selection\")\n\nprint(\"\\n\u2705 Real-world problem solving concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.cluster\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/12_model_evaluation.ipynb",
      "status": "passed",
      "execution_time": 6.423153877258301,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/13_cpu_vs_gpu_ml.ipynb",
      "status": "passed",
      "execution_time": 1.8969690799713135,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/applying_supervised_learning_algorithms_on_labeled_data_eg_logistic_regression.ipynb",
      "status": "failed",
      "execution_time": 0.5223560333251953,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/applying_unsupervised_learning_techniques_eg_k_means_clustering_on_unlabeled_dat.ipynb",
      "status": "failed",
      "execution_time": 0.7315499782562256,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX, _ = make_blobs(n_samples=500, centers=4, cluster_std=1.2, random_state=42)\ninertias = []_sil =  []\nsil = []_ks =  range(2, 9)\nks = range(2, 9)\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)_labels =  km.fit_predict(X)\nlabels = km.fit_predict(X)\ninertias.append(km.inertia_)\nsil.append(silhouette_score(X, labels))\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].plot(list(ks), inertias, marker='o')\nax[0].set_title('Elbow method (inertia)')\nax[0].set_xlabel('k')\nax[1].plot(list(ks), sil, marker='o')\nax[1].set_title('Silhouette score')\nax[1].set_xlabel('k')\nplt.tight_layout()\nplt.show()\n\n# Fit final model_k_best = 4_km = KMeans(n_clusters=k_best, n_init=10, random_state=42)\nlabels = km.fit_predict(X)\nplt.figure(figsize=(6, 5))\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=15)\nplt.title(f'K-Means clustering (k={k_best})')\nplt.show()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    inertias = []_sil =  []\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/cleaning_and_preparing_data_for_ml_tasks_handling_missing_values_encoding_catego.ipynb",
      "status": "failed",
      "execution_time": 0.82729172706604,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/hyperparameter_tuning_using_techniques_like_grid_search_and_random_search.ipynb",
      "status": "failed",
      "execution_time": 0.8295221328735352,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/implementing_ml_models_using_scikit_learn_library_regression_classification.ipynb",
      "status": "failed",
      "execution_time": 0.5885870456695557,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/real_world_problem_solving_using_a_mix_of_supervised_and_unsupervised_learning_a.ipynb",
      "status": "failed",
      "execution_time": 0.730029821395874,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit4-ml-intro/examples/working_with_data_using_python_libraries_like_pandas.ipynb",
      "status": "failed",
      "execution_time": 0.7240440845489502,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd_rng = np.random.default_rng(7)\nn = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\nincome = rng.normal(4000, 1200, size=n).clip(800, None)_city =  rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])\ncity = rng.choice(['Riyadh', 'Jeddah', 'Dammam'], size=n, p=[0.5, 0.3, 0.2])_clicked =  (income > 4200).astype(int)\nclicked = (income > 4200).astype(int)\n\n# inject missing values_income[rng.choice(n, size=30, replace=False)] = np.nan_df = pd.DataFrame({'age': age, 'income': income, 'city': city, 'clicked': clicked})\ndf.head()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 500_age = rng.integers(18, 70, size=n)_income =  rng.normal(4000, 1200, size=n).clip(800, None)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit4-ml-intro",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/14_dask_distributed.ipynb",
      "status": "passed",
      "execution_time": 1.7051289081573486,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/15_rapids_workflows.ipynb",
      "status": "passed",
      "execution_time": 2.026124954223633,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/16_production_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.4787929058074951,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/17_performance_optimization.ipynb",
      "status": "passed",
      "execution_time": 1.2977111339569092,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/18_large_datasets.ipynb",
      "status": "passed",
      "execution_time": 2.5435502529144287,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/19_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.4225821495056152,
      "error": null,
      "error_traceback": null,
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 05/unit5-scaling/examples/accelerated_data_with_gpu_using_rapids_using_rapids_libraries_like_cudf_data_fra.ipynb",
      "status": "failed",
      "execution_time": 0.7188100814819336,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# small synthetic dataset_rng = np.random.default_rng(123)\nn = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\nx2 = rng.normal(size=n)_color =  rng.choice(['red','green','blue'], size=n)\ncolor = rng.choice(['red','green','blue'], size=n)\ny = ((x1 + 0.8*x2 + (color == 'red')*0.6 + rng.normal(scale=0.5, size=n)) > 0.2).astype(int)\ndf = pd.DataFrame({'x1': x1, 'x2': x2, 'color': color, 'y': y})_X =  df.drop(columns=['y'])\nX = df.drop(columns=['y'])_y =  df['y']\ny = df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\npre = ColumnTransformer([\n ('cat', OneHotEncoder(handle_unknown='ignore'), ['color']),\n], remainder='passthrough')\n\nclf = Pipeline([\n ('pre', pre),\n ('model', LogisticRegression(max_iter=1000))\n])\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('accuracy:', accuracy_score(y_test, y_pred))\nprint('confusion matrix:', confusion_matrix(y_test, y_pred))\nprint('\\nreport:', classification_report(y_test, y_pred))\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    n = 600_x1 = rng.normal(size=n)_x2 =  rng.normal(size=n)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 05",
      "unit": "unit5-scaling",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/01_ethical_frameworks.ipynb",
      "status": "passed",
      "execution_time": 1.3163390159606934,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/02_ethical_decision_making.ipynb",
      "status": "passed",
      "execution_time": 1.066882848739624,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/03_case_study_analysis.ipynb",
      "status": "failed",
      "execution_time": 0.721839189529419,
      "error": "An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us analyze and visualize the case stud\ny\n\nimport matplotlib.pyplot as plt # For creating visualizations: Charts, graphs, bar charts\nimport matplotlib.patches as mpatches # For drawing shapes: Legends, patche\nsi\nmport numpy as np # For numerical operations: Arrays, calculations\nimport pandas as pd # For data manipulation: DataFrames, data analysis\nimport os # For file operations: Saving images\n\n# Configure matplotlib settings: Set default figure size and font size for better visualizations\nplt.rcParams['font.size'] = 10 # Font size: Make text readable (10\npt is good for most displays)\nplt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda What each library does:\")\nprint(\" - matplotlib: Create visualizations (charts, graphs)\")\nprint(\" - numpy: Numerical operations (arrays, calculations)\")\nprint(\" - pandas: Data manipulation (DataFrames, analysis)\")\nprint(\" - os: File operations (saving images)\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    pt is good for most displays)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Step 1: Import necessary libraries\n# These libraries help us analyze and visualize the case stud\ny\n\nimport matplotlib.pyplot as plt # For creating visualizations: Charts, graphs, bar charts\nimport matplotlib.patches as mpatches # For drawing shapes: Legends, patche\nsi\nmport numpy as np # For numerical operations: Arrays, calculations\nimport pandas as pd # For data manipulation: DataFrames, data analysis\nimport os # For file operations: Saving images\n\n# Configure matplotlib settings: Set default figure size and font size for better visualizations\nplt.rcParams['font.size'] = 10 # Font size: Make text readable (10\npt is good for most displays)\nplt.rcParams['figure.figsize'] = (14, 8) # Figure size: 14 inches wide, 8 inches tall (good for detailed charts)\nprint(\"\u2705 Libraries imported successfully!\")\nprint(\"\\n\ud83d\udcda What each library does:\")\nprint(\" - matplotlib: Create visualizations (charts, graphs)\")\nprint(\" - numpy: Numerical operations (arrays, calculations)\")\nprint(\" - pandas: Data manipulation (DataFrames, analysis)\")\nprint(\" - os: File operations (saving images)\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    pt is good for most displays)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/algorithmic_fairness_testing_applying_fairness_metrics_and_interpreting_ai_decis.ipynb",
      "status": "passed",
      "execution_time": 1.2970995903015137,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/case_studies_analysis_investigating_real_ethical_failures_in_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.503767728805542,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/detecting_bias_in_ai_models_identifying_biases_in_datasets_and_algorithms_and_ap.ipynb",
      "status": "passed",
      "execution_time": 1.2855439186096191,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/examples/privacy_simulation_assessing_privacy_risks_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.479137897491455,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "example"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.659743070602417,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit1-ethics-foundations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7627930641174316,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "other"
    },
    {
      "path": "Course 06/unit2-bias-fairness/examples/06_detecting_bias_ai_models.ipynb",
      "status": "passed",
      "execution_time": 1.1672980785369873,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-fairness",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-fairness/examples/07_fairness_testing_metrics.ipynb",
      "status": "passed",
      "execution_time": 0.6751048564910889,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-fairness",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/01_bias_detection.ipynb",
      "status": "passed",
      "execution_time": 2.322115898132324,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/02_bias_mitigation.ipynb",
      "status": "passed",
      "execution_time": 1.8467001914978027,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/03_fair_representation.ipynb",
      "status": "passed",
      "execution_time": 1.5011558532714844,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/04_bias_case_studies.ipynb",
      "status": "passed",
      "execution_time": 1.717216968536377,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/05_fair_ai_development.ipynb",
      "status": "passed",
      "execution_time": 2.3484508991241455,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/ai_fairness_auditing_evaluating_and_improving_ethical_compliance_in_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.384922742843628,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/case_studies_analysis_investigating_bias_incidents_in_ai_in_real_world.ipynb",
      "status": "passed",
      "execution_time": 1.353745698928833,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/detecting_bias_in_ai_models_identifying_biases_in_datasets_and_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.4994549751281738,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/developing_ai_ethics_policies_formulating_guidelines_for_responsible_ai_use.ipynb",
      "status": "passed",
      "execution_time": 1.548166036605835,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/fairness_testing_using_fairness_metrics_to_evaluate_ai_decisions.ipynb",
      "status": "passed",
      "execution_time": 1.498305082321167,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/examples/implementing_bias_mitigation_techniques_applying_correction_techniques_and_evalu.ipynb",
      "status": "passed",
      "execution_time": 1.4062402248382568,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "example"
    },
    {
      "path": "Course 06/unit2-bias-justice/exercises/exercise_02.ipynb",
      "status": "failed",
      "execution_time": 0.527008056640625,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI\nExercise 2: Bias Mitigation TechniquesThis exercise requires you to implement and compare different bias mitigation techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# TASK 1: Generate Biased Datase\nt\n# ============================================================================\ndef generate_biased_dataset(n_samples=2000):\n \n    \n    \"\"\"\n TODO: Generate a synthetic dataset with bias.\n Requirements:\n - Create a dataset with features and a sensitive attribute (e.g., gender: 0 or 1)\n - Introduce bias such that one group has lower probability of positive outcome\n - Return a DataFrame with columns: feature1, feature2, sensitive, target\n \"\"\"\n np.random.seed(42)\n # TODO: Your code here\n # Hint: Use np.random functions to generate features\n # Hint: Make the target depend on features but add bias based on sensitive attribut\nepass\n# ============================================================================\n# TASK 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Implement reweighing technique.\n Requirements:\n - Calculate weights to balance representation across groups\n - Return array of weights for each training sample\n \"\"\"\n # TODO: Your code here\n # Hint: Calculate weights inversely proportional to group size\n pass\n# ============================================================================\n# TASK 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \"\"\"\n TODO: Train a baseline model without any bias mitigation.\n \"\"\"\n # TODO: Your code here\n # Hint: Use RandomForestClassifier\n pass\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Train a model using reweighing technique.\n \"\"\"\n # TODO: Your code here\n # Hint: Use the preprocess_reweighing function and pass weights to fi\nt()\n pass\n# ============================================================================\n# TASK 4: Evaluate Fairness Metric\ns\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \"\"\"\n TODO: Evaluate fairness metrics.\n Requirements:\n - Calculate demographic parity difference\n - Calculate equalized odds difference\n - Calculate accuracy\n - Return a dictionary with these metrics\n \"\"\"\n # TODO: Your code here\n # Hint: Use fairlearn.metrics function\nspass\n# ============================================================================\n# TASK 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \"\"\"\n TODO: Compare baseline vs reweighing techniques.\n Requirements:\n - Split data into train/test\n - Train baseline and reweighed models\n - Evaluate fairness metrics for both\n - Print comparison results\n \"\"\"\n # TODO: Your code here\n pass\n# ============================================================================\n# MAIN EXECUTIO\nN\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate datase\nt\n print(\"\\nTask 1: Generating biased dataset...\")\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"Sensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n # Compare techniques\n print(\"\\nTask 5: Comparing mitigation techniques...\")\n compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Exercise completed! Check your results against the solution.\")\n print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI\nExercise 2: Bias Mitigation TechniquesThis exercise requires you to implement and compare different bias mitigation techniques.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# TASK 1: Generate Biased Datase\nt\n# ============================================================================\ndef generate_biased_dataset(n_samples=2000):\n \n    \n    \"\"\"\n TODO: Generate a synthetic dataset with bias.\n Requirements:\n - Create a dataset with features and a sensitive attribute (e.g., gender: 0 or 1)\n - Introduce bias such that one group has lower probability of positive outcome\n - Return a DataFrame with columns: feature1, feature2, sensitive, target\n \"\"\"\n np.random.seed(42)\n # TODO: Your code here\n # Hint: Use np.random functions to generate features\n # Hint: Make the target depend on features but add bias based on sensitive attribut\nepass\n# ============================================================================\n# TASK 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Implement reweighing technique.\n Requirements:\n - Calculate weights to balance representation across groups\n - Return array of weights for each training sample\n \"\"\"\n # TODO: Your code here\n # Hint: Calculate weights inversely proportional to group size\n pass\n# ============================================================================\n# TASK 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \"\"\"\n TODO: Train a baseline model without any bias mitigation.\n \"\"\"\n # TODO: Your code here\n # Hint: Use RandomForestClassifier\n pass\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \"\"\"\n TODO: Train a model using reweighing technique.\n \"\"\"\n # TODO: Your code here\n # Hint: Use the preprocess_reweighing function and pass weights to fi\nt()\n pass\n# ============================================================================\n# TASK 4: Evaluate Fairness Metric\ns\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \"\"\"\n TODO: Evaluate fairness metrics.\n Requirements:\n - Calculate demographic parity difference\n - Calculate equalized odds difference\n - Calculate accuracy\n - Return a dictionary with these metrics\n \"\"\"\n # TODO: Your code here\n # Hint: Use fairlearn.metrics function\nspass\n# ============================================================================\n# TASK 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \"\"\"\n TODO: Compare baseline vs reweighing techniques.\n Requirements:\n - Split data into train/test\n - Train baseline and reweighed models\n - Evaluate fairness metrics for both\n - Print comparison results\n \"\"\"\n # TODO: Your code here\n pass\n# ============================================================================\n# MAIN EXECUTIO\nN\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate datase\nt\n print(\"\\nTask 1: Generating biased dataset...\")\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"Sensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n # Compare techniques\n print(\"\\nTask 5: Comparing mitigation techniques...\")\n compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Exercise completed! Check your results against the solution.\")\n print(\"=\"*80)\n\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit2-bias-justice/solutions/solution_02.ipynb",
      "status": "passed",
      "execution_time": 0.8518939018249512,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "other"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/01_data_protection.ipynb",
      "status": "passed",
      "execution_time": 2.048283100128174,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/02_privacy_technologies.ipynb",
      "status": "passed",
      "execution_time": 1.8356211185455322,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/03_differential_privacy.ipynb",
      "status": "passed",
      "execution_time": 1.9052231311798096,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/04_gdpr_compliance.ipynb",
      "status": "passed",
      "execution_time": 2.016494035720825,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/05_secure_development.ipynb",
      "status": "passed",
      "execution_time": 1.924475908279419,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/06_data_encryption_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.8318588733673096,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/07_anonymization_pseudonymization.ipynb",
      "status": "passed",
      "execution_time": 0.8395380973815918,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/anonymization_techniques_applying_anonymization_and_pseudonymization_methods.ipynb",
      "status": "passed",
      "execution_time": 1.505230188369751,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/case_study_analysis_investigating_real_world_privacy_breaches_and_security_failu.ipynb",
      "status": "passed",
      "execution_time": 1.4939649105072021,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/compliance_testing_ensuring_ai_systems_comply_with_gdpr_and_other_regulations.ipynb",
      "status": "passed",
      "execution_time": 1.3510141372680664,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/data_encryption_implementing_encryption_techniques_for_data_protection.ipynb",
      "status": "passed",
      "execution_time": 1.503067970275879,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/privacy_risk_assessment_evaluating_privacy_risks_in_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 1.3813860416412354,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/examples/security_auditing_conducting_security_audits_on_ai_systems.ipynb",
      "status": "passed",
      "execution_time": 1.3404452800750732,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "example"
    },
    {
      "path": "Course 06/unit3-privacy-security/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.6801128387451172,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit3-privacy-security/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7317807674407959,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "other"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/01_shap_explanations.ipynb",
      "status": "passed",
      "execution_time": 2.7828128337860107,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/02_lime_explanations.ipynb",
      "status": "passed",
      "execution_time": 2.1543800830841064,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/03_counterfactual_analysis.ipynb",
      "status": "passed",
      "execution_time": 2.3971498012542725,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/04_accountability_frameworks.ipynb",
      "status": "passed",
      "execution_time": 1.973069190979004,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/05_hitl_approaches.ipynb",
      "status": "passed",
      "execution_time": 1.7761971950531006,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/06_transparency_tools.ipynb",
      "status": "passed",
      "execution_time": 1.5576958656311035,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/07_explainable_ai_techniques.ipynb",
      "status": "failed",
      "execution_time": 0.7339200973510742,
      "error": "An error occurred while executing the following cell:\n------------------\nimport shap\nimport lime\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nExplainable AI Techniques\")\nprint(\"=\" * 60)\n\nprint(\"\\nSHAP (SHapley Additive exPlanations):\")\nprint(\" - Game theory-based\")\nprint(\" - Feature importance\")\nprint(\" - Global and local explanations\")\nprint(\" - Consistent explanations\")\n\nprint(\"\\nLIME (Local Interpretable Model-agnostic Explanations):\")\nprint(\" - Local explanations\")\nprint(\" - Model-agnostic\")\nprint(\" - Perturbation-based\")\nprint(\" - Interpretable models\")\n\nprint(\"\\nApplications:\")\nprint(\" - Model debugging\")\nprint(\" - Feature importance\")\nprint(\" - Regulatory compliance\")\nprint(\" - User trust\")\n\nprint(\"\\n\u2705 Explainable AI concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport shap\nimport lime\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nExplainable AI Techniques\")\nprint(\"=\" * 60)\n\nprint(\"\\nSHAP (SHapley Additive exPlanations):\")\nprint(\" - Game theory-based\")\nprint(\" - Feature importance\")\nprint(\" - Global and local explanations\")\nprint(\" - Consistent explanations\")\n\nprint(\"\\nLIME (Local Interpretable Model-agnostic Explanations):\")\nprint(\" - Local explanations\")\nprint(\" - Model-agnostic\")\nprint(\" - Perturbation-based\")\nprint(\" - Interpretable models\")\n\nprint(\"\\nApplications:\")\nprint(\" - Model debugging\")\nprint(\" - Feature importance\")\nprint(\" - Regulatory compliance\")\nprint(\" - User trust\")\n\nprint(\"\\n\u2705 Explainable AI concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/case_studies_analysis_analyzing_success_and_failure_in_transparency_and_accounta.ipynb",
      "status": "passed",
      "execution_time": 1.4996726512908936,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/examples/implementing_xai_techniques_applying_techniques_like_lime_and_shap_to_interpret_.ipynb",
      "status": "passed",
      "execution_time": 1.4488770961761475,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "example"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 1.4542169570922852,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit4-transparency-accountability/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.6239700317382812,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "other"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/01_global_regulations.ipynb",
      "status": "passed",
      "execution_time": 2.2010209560394287,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/02_industry_regulations.ipynb",
      "status": "passed",
      "execution_time": 1.8676750659942627,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/03_governance_frameworks.ipynb",
      "status": "passed",
      "execution_time": 1.8240063190460205,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/04_legal_challenges.ipynb",
      "status": "passed",
      "execution_time": 1.6211531162261963,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/06_ai_governance_frameworks.ipynb",
      "status": "passed",
      "execution_time": 0.7354280948638916,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/accountability_practices_in_ai_developing_and_simulating_monitoring_systems_for_.ipynb",
      "status": "passed",
      "execution_time": 1.4330790042877197,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/case_studies_evaluation_evaluating_regulatory_challenges_and_ai_in_real_world.ipynb",
      "status": "passed",
      "execution_time": 1.5072407722473145,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/predictive_analysis_for_future_challenges_identifying_and_predicting_upcoming_ch.ipynb",
      "status": "passed",
      "execution_time": 1.481379747390747,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/examples/transparency_and_interpretability_tools_implementing_and_testing_interpretabilit.ipynb",
      "status": "passed",
      "execution_time": 1.2543668746948242,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "example"
    },
    {
      "path": "Course 06/unit5-governance-regulations/exercises/exercise_01.ipynb",
      "status": "passed",
      "execution_time": 0.8258368968963623,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "exercise"
    },
    {
      "path": "Course 06/unit5-governance-regulations/solutions/solution_01.ipynb",
      "status": "passed",
      "execution_time": 0.7419939041137695,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "other"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/01_text_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 0.9918069839477539,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/02_nltk_spacy_introduction.ipynb",
      "status": "passed",
      "execution_time": 0.8758161067962646,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/03_real_world_nlp_applications.ipynb",
      "status": "passed",
      "execution_time": 0.6708660125732422,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/04_text_conversion_script.ipynb",
      "status": "passed",
      "execution_time": 0.6849191188812256,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/examples/05_exploring_real_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.2916011810302734,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/exercises/01_text_preprocessing_exercise.ipynb",
      "status": "failed",
      "execution_time": 0.730445146560669,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\\n\n%pip install nltk pandas -q\\n\n\\ni\nmport nltk\\ni\nmport pandas as pd\\ni\nmport re\\nf\nrom nltk.corpus import stopwords\\nf\nrom nltk.tokenize import word_tokenize\\nf\nrom nltk.stem import PorterStemmer, WordNetLemmatizer\\n\n\\nn\nltk.download('punkt', quiet=True)\\nn\nltk.download('stopwords', quiet=True)\\nn\nltk.download('wordnet', quiet=True)\\np\nrint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\ni\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\\n\n%pip install nltk pandas -q\\n\n\\ni\nmport nltk\\ni\nmport pandas as pd\\ni\nmport re\\nf\nrom nltk.corpus import stopwords\\nf\nrom nltk.tokenize import word_tokenize\\nf\nrom nltk.stem import PorterStemmer, WordNetLemmatizer\\n\n\\nn\nltk.download('punkt', quiet=True)\\nn\nltk.download('stopwords', quiet=True)\\nn\nltk.download('wordnet', quiet=True)\\np\nrint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\ni\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n\n\n",
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit1-nlp-fundamentals/solutions/01_text_preprocessing_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7470839023590088,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install nltk pandas -q\nimport nltk\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom collections import Counter_nltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections import Counter_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install nltk pandas -q\nimport nltk\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom collections import Counter_nltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections import Counter_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit1-nlp-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/01_advanced_tokenization.ipynb",
      "status": "passed",
      "execution_time": 0.8458340167999268,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/02_text_vectorization_bow_tfidf.ipynb",
      "status": "passed",
      "execution_time": 0.9537479877471924,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/03_word_embeddings_word2vec.ipynb",
      "status": "passed",
      "execution_time": 1.7173781394958496,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/04_word_embeddings_glove_fasttext.ipynb",
      "status": "failed",
      "execution_time": 0.6665658950805664,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom gensim.models \nimport KeyedVectors\nimport gensim.downloader as api\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained Word Embeddings: GloVe and FastText\")\nprint(\"=\" * 60)\n\nprint(\"\\nGloVe (Global Vectors):\")\nprint(\" - Global co-occurrence statistics\")\nprint(\" - Pre-trained on large corpora\")\nprint(\" - Available in multiple dimensions\")\n\nprint(\"\\nFastText:\")\nprint(\" - Subword information\")\nprint(\" - Handles out-of-vocabulary words\")\nprint(\" - Character n-grams\")\n\nprint(\"\\nApplications:\")\nprint(\" - Word similarity\")\nprint(\" - Text classification\")\nprint(\" - Semantic analysis\")\nprint(\" - Transfer learning\")\n\nprint(\"\\n\u2705 Pre-trained embeddings concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gensim.models\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom gensim.models \nimport KeyedVectors\nimport gensim.downloader as api\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nPre-trained Word Embeddings: GloVe and FastText\")\nprint(\"=\" * 60)\n\nprint(\"\\nGloVe (Global Vectors):\")\nprint(\" - Global co-occurrence statistics\")\nprint(\" - Pre-trained on large corpora\")\nprint(\" - Available in multiple dimensions\")\n\nprint(\"\\nFastText:\")\nprint(\" - Subword information\")\nprint(\" - Handles out-of-vocabulary words\")\nprint(\" - Character n-grams\")\n\nprint(\"\\nApplications:\")\nprint(\" - Word similarity\")\nprint(\" - Text classification\")\nprint(\" - Semantic analysis\")\nprint(\" - Transfer learning\")\n\nprint(\"\\n\u2705 Pre-trained embeddings concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gensim.models\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/applying_dimensionality_reduction_on_high_dimensional_vectors_and_visualizing_re.ipynb",
      "status": "passed",
      "execution_time": 1.748701810836792,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/implementing_basic_text_processing_techniques_using_nltk_and_spacy.ipynb",
      "status": "passed",
      "execution_time": 1.3537137508392334,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/implementing_bert_embeddings_using_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.4000120162963867,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/performing_tokenization_stemming_and_lemmatization_on_sample_datasets.ipynb",
      "status": "passed",
      "execution_time": 1.2615549564361572,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/examples/writing_a_simple_text_conversion_script_using_python.ipynb",
      "status": "passed",
      "execution_time": 1.5013909339904785,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "example"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/exercises/01_tokenization_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.9653539657592773,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit2-tokenization-morphology/solutions/01_tokenization_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7261559963226318,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install nltk -q\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re_nltk.download('punkt', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    import re_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install nltk -q\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re_nltk.download('punkt', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    import re_nltk.download('punkt', quiet=True)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit2-tokenization-morphology",
      "type": "other"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/01_text_classification.ipynb",
      "status": "passed",
      "execution_time": 1.3467001914978027,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/02_named_entity_recognition.ipynb",
      "status": "passed",
      "execution_time": 1.8306429386138916,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/03_topic_modeling_lda_nmf.ipynb",
      "status": "passed",
      "execution_time": 0.8958978652954102,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/examples/04_model_evaluation_metrics_nlp.ipynb",
      "status": "passed",
      "execution_time": 1.3488891124725342,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/exercises/01_sentiment_classification_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.828969955444336,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit3-ml-for-nlp/solutions/01_sentiment_classification_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5126500129699707,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pandas scikit-learn nltk -q\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk_nltk.download('stopwords', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nltk_nltk.download('stopwords', quiet=True)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pandas scikit-learn nltk -q\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk_nltk.download('stopwords', quiet=True)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nltk_nltk.download('stopwords', quiet=True)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit3-ml-for-nlp",
      "type": "other"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/01_rnn_lstm_nlp.ipynb",
      "status": "passed",
      "execution_time": 0.5713107585906982,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/02_lstm_text_generation.ipynb",
      "status": "passed",
      "execution_time": 0.6599609851837158,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/03_bert_advanced_usage.ipynb",
      "status": "failed",
      "execution_time": 7.276197910308838,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Try importing Hugging Face Transformers\ntry:\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n    from transformers import pipeline\n    HAS_TRANSFORMERS = True\n    print(\"\u2705 Hugging Face Transformers available!\")\nexcept ImportError:\n    HAS_TRANSFORMERS = False\n    print(\"\u26a0\ufe0f  Transformers not available. Install with: pip install transformers\")\n\n# Try importing TensorFlow/Keras\ntry:\n    import tensorflow as tf\n    from tensorflow import keras\n    HAS_TF = True\n    print(\"\u2705 TensorFlow/Keras available!\")\nexcept ImportError:\n    HAS_TF = False\n    print(\"\u26a0\ufe0f  TensorFlow not available. Install with: pip install tensorflow\")\n\nprint(\"\\n\u2705 Libraries imported!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Try importing Hugging Face Transformers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     10\u001b[0m     HAS_TRANSFORMERS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\nFile \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:42\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Optional, Union\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ruff: isort: off\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# ruff: isort: on\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhf_hub_utils\u001b[39;00m\n\nFile \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/integrations/integration_utils.py:60\u001b[0m\n\u001b[1;32m     57\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TFPreTrainedModel\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\nFile \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    initially created. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Also see\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    https://huggingface.co/papers/1606.08415\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\n\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Try importing Hugging Face Transformers\ntry:\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n    from transformers import pipeline\n    HAS_TRANSFORMERS = True\n    print(\"\u2705 Hugging Face Transformers available!\")\nexcept ImportError:\n    HAS_TRANSFORMERS = False\n    print(\"\u26a0\ufe0f  Transformers not available. Install with: pip install transformers\")\n\n# Try importing TensorFlow/Keras\ntry:\n    import tensorflow as tf\n    from tensorflow import keras\n    HAS_TF = True\n    print(\"\u2705 TensorFlow/Keras available!\")\nexcept ImportError:\n    HAS_TF = False\n    print(\"\u26a0\ufe0f  TensorFlow not available. Install with: pip install tensorflow\")\n\nprint(\"\\n\u2705 Libraries imported!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Try importing Hugging Face Transformers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     10\u001b[0m     HAS_TRANSFORMERS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\nFile \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:42\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Optional, Union\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ruff: isort: off\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# ruff: isort: on\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhf_hub_utils\u001b[39;00m\n\nFile \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/integrations/integration_utils.py:60\u001b[0m\n\u001b[1;32m     57\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TFPreTrainedModel\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\nFile \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    initially created. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Also see\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    https://huggingface.co/papers/1606.08415\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\n\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n\n",
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/04_seq2seq_attention_translation.ipynb",
      "status": "passed",
      "execution_time": 3.093993902206421,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/05_gpt_openai_text_generation.ipynb",
      "status": "passed",
      "execution_time": 0.744347095489502,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/06_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 0.5169479846954346,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/07_building_simple_chatbot.ipynb",
      "status": "passed",
      "execution_time": 0.5357949733734131,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/building_a_simple_chatbot.ipynb",
      "status": "passed",
      "execution_time": 1.4173531532287598,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/building_an_lstm_based_text_classifier_using_tensorflowkeras.ipynb",
      "status": "passed",
      "execution_time": 1.5593600273132324,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/fine_tuning_bert_model_for_text_classification_using_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.4976160526275635,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/examples/implementing_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 1.5069689750671387,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "example"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/exercises/01_ner_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.156761884689331,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit4-deep-learning-nlp/solutions/01_ner_solution.ipynb",
      "status": "failed",
      "execution_time": 1.3755481243133545,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install spacy -q\n# Note: Requires: python -m spacy download en_core_web_sm\nimport spacy_\nprint('\ud83d\udcdd NER Solution Concept:')\nprint('\\n1. Load spaCy model: nlp = spacy.load(\"en_core_web_sm\")')\nprint('2. Process text: doc = nlp(text)')\nprint('3. Extract entities: doc.ents')\nprint('4. Classify: entity.label_')\nprint('\\n\u2705 NER solution understood!')\nprint('\\nReal-world: Extract key information from news articles')\n------------------\n\n----- stdout -----\nNote: you may need to restart the kernel to use updated packages.\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall spacy -q\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: Requires: python -m spacy download en_core_web_sm\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy_\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\ud83d\udcdd NER Solution Concept:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. Load spaCy model: nlp = spacy.load(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy_'\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install spacy -q\n# Note: Requires: python -m spacy download en_core_web_sm\nimport spacy_\nprint('\ud83d\udcdd NER Solution Concept:')\nprint('\\n1. Load spaCy model: nlp = spacy.load(\"en_core_web_sm\")')\nprint('2. Process text: doc = nlp(text)')\nprint('3. Extract entities: doc.ents')\nprint('4. Classify: entity.label_')\nprint('\\n\u2705 NER solution understood!')\nprint('\\nReal-world: Extract key information from news articles')\n------------------\n\n----- stdout -----\nNote: you may need to restart the kernel to use updated packages.\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall spacy -q\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: Requires: python -m spacy download en_core_web_sm\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy_\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\ud83d\udcdd NER Solution Concept:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. Load spaCy model: nlp = spacy.load(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\n\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy_'\n\n",
      "course": "Course 07",
      "unit": "unit4-deep-learning-nlp",
      "type": "other"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/01_bias_detection.ipynb",
      "status": "passed",
      "execution_time": 0.6062898635864258,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/02_text_summarization.ipynb",
      "status": "passed",
      "execution_time": 0.6499619483947754,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/examples/03_chatbot_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.8722751140594482,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "example"
    },
    {
      "path": "Course 07/unit5-applications-ethics/exercises/01_nlp_applications_ethics_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.2060132026672363,
      "error": null,
      "error_traceback": null,
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "exercise"
    },
    {
      "path": "Course 07/unit5-applications-ethics/solutions/01_nlp_applications_ethics_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7235908508300781,
      "error": "An error occurred while executing the following cell:\n------------------\n# Setup\n%pip install nltk transformers torch pandas numpy matplotlib seaborn -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections \nimport Counter_\nprint('\u2705 Setup complete!')\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Setup\n%pip install nltk transformers torch pandas numpy matplotlib seaborn -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections \nimport Counter_\nprint('\u2705 Setup complete!')\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    from collections\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 07",
      "unit": "unit5-applications-ethics",
      "type": "other"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/01_simple_neural_network.ipynb",
      "status": "failed",
      "execution_time": 0.5634028911590576,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 1 - Example 1: Simple Neural Network with Keras\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\n\nThis example demonstrates:\n1. Building a simple neural network2. Training on a dataset3. Making predictions4. Evaluating the model\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Simple Neural Network with Keras\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\")\nprint(\"=\" * 60)\n\n# Note: This example shows the structure. Actual implementation requires TensorFlow.\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u0627\u0644\u0647\u064a\u0643\u0644. \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a \u064a\u062a\u0637\u0644\u0628 TensorFlow. print(\"\\nNeural Network Structure:\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629:\")\nprint(\"-\" * 60)\nnetwork_structure = \"\"\"\nModel: Sequential\n\u251c\u2500\u2500 Input Layer: 784 neurons (for 28\nx28 images)\n\u251c\u2500\u2500 Hidden Layer 1: 128 neurons, ReLU activation\n\u251c\u2500\u2500 Hidden Layer 2: 64 neurons, ReLU activation\n\u2514\u2500\u2500 Output Layer: 10 neurons, Softmax activation (for 10 classes)\n\"\"\"\n\nprint(network_structure)\nprint(\"\\nCode Structure (using Keras):\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0643\u0648\u062f (\u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras):\")\nprint(\"-\" * 60)\ncode_example = \"\"\"\nfrom tensorflow \nimport kerasf\nrom tensorflow.keras import layers\n\n# Create mode\nlm\nodel = keras.Sequential([\n layers.Dense(128, activation='relu', input_shape=(784,)),\n layers.Dense(64, activation='relu'),\n layers.Dense(10, activation='softmax')\n])\n\n# Compile mode\nlm\nodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n metrics=['accuracy']\n)\n\n# Train mode\nlm\nodel.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n# Evaluate\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test accuracy: {accuracy}')\n\"\"\"\n\nprint(code_example)\nprint(\"\\nKey Concepts:\")\nprint(\"\u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629:\")\nprint(\"-\" * 60)\nconcepts = {\n \"Dense Layer\": \"Fully connected layer where each neuron connects to all neurons in next layer\", \"ReLU\": \"Rectified Linear Unit - activation function that outputs max(0, x)\",\n \"Softmax\": \"Activation function for multi-class classification\",\n \"Adam Optimizer\": \"Adaptive learning rate optimization algorithm\",\n \"Epochs\": \"Number of times the model sees the entire training dataset\"\n}\n\nfor concept, explanation in concepts.items():\n print(f\"\\n{concept}:\")\nprint(f\" {explanation}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: Install TensorFlow to run actual code:\")\nprint(\"pip install tensorflow\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 1 - Example 1: Simple Neural Network with Keras\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\n\nThis example demonstrates:\n1. Building a simple neural network2. Training on a dataset3. Making predictions4. Evaluating the model\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: Simple Neural Network with Keras\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0634\u0628\u0643\u0629 \u0639\u0635\u0628\u064a\u0629 \u0628\u0633\u064a\u0637\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras\")\nprint(\"=\" * 60)\n\n# Note: This example shows the structure. Actual implementation requires TensorFlow.\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u0627\u0644\u0647\u064a\u0643\u0644. \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a \u064a\u062a\u0637\u0644\u0628 TensorFlow. print(\"\\nNeural Network Structure:\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629:\")\nprint(\"-\" * 60)\nnetwork_structure = \"\"\"\nModel: Sequential\n\u251c\u2500\u2500 Input Layer: 784 neurons (for 28\nx28 images)\n\u251c\u2500\u2500 Hidden Layer 1: 128 neurons, ReLU activation\n\u251c\u2500\u2500 Hidden Layer 2: 64 neurons, ReLU activation\n\u2514\u2500\u2500 Output Layer: 10 neurons, Softmax activation (for 10 classes)\n\"\"\"\n\nprint(network_structure)\nprint(\"\\nCode Structure (using Keras):\")\nprint(\"\u0647\u064a\u0643\u0644 \u0627\u0644\u0643\u0648\u062f (\u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 Keras):\")\nprint(\"-\" * 60)\ncode_example = \"\"\"\nfrom tensorflow \nimport kerasf\nrom tensorflow.keras import layers\n\n# Create mode\nlm\nodel = keras.Sequential([\n layers.Dense(128, activation='relu', input_shape=(784,)),\n layers.Dense(64, activation='relu'),\n layers.Dense(10, activation='softmax')\n])\n\n# Compile mode\nlm\nodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n metrics=['accuracy']\n)\n\n# Train mode\nlm\nodel.fit(X_train, y_train, epochs=10, validation_split=0.2)\n\n# Evaluate\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test accuracy: {accuracy}')\n\"\"\"\n\nprint(code_example)\nprint(\"\\nKey Concepts:\")\nprint(\"\u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629:\")\nprint(\"-\" * 60)\nconcepts = {\n \"Dense Layer\": \"Fully connected layer where each neuron connects to all neurons in next layer\", \"ReLU\": \"Rectified Linear Unit - activation function that outputs max(0, x)\",\n \"Softmax\": \"Activation function for multi-class classification\",\n \"Adam Optimizer\": \"Adaptive learning rate optimization algorithm\",\n \"Epochs\": \"Number of times the model sees the entire training dataset\"\n}\n\nfor concept, explanation in concepts.items():\n print(f\"\\n{concept}:\")\nprint(f\" {explanation}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: Install TensorFlow to run actual code:\")\nprint(\"pip install tensorflow\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n\n",
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/02_backpropagation_detailed.ipynb",
      "status": "passed",
      "execution_time": 0.8900020122528076,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/03_optimization_techniques.ipynb",
      "status": "passed",
      "execution_time": 0.7365419864654541,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/04_perceptron_mlp_tensorflow_pytorch_setup.ipynb",
      "status": "passed",
      "execution_time": 4.9005022048950195,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/05_image_processing_feature_extraction.ipynb",
      "status": "passed",
      "execution_time": 0.9892280101776123,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/activation_functions_and_optimization_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.5802578926086426,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/deep_learning_fundamentals_compared_to_traditional_ml.ipynb",
      "status": "passed",
      "execution_time": 1.5223627090454102,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/ethical_concerns_in_ai_bias_fairness_interpretability.ipynb",
      "status": "passed",
      "execution_time": 1.6304919719696045,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/forward_and_backward_propagation.ipynb",
      "status": "passed",
      "execution_time": 1.678577184677124,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/gans_and_autoencoders_vaes.ipynb",
      "status": "passed",
      "execution_time": 1.5038971900939941,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/implementing_a_vae_variational_autoencoder_for_anomaly_detection.ipynb",
      "status": "passed",
      "execution_time": 1.6625211238861084,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/examples/reinforcement_learning_fundamentals_deep_q_networks_policy_gradients.ipynb",
      "status": "passed",
      "execution_time": 1.5257251262664795,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "example"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/exercises/01_neural_network_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.1772029399871826,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit1-deep-learning-basics/solutions/01_neural_network_solution.ipynb",
      "status": "passed",
      "execution_time": 2.217919111251831,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit1-deep-learning-basics",
      "type": "other"
    },
    {
      "path": "Course 08/unit2-cnns/examples/01_cnn_architecture.ipynb",
      "status": "failed",
      "execution_time": 0.7387921810150146,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 2 - Example 1: CNN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\n\nThis example demonstrates:\n1. CNN architecture components2. Convolution and pooling operations\n3. Building a simple CNN\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: CNN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\n\n# 1. CNN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a CN\nNp\nrint(\"\\n1. CNN Architecture Components\")\nprint(\"\u0645\u0643\u0648\u0646\u0627\u062a \u0647\u064a\u0643\u0644 CNN\")\nprint(\"-\" * 60)\ncnn_components = \"\"\"\nCNN Architecture:\n1. Convolutional Layers - Detect features (edges, shapes)\n2. Pooling Layers - Reduce dimensionality (Max, Average)\n3. Fully Connected Layers - Classification4. Activation Functions - ReLU, Softmax\n\n\u0647\u064a\u0643\u0644 CNN:\n1. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 - \u0627\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0645\u064a\u0632\u0627\u062a (\u0627\u0644\u062d\u0648\u0627\u0641\u060c \u0627\u0644\u0623\u0634\u0643\u0627\u0644)\n2. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 - \u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f (\u0627\u0644\u062d\u062f \u0627\u0644\u0623\u0642\u0635\u0649\u060c \u0627\u0644\u0645\u062a\u0648\u0633\u0637)\n3. \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0628\u0627\u0644\u0643\u0627\u0645\u0644 - \u0627\u0644\u062a\u0635\u0646\u064a\u06414. \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 - ReLU\u060c Softmax\n\"\"\"\n\nprint(cnn_components)\n\n# 2. Convolution Operation\n# \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Convolution Operation\")\nprint(\"\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641\")\nprint(\"=\" * 60)\ndef simple_convolution_example():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Demonstrate convolution concept.\n \u062a\u0648\u0636\u064a\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641.\n \"\"\"\n # Simple 3\nx3 imag\neimage = [\n [1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]\n ]\n \n # 2\nx2 filter (kernel)\nfilter_kernel = [\n [1, 0],\n [0, -1]\n ]\n \n print(\"\\nImage (3\\nx3):\")\n for row in image:\n print(f\" {row}\")\nprint(\"\\nFilter (2\\nx2):\")\n for row in filter_kernel:\n print(f\" {row}\")\n \n # Apply convolution (simplified)\nresult = []\n for i in range(len(image) - 1):\n row_result = []\n for j in range(len(image[0]) - 1):\n # Element-wise multiplication and sum\n conv_value = (image[i][j] * filter_kernel[0][0] +\n image[i][j+1] * filter_kernel[0][1] +\n image[i+1][j] * filter_kernel[1][0] +\n image[i+1][j+1] * filter_kernel[1][1])\nrow_result.append(conv_value)\nresult.append(row_result)\nprint(\"\\nConvolution Result (2\\nx2):\")\n for row in result:\n print(f\" {row}\")\nsimple_convolution_example()\n\n# 3. CNN Architecture Example\n# \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CN\nNp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. CNN Architecture Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\ncnn_architecture = \"\"\"\nSimple CNN for Image Classification:\n\nInput (28\nx28\nx1) # Grayscale image\n \u2193\nConv2\nD (32 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nConv2\nD (64 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nFlatten\n \u2193\nDense (128) + ReLU\n \u2193\nDense (10) + Softmax # 10 classes\n \u2193\nOutput (10 classes)\n\"\"\"\n\nprint(cnn_architecture)\n\n# 4. Transfer Learning Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Transfer Learning\")\nprint(\"\u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644\")\nprint(\"=\" * 60)\ntransfer_learning = \"\"\"\nTransfer Learning Process:\n1. Use pre-trained model (e.g., ResNet, VGG)\n2. Remove final classification layer3. Add new layers for your task\n4. Fine-tune on your dataset5. Much faster than training from scratch!\n\n\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644:\n1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0645\u0648\u0630\u062c \u0645\u062f\u0631\u0628 \u0645\u0633\u0628\u0642\u0627\u064b (\u0645\u062b\u0644 ResNet\u060c VGG)\n2. \u0625\u0632\u0627\u0644\u0629 \u0637\u0628\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0646\u0647\u0627\u0626\u064a\u06293. \u0625\u0636\u0627\u0641\u0629 \u0637\u0628\u0642\u0627\u062a \u062c\u062f\u064a\u062f\u0629 \u0644\u0645\u0647\u0645\u062a\u06434. \u0627\u0644\u0636\u0628\u0637 \u0627\u0644\u062f\u0642\u064a\u0642 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u062a\u06435. \u0623\u0633\u0631\u0639 \u0628\u0643\u062b\u064a\u0631 \u0645\u0646 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631!\n\"\"\"\n\nprint(transfer_learning)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Neural Network Architecture\n# \u062a\u0635\u0648\u0631: \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n \n fig, ax = plt.subplots(figsize=(12, 8))\n # Draw layers layers = ['Input\n(784)', 'Hidden 1\n(128)', 'Hidden 2\n(64)', 'Output\n(10)']\n x_positions = [1, 3, 5, 7]\n \n for i, (layer, x)\nin enumerate(zip(layers, x_positions)):\n # Draw layer box\n rect = mpatches.Rectangle((x-0.4, 2), 0.8, 4, \n linewidth=2, edgecolor='black', \n facecolor='lightblue', alpha=0.7)\n ax.add_patch(rect)\nax.text(x, 4, layer, ha='center', va='center', fontsize=12, fontweight='bold')\n \n # Draw arrows if i < len(x_positions) - 1:\n ax.arrow(x+0.4, 4, 1.2, 0, head_width=0.3, head_length=0.2, \n fc='black', ec='black', linewidth=2)\nax.set_xlim(0, 8)\nax.set_ylim(0, 7)\nax.set_title('Neural Network Architecture | \u0647\u064a\u0643\u0644 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629', fontsize=16, pad=20, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Network architecture diagram displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib for architecture diagrams\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0627\u0644\u0647\u064a\u0643\u0644\")\n\n\"\"\"\nUnit 2 - Example 1: CNN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\n\nThis example demonstrates:\n1. CNN architecture components2. Convolution and pooling operations\n3. Building a simple CNN\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Example 1: CNN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\n\n# 1. CNN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a CN\nNp\nrint(\"\\n1. CNN Architecture Components\")\nprint(\"\u0645\u0643\u0648\u0646\u0627\u062a \u0647\u064a\u0643\u0644 CNN\")\nprint(\"-\" * 60)\ncnn_components = \"\"\"\nCNN Architecture:\n1. Convolutional Layers - Detect features (edges, shapes)\n2. Pooling Layers - Reduce dimensionality (Max, Average)\n3. Fully Connected Layers - Classification4. Activation Functions - ReLU, Softmax\n\n\u0647\u064a\u0643\u0644 CNN:\n1. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 - \u0627\u0643\u062a\u0634\u0627\u0641 \u0627\u0644\u0645\u064a\u0632\u0627\u062a (\u0627\u0644\u062d\u0648\u0627\u0641\u060c \u0627\u0644\u0623\u0634\u0643\u0627\u0644)\n2. \u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 - \u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u0623\u0628\u0639\u0627\u062f (\u0627\u0644\u062d\u062f \u0627\u0644\u0623\u0642\u0635\u0649\u060c \u0627\u0644\u0645\u062a\u0648\u0633\u0637)\n3. \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0628\u0627\u0644\u0643\u0627\u0645\u0644 - \u0627\u0644\u062a\u0635\u0646\u064a\u06414. \u062f\u0648\u0627\u0644 \u0627\u0644\u062a\u0646\u0634\u064a\u0637 - ReLU\u060c Softmax\n\"\"\"\n\nprint(cnn_components)\n\n# 2. Convolution Operation\n# \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Convolution Operation\")\nprint(\"\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641\")\nprint(\"=\" * 60)\ndef simple_convolution_example():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Demonstrate convolution concept.\n \u062a\u0648\u0636\u064a\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641.\n \"\"\"\n # Simple 3\nx3 imag\neimage = [\n [1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]\n ]\n \n # 2\nx2 filter (kernel)\nfilter_kernel = [\n [1, 0],\n [0, -1]\n ]\n \n print(\"\\nImage (3\\nx3):\")\n for row in image:\n print(f\" {row}\")\nprint(\"\\nFilter (2\\nx2):\")\n for row in filter_kernel:\n print(f\" {row}\")\n \n # Apply convolution (simplified)\nresult = []\n for i in range(len(image) - 1):\n row_result = []\n for j in range(len(image[0]) - 1):\n # Element-wise multiplication and sum\n conv_value = (image[i][j] * filter_kernel[0][0] +\n image[i][j+1] * filter_kernel[0][1] +\n image[i+1][j] * filter_kernel[1][0] +\n image[i+1][j+1] * filter_kernel[1][1])\nrow_result.append(conv_value)\nresult.append(row_result)\nprint(\"\\nConvolution Result (2\\nx2):\")\n for row in result:\n print(f\" {row}\")\nsimple_convolution_example()\n\n# 3. CNN Architecture Example\n# \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CN\nNp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. CNN Architecture Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0647\u064a\u0643\u0644 CNN\")\nprint(\"=\" * 60)\ncnn_architecture = \"\"\"\nSimple CNN for Image Classification:\n\nInput (28\nx28\nx1) # Grayscale image\n \u2193\nConv2\nD (32 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nConv2\nD (64 filters, 3\nx3) + ReLU\n \u2193\nMaxPooling2\nD (2\nx2)\n \u2193\nFlatten\n \u2193\nDense (128) + ReLU\n \u2193\nDense (10) + Softmax # 10 classes\n \u2193\nOutput (10 classes)\n\"\"\"\n\nprint(cnn_architecture)\n\n# 4. Transfer Learning Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Transfer Learning\")\nprint(\"\u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644\")\nprint(\"=\" * 60)\ntransfer_learning = \"\"\"\nTransfer Learning Process:\n1. Use pre-trained model (e.g., ResNet, VGG)\n2. Remove final classification layer3. Add new layers for your task\n4. Fine-tune on your dataset5. Much faster than training from scratch!\n\n\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u0639\u0644\u0645 \u0628\u0627\u0644\u0646\u0642\u0644:\n1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0646\u0645\u0648\u0630\u062c \u0645\u062f\u0631\u0628 \u0645\u0633\u0628\u0642\u0627\u064b (\u0645\u062b\u0644 ResNet\u060c VGG)\n2. \u0625\u0632\u0627\u0644\u0629 \u0637\u0628\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0646\u0647\u0627\u0626\u064a\u06293. \u0625\u0636\u0627\u0641\u0629 \u0637\u0628\u0642\u0627\u062a \u062c\u062f\u064a\u062f\u0629 \u0644\u0645\u0647\u0645\u062a\u06434. \u0627\u0644\u0636\u0628\u0637 \u0627\u0644\u062f\u0642\u064a\u0642 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u062a\u06435. \u0623\u0633\u0631\u0639 \u0628\u0643\u062b\u064a\u0631 \u0645\u0646 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631!\n\"\"\"\n\nprint(transfer_learning)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    (10)']\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n\n\n",
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/02_cnn_advanced_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.8980057239532471,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/03_transfer_learning_cnns.ipynb",
      "status": "passed",
      "execution_time": 0.7866659164428711,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/04_pretrained_cnn_architectures.ipynb",
      "status": "passed",
      "execution_time": 3.283801794052124,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/05_training_cnn_image_datasets.ipynb",
      "status": "passed",
      "execution_time": 3.0760810375213623,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/06_transfer_learning_object_detection.ipynb",
      "status": "passed",
      "execution_time": 3.0585989952087402,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/cnn_architecture_convolutional_layers_pooling_layers_fully_connected_layers.ipynb",
      "status": "passed",
      "execution_time": 1.3978228569030762,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/image_processing_fundamentals_and_feature_extraction.ipynb",
      "status": "passed",
      "execution_time": 1.5747315883636475,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/implementing_a_cnn_from_scratch_using_tensorflowpytorch.ipynb",
      "status": "passed",
      "execution_time": 1.62105393409729,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/introduction_to_pre_trained_cnn_architectures_resnet_vgg_inception.ipynb",
      "status": "passed",
      "execution_time": 1.4855940341949463,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/examples/training_a_cnn_on_image_datasets_eg_cifar_10_imagenet.ipynb",
      "status": "passed",
      "execution_time": 1.5585968494415283,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit2-cnns/exercises/01_cnn_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.7152647972106934,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit2-cnns/solutions/01_cnn_solution.ipynb",
      "status": "passed",
      "execution_time": 1.9835858345031738,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit2-cnns",
      "type": "other"
    },
    {
      "path": "Course 08/unit3-rnns/examples/01_rnn_basics.ipynb",
      "status": "passed",
      "execution_time": 1.018545150756836,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/02_lstm_advanced.ipynb",
      "status": "passed",
      "execution_time": 0.8054440021514893,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/03_sequence_to_sequence.ipynb",
      "status": "passed",
      "execution_time": 0.7678239345550537,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/04_text_generation_rnn_lstm_gru.ipynb",
      "status": "passed",
      "execution_time": 3.1534006595611572,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/05_transformer_models_bert_gpt_nlp.ipynb",
      "status": "passed",
      "execution_time": 5.665968894958496,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/06_sentiment_analysis_translation_speech.ipynb",
      "status": "passed",
      "execution_time": 5.283288955688477,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/advanced_architectures_lstm_gru_transformers_attention_mechanism.ipynb",
      "status": "passed",
      "execution_time": 1.569732904434204,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/applications_in_nlp.ipynb",
      "status": "passed",
      "execution_time": 1.5768039226531982,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/implementing_rnn_lstm_and_gru_for_text_generation.ipynb",
      "status": "passed",
      "execution_time": 1.5861749649047852,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/performing_sentiment_analysis_machine_translation_and_speech_recognition.ipynb",
      "status": "passed",
      "execution_time": 1.7114429473876953,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/rnn_structure_and_challenges_vanishing_gradients_problem.ipynb",
      "status": "passed",
      "execution_time": 1.716397762298584,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/understanding_sequential_data_and_time_series_prediction.ipynb",
      "status": "passed",
      "execution_time": 1.4481399059295654,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/examples/using_transformer_models_like_bert_and_gpt_for_nlp_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.4130339622497559,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "example"
    },
    {
      "path": "Course 08/unit3-rnns/exercises/01_rnn_exercise.ipynb",
      "status": "failed",
      "execution_time": 2.449767827987671,
      "error": "An error occurred while executing the following cell:\n------------------\n# TODO: Generate synthetic time series data\n# Hint: Use sine wave + trend + noise\ndef generate_stock_data(n_samples=1000):\n # YOUR CODE HERE\n pass\n\n# Test\ndata = generate_stock_data()\nplt.plot(data[:100])\nplt.title('Stock Price Data')\nplt.show()\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_stock_data()\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Price Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# TODO: Generate synthetic time series data\n# Hint: Use sine wave + trend + noise\ndef generate_stock_data(n_samples=1000):\n # YOUR CODE HERE\n pass\n\n# Test\ndata = generate_stock_data()\nplt.plot(data[:100])\nplt.title('Stock Price Data')\nplt.show()\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_stock_data()\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Price Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit3-rnns/solutions/01_rnn_solution.ipynb",
      "status": "failed",
      "execution_time": 2.1780588626861572,
      "error": "An error occurred while executing the following cell:\n------------------\ndef generate_stock_data(n_samples=1000):\n    \n    \n    \n    \"\"\"Generate synthetic stock price data\"\"\"\n_t =  np.linspace(0, 100, n_samples)\n    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)\n    trend = 0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)_noise =  np.random.normal(0, 2, n_samples)\n    noise = np.random.normal(0, 2, n_samples)\n    return trend + seasonality + noise + 100_data = generate_stock_data()\nplt.figure(figsize=(12, 4))\nplt.plot(data[:200])\nplt.title('Synthetic Stock Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.grid(True)\nplt.show()\nprint(f'\u2705 Generated {len(data)} samples')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\ndef generate_stock_data(n_samples=1000):\n    \n    \n    \n    \"\"\"Generate synthetic stock price data\"\"\"\n_t =  np.linspace(0, 100, n_samples)\n    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)\n    trend = 0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\n50)_noise =  np.random.normal(0, 2, n_samples)\n    noise = np.random.normal(0, 2, n_samples)\n    return trend + seasonality + noise + 100_data = generate_stock_data()\nplt.figure(figsize=(12, 4))\nplt.plot(data[:200])\nplt.title('Synthetic Stock Price')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.grid(True)\nplt.show()\nprint(f'\u2705 Generated {len(data)} samples')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    t = np.linspace(0, 100, n_samples)_trend =  0.5 * t_seasonality = 10 * np.sin(2 * np.pi * t\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n\n\n",
      "course": "Course 08",
      "unit": "unit3-rnns",
      "type": "other"
    },
    {
      "path": "Course 08/unit4-transformers/examples/01_transformer_attention.ipynb",
      "status": "passed",
      "execution_time": 0.5267701148986816,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/examples/02_bert_finetuning.ipynb",
      "status": "passed",
      "execution_time": 0.5986599922180176,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/examples/03_gpt_text_generation.ipynb",
      "status": "failed",
      "execution_time": 0.5275447368621826,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch datasets -q\n\nimport torch\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers \nimport Trainer, TrainingArguments\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch datasets -q\n\nimport torch\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers \nimport Trainer, TrainingArguments\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "example"
    },
    {
      "path": "Course 08/unit4-transformers/exercises/01_transformer_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.8134140968322754,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit4-transformers/solutions/01_transformer_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6087501049041748,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Use pre-trained translation model_model_name = 'Helsinki-NLP/opus-mt-en-de'\ntokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\nprint('\u2705 Translation model loaded')\nprint('\\nTeaching Notes: Use pre-trained transformer models for translation')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Use pre-trained translation model_model_name = 'Helsinki-NLP/opus-mt-en-de'\ntokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\nprint('\u2705 Translation model loaded')\nprint('\\nTeaching Notes: Use pre-trained transformer models for translation')\nprint('Grading: Task 1 (35pts), Task 2 (30pts), Task 3 (35pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer = MarianTokenizer.from_pretrained(model_name)_model =  MarianMTModel.from_pretrained(model_name)\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit4-transformers",
      "type": "other"
    },
    {
      "path": "Course 08/unit5-deployment/examples/01_model_optimization.ipynb",
      "status": "passed",
      "execution_time": 0.7348330020904541,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/02_tensorflow_serving.ipynb",
      "status": "failed",
      "execution_time": 4.321418046951294,
      "error": "An error occurred while executing the following cell:\n------------------\n# Create a simple model for demonstration\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n tf.keras.layers.Dense(32, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Save in SavedModel format\nmodel_path = './saved_model'\nmodel.save(model_path, save_format='tf')\nprint(f'\u2705 Model saved to {model_path}')\n------------------\n\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save in SavedModel format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\u2705 Model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:69\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend removing this argument as it can be inferred \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the file path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\n\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Create a simple model for demonstration\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n tf.keras.layers.Dense(32, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Save in SavedModel format\nmodel_path = './saved_model'\nmodel.save(model_path, save_format='tf')\nprint(f'\u2705 Model saved to {model_path}')\n------------------\n\n----- stderr -----\n/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\nCell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save in SavedModel format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\u2705 Model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:69\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend removing this argument as it can be inferred \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the file path. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\n\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf\n\n",
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/03_onnx_conversion.ipynb",
      "status": "failed",
      "execution_time": 0.6491141319274902,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch onnx onnxruntime -q\nimport torch\nimport torch.nn as nn\nimport onnx\nimport onnxruntime as ortprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import onnxruntime as ortprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch onnx onnxruntime -q\nimport torch\nimport torch.nn as nn\nimport onnx\nimport onnxruntime as ortprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import onnxruntime as ortprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/04_model_pruning.ipynb",
      "status": "passed",
      "execution_time": 0.905400276184082,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/05_model_distillation.ipynb",
      "status": "passed",
      "execution_time": 0.661815881729126,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/06_flask_fastapi_deployment.ipynb",
      "status": "passed",
      "execution_time": 1.7308859825134277,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/07_model_optimization_quantization.ipynb",
      "status": "passed",
      "execution_time": 3.0731961727142334,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/cloud_deployment_of_deep_learning_models.ipynb",
      "status": "passed",
      "execution_time": 1.4150309562683105,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/model_compression_for_edge_devices.ipynb",
      "status": "passed",
      "execution_time": 1.6845319271087646,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/optimizing_deep_learning_models_using_regularization.ipynb",
      "status": "passed",
      "execution_time": 1.42262601852417,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/regularization_and_hyperparameter_tuning.ipynb",
      "status": "passed",
      "execution_time": 1.6738159656524658,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/examples/regularization_techniques_dropout_batch_normalization.ipynb",
      "status": "passed",
      "execution_time": 1.5456061363220215,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "example"
    },
    {
      "path": "Course 08/unit5-deployment/exercises/01_deep_learning_model_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7410690784454346,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "exercise"
    },
    {
      "path": "Course 08/unit5-deployment/solutions/01_deep_learning_model_deployment_solution.ipynb",
      "status": "passed",
      "execution_time": 0.631033182144165,
      "error": null,
      "error_traceback": null,
      "course": "Course 08",
      "unit": "unit5-deployment",
      "type": "other"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/01_mdp_example.ipynb",
      "status": "passed",
      "execution_time": 0.7665450572967529,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/02_mdp_solving.ipynb",
      "status": "passed",
      "execution_time": 0.7832508087158203,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/03_value_iteration.ipynb",
      "status": "passed",
      "execution_time": 0.8251960277557373,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/04_openai_gym_setup.ipynb",
      "status": "failed",
      "execution_time": 0.7387330532073975,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Interacting with Gym Environments\")\nprint(\"=\" * 60)\n\n# Create environment\nenv = gym.make('CartPole-v1')\n\n# Reset environment\nobservation, info = env.reset()\nprint(f\"\\nInitial observation: {observation}\")\n\n# Take a few random actions\ntotal_reward = 0\nfor step in range(5):\n # Sample random action\n action = env.action_space.sample()\n \n # Take step\n observation, reward, terminated, truncated, info = env.step(action)\n \n done = terminated or truncated\n total_reward += reward\n \n print(f\"\\nStep {step + 1}:\")\n print(f\" Action: {action}\")\n print(f\" Reward: {reward}\")\n print(f\" Done: {done}\")\n print(f\" Observation: {observation[:2]}...\") # Show first 2 values\n \n if done:\n print(\" Episode ended!\")\n observation, info = env.reset()\n break\n\nprint(f\"\\nTotal reward: {total_reward}\")\nenv.close()\n\nprint(\"\\n\u2705 Environment interaction complete!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" Episode ended!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Interacting with Gym Environments\")\nprint(\"=\" * 60)\n\n# Create environment\nenv = gym.make('CartPole-v1')\n\n# Reset environment\nobservation, info = env.reset()\nprint(f\"\\nInitial observation: {observation}\")\n\n# Take a few random actions\ntotal_reward = 0\nfor step in range(5):\n # Sample random action\n action = env.action_space.sample()\n \n # Take step\n observation, reward, terminated, truncated, info = env.step(action)\n \n done = terminated or truncated\n total_reward += reward\n \n print(f\"\\nStep {step + 1}:\")\n print(f\" Action: {action}\")\n print(f\" Reward: {reward}\")\n print(f\" Done: {done}\")\n print(f\" Observation: {observation[:2]}...\") # Show first 2 values\n \n if done:\n print(\" Episode ended!\")\n observation, info = env.reset()\n break\n\nprint(f\"\\nTotal reward: {total_reward}\")\nenv.close()\n\nprint(\"\\n\u2705 Environment interaction complete!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\" Episode ended!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/05_exploration_strategies_epsilon_greedy.ipynb",
      "status": "passed",
      "execution_time": 0.9208502769470215,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/06_solving_rl_problems_states_actions_rewards.ipynb",
      "status": "failed",
      "execution_time": 0.8417298793792725,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Designing Reward Functions\")\nprint(\"=\" * 60)\n\nprint(\"\\nReward Function Design Principles:\")\nprint(\" 1. Provide clear feedback (positive for good, negative for bad)\")\nprint(\" 2. Shape rewards to guide learning (sparse vs dense)\")\nprint(\" 3. Balance immediate vs long-term rewards\")\nprint(\" 4. Avoid reward hacking (unintended behaviors)\")\n\n# Test CartPole rewards\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint(\"\\nCartPole-v1 Reward Function:\")\nprint(\" +1 for each step the pole remains balanced\")\nprint(\" Episode ends when pole falls or cart goes out of bounds\")\nprint(\" Maximum reward: 500 (episode length limit)\")\n\ntotal_reward = 0\nfor step in range(10):\n action = env.action_space.sample()\n obs, reward, terminated, truncated, info = env.step(action)\n done = terminated or truncated\n total_reward += reward\n print(f\" Step {step+1}: Reward = {reward}, Total = {total_reward}\")\n if done:\n break\n\nenv.close()\n\nprint(\"\\n\u2705 Reward functions understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 27\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 3: Designing Reward Functions\")\nprint(\"=\" * 60)\n\nprint(\"\\nReward Function Design Principles:\")\nprint(\" 1. Provide clear feedback (positive for good, negative for bad)\")\nprint(\" 2. Shape rewards to guide learning (sparse vs dense)\")\nprint(\" 3. Balance immediate vs long-term rewards\")\nprint(\" 4. Avoid reward hacking (unintended behaviors)\")\n\n# Test CartPole rewards\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint(\"\\nCartPole-v1 Reward Function:\")\nprint(\" +1 for each step the pole remains balanced\")\nprint(\" Episode ends when pole falls or cart goes out of bounds\")\nprint(\" Maximum reward: 500 (episode length limit)\")\n\ntotal_reward = 0\nfor step in range(10):\n action = env.action_space.sample()\n obs, reward, terminated, truncated, info = env.step(action)\n done = terminated or truncated\n total_reward += reward\n print(f\" Step {step+1}: Reward = {reward}, Total = {total_reward}\")\n if done:\n break\n\nenv.close()\n\nprint(\"\\n\u2705 Reward functions understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[4], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 27\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/07_mini_projects_cartpole_frozenlake_qlearning_dqn.ipynb",
      "status": "failed",
      "execution_time": 1.0279901027679443,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Q-Learning Algorithm Implementation\")\nprint(\"=\" * 60)\n\ndef epsilon_greedy_action(q_table, state, epsilon, n_actions):\n \n    \n    \"\"\"Choose action using epsilon-greedy strategy.\"\"\"\n if random.random() < epsilon:\n return random.randint(0, n_actions - 1)\n else:\n return np.argmax(q_table[state])\n\ndef q_learning_update(q_table, state, action, reward, next_state, alpha, gamma):\n \n    \n    \"\"\"\n Q-learning update rule:\n Q(s,a) = Q(s,a) + \u03b1[r + \u03b3 * max(Q(s',a')) - Q(s,a)]\n \"\"\"\n current_q = q_table[state, action]\n max_next_q = np.max(q_table[next_state])\n new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n q_table[state, action] = new_q\n return q_table\n\nprint(\"\\nQ-Learning Algorithm:\")\nprint(\" 1. Initialize Q-table (states \u00d7 actions)\")\nprint(\" 2. For each episode:\")\nprint(\" a. Initialize state\")\nprint(\" b. While not done:\")\nprint(\" - Choose action using epsilon-greedy\")\nprint(\" - Take action, observe reward and next state\")\nprint(\" - Update Q-table: Q(s,a) = Q(s,a) + \u03b1[r + \u03b3*max(Q(s',a')) - Q(s,a)]\")\nprint(\" - Set state = next_state\")\nprint(\" 3. Return Q-table\")\n\nprint(\"\\nKey Parameters:\")\nprint(\" - \u03b1 (alpha): Learning rate (0.0 to 1.0)\")\nprint(\" - \u03b3 (gamma): Discount factor (0.0 to 1.0)\")\nprint(\" - \u03b5 (epsilon): Exploration rate\")\nprint(\" - Q-table: State-action value function\")\n\nprint(\"\\n\u2705 Q-Learning algorithm understood!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    if random.random() < epsilon:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"=\" * 60)\nprint(\"Part 1: Q-Learning Algorithm Implementation\")\nprint(\"=\" * 60)\n\ndef epsilon_greedy_action(q_table, state, epsilon, n_actions):\n \n    \n    \"\"\"Choose action using epsilon-greedy strategy.\"\"\"\n if random.random() < epsilon:\n return random.randint(0, n_actions - 1)\n else:\n return np.argmax(q_table[state])\n\ndef q_learning_update(q_table, state, action, reward, next_state, alpha, gamma):\n \n    \n    \"\"\"\n Q-learning update rule:\n Q(s,a) = Q(s,a) + \u03b1[r + \u03b3 * max(Q(s',a')) - Q(s,a)]\n \"\"\"\n current_q = q_table[state, action]\n max_next_q = np.max(q_table[next_state])\n new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n q_table[state, action] = new_q\n return q_table\n\nprint(\"\\nQ-Learning Algorithm:\")\nprint(\" 1. Initialize Q-table (states \u00d7 actions)\")\nprint(\" 2. For each episode:\")\nprint(\" a. Initialize state\")\nprint(\" b. While not done:\")\nprint(\" - Choose action using epsilon-greedy\")\nprint(\" - Take action, observe reward and next state\")\nprint(\" - Update Q-table: Q(s,a) = Q(s,a) + \u03b1[r + \u03b3*max(Q(s',a')) - Q(s,a)]\")\nprint(\" - Set state = next_state\")\nprint(\" 3. Return Q-table\")\n\nprint(\"\\nKey Parameters:\")\nprint(\" - \u03b1 (alpha): Learning rate (0.0 to 1.0)\")\nprint(\" - \u03b3 (gamma): Discount factor (0.0 to 1.0)\")\nprint(\" - \u03b5 (epsilon): Exploration rate\")\nprint(\" - Q-table: State-action value function\")\n\nprint(\"\\n\u2705 Q-Learning algorithm understood!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    if random.random() < epsilon:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/exploration_strategies_programming_epsilon_greedy_strategy_and_visualizing_its_i.ipynb",
      "status": "passed",
      "execution_time": 1.4973061084747314,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/mini_projects_applying_rl_in_games_like_cartpole_and_frozenlake_implementing_q_l.ipynb",
      "status": "failed",
      "execution_time": 0.748790979385376,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/setting_up_rl_environment_installing_openai_gym_and_using_python_based_framework.ipynb",
      "status": "failed",
      "execution_time": 0.5351459980010986,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/examples/solving_rl_problems_defining_states_actions_and_rewards_running_rl_simulations.ipynb",
      "status": "passed",
      "execution_time": 1.6311960220336914,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/exercises/01_rl_fundamentals_and_mdps_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.5958950519561768,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit1-rl-fundamentals/solutions/01_rl_fundamentals_and_mdps_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5982029438018799,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit1-rl-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/01_q_learning.ipynb",
      "status": "passed",
      "execution_time": 0.924170970916748,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/02_sarsa_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.9410638809204102,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/03_policy_gradient_basics.ipynb",
      "status": "passed",
      "execution_time": 0.9064218997955322,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/04_monte_carlo_value_estimation.ipynb",
      "status": "failed",
      "execution_time": 0.7788290977478027,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: First-Visit Monte Carlo Implementation\")\nprint(\"=\" * 60)\n\ndef generate_episode(policy, env, max_steps=100):\n \n    \n    \"\"\"Generate an episode following the policy.\"\"\"\n episode = []\n state = env.reset()[0] if hasattr(env.reset(), '__len__') else env.reset()\n \n for step in range(max_steps):\n # Choose action based on policy\n if isinstance(policy, dict):\n action = policy.get(state, random.choice(range(env.action_space.n)))\n else:\n action = policy(state)\n \n # Take action (simplified - assuming env.step returns tuple)\n if hasattr(env, 'step'):\n next_state, reward, done, truncated, info = env.step(action) if hasattr(env.step(action), '__len__') and len(env.step(action)) > 1 else (None, 0, True, False, {})\n if isinstance(env.step(action), tuple) and len(env.step(action)) >= 2:\n next_state, reward = env.step(action)[:2]\n done = env.step(action)[2] if len(env.step(action)) > 2 else Falseelse:\n next_state, reward, done = state, 0, Trueelse:\n next_state, reward, done = state, 0, True\n \n episode.append((state, action, reward))\n state = next_state\n \n if done:\n break\n \n return episode\n\ndef first_visit_mc(policy, env, n_episodes=1000, gamma=0.99):\n \n    \n    \"\"\"\n First-visit Monte Carlo for estimating state values.\n \"\"\"\n returns = defaultdict(list)\n V = defaultdict(float)\n \n for episode_num in range(n_episodes):\n episode = generate_episode(policy, env)\n \n # Calculate returns\n G = 0\n visited_states = set()\n \n # Process episode backwards\n for t in reversed(range(len(episode))):\n state, action, reward = episode[t]\n G = gamma * G + reward\n \n # First-visit: only update if state not visited yet in this episode\n if state not in visited_states:\n visited_states.add(state)\n returns[state].append(G)\n V[state] = np.mean(returns[state])\n \n return V, returns\n\n# Simple example: Random walk\nprint(\"\\nExample: Simple Random Walk\")\nprint(\" States: [0, 1, 2, 3, 4]\")\nprint(\" Actions: Move left (-1) or right (+1)\")\nprint(\" Goal: Estimate state values\")\n\n# Simplified environment simulation\nclass SimpleRandomWalk:\n \ndef__init__(self):\n self.state = 2\n self.n_states = 5\n \n def reset(self):\n self.state = 2\n return self.state\n \n def step(self, action):\n self.state = max(0, min(4, self.state + action))\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state in [0, 4]\n return self.state, reward, done\n \n @property\n def action_space(self):\n class Space:\n n = 2\n return Space()\n\n# Random policy\ndef random_policy(state):\n return random.choice([-1, 1])\n\nenv_simple = SimpleRandomWalk()\nV_mc, returns_mc = first_visit_mc(random_policy, env_simple, n_episodes=100, gamma=1.0)\n\nprint(f\"\\nEstimated State Values (First-Visit MC):\")\nfor state in sorted(V_mc.keys()):\n print(f\" V({state}) = {V_mc[state]:.4f} (from {len(returns_mc[state])} visits)\")\n\nprint(\"\\n\u2705 First-visit Monte Carlo implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    episode = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: First-Visit Monte Carlo Implementation\")\nprint(\"=\" * 60)\n\ndef generate_episode(policy, env, max_steps=100):\n \n    \n    \"\"\"Generate an episode following the policy.\"\"\"\n episode = []\n state = env.reset()[0] if hasattr(env.reset(), '__len__') else env.reset()\n \n for step in range(max_steps):\n # Choose action based on policy\n if isinstance(policy, dict):\n action = policy.get(state, random.choice(range(env.action_space.n)))\n else:\n action = policy(state)\n \n # Take action (simplified - assuming env.step returns tuple)\n if hasattr(env, 'step'):\n next_state, reward, done, truncated, info = env.step(action) if hasattr(env.step(action), '__len__') and len(env.step(action)) > 1 else (None, 0, True, False, {})\n if isinstance(env.step(action), tuple) and len(env.step(action)) >= 2:\n next_state, reward = env.step(action)[:2]\n done = env.step(action)[2] if len(env.step(action)) > 2 else Falseelse:\n next_state, reward, done = state, 0, Trueelse:\n next_state, reward, done = state, 0, True\n \n episode.append((state, action, reward))\n state = next_state\n \n if done:\n break\n \n return episode\n\ndef first_visit_mc(policy, env, n_episodes=1000, gamma=0.99):\n \n    \n    \"\"\"\n First-visit Monte Carlo for estimating state values.\n \"\"\"\n returns = defaultdict(list)\n V = defaultdict(float)\n \n for episode_num in range(n_episodes):\n episode = generate_episode(policy, env)\n \n # Calculate returns\n G = 0\n visited_states = set()\n \n # Process episode backwards\n for t in reversed(range(len(episode))):\n state, action, reward = episode[t]\n G = gamma * G + reward\n \n # First-visit: only update if state not visited yet in this episode\n if state not in visited_states:\n visited_states.add(state)\n returns[state].append(G)\n V[state] = np.mean(returns[state])\n \n return V, returns\n\n# Simple example: Random walk\nprint(\"\\nExample: Simple Random Walk\")\nprint(\" States: [0, 1, 2, 3, 4]\")\nprint(\" Actions: Move left (-1) or right (+1)\")\nprint(\" Goal: Estimate state values\")\n\n# Simplified environment simulation\nclass SimpleRandomWalk:\n \ndef__init__(self):\n self.state = 2\n self.n_states = 5\n \n def reset(self):\n self.state = 2\n return self.state\n \n def step(self, action):\n self.state = max(0, min(4, self.state + action))\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state in [0, 4]\n return self.state, reward, done\n \n @property\n def action_space(self):\n class Space:\n n = 2\n return Space()\n\n# Random policy\ndef random_policy(state):\n return random.choice([-1, 1])\n\nenv_simple = SimpleRandomWalk()\nV_mc, returns_mc = first_visit_mc(random_policy, env_simple, n_episodes=100, gamma=1.0)\n\nprint(f\"\\nEstimated State Values (First-Visit MC):\")\nfor state in sorted(V_mc.keys()):\n print(f\" V({state}) = {V_mc[state]:.4f} (from {len(returns_mc[state])} visits)\")\n\nprint(\"\\n\u2705 First-visit Monte Carlo implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    episode = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/05_td_algorithms_td0_nstep.ipynb",
      "status": "failed",
      "execution_time": 0.7895891666412354,
      "error": "An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: TD(0) Implementation\")\nprint(\"=\" * 60)\n\ndef td0(policy, env_simulator, n_episodes=100, alpha=0.1, gamma=0.99):\n \n    \n    \"\"\"\n TD(0) for estimating state values.\n V(S_t) \u2190 V(S_t) + \u03b1[R_{t+1} + \u03b3V(S_{t+1}) - V(S_t)]\n \"\"\"\n V = defaultdict(float)\n \n for episode in range(n_episodes):\n state = env_simulator.reset()\n done = False\n \n while not done:\n # Choose action (simplified)\n action = policy(state) if callable(policy) else policy.get(state, 0)\n \n # Take step (simplified - assuming env interface)\n next_state, reward, done = env_simulator.step(action)\n \n # TD(0) update\n td_target = reward + gamma * V[next_state]\n td_error = td_target - V[state]\n V[state] = V[state] + alpha * td_error\n \n state = next_state\n \n return V\n\n# Simple example\nclass SimpleEnv:\n \ndef__init__(self):\n self.state = 1\n self.n_states = 5\n \n def reset(self):\n self.state = 1\n return self.state\n \n def step(self, action):\n # Simple transition: move towards goal (state 4)\n if self.state < 4:\n self.state += 1\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state == 4\n return self.state, reward, done\n\nenv = SimpleEnv()\ndef simple_policy(state):\n return 1 # Always move forward\n\nV_td0 = td0(simple_policy, env, n_episodes=100, alpha=0.1, gamma=1.0)\n\nprint(\"\\nTD(0) Estimated State Values:\")\nfor state in sorted(V_td0.keys()):\n print(f\" V({state}) = {V_td0[state]:.4f}\")\n\nprint(\"\\n\u2705 TD(0) implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    V = defaultdict(float)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Part 2: TD(0) Implementation\")\nprint(\"=\" * 60)\n\ndef td0(policy, env_simulator, n_episodes=100, alpha=0.1, gamma=0.99):\n \n    \n    \"\"\"\n TD(0) for estimating state values.\n V(S_t) \u2190 V(S_t) + \u03b1[R_{t+1} + \u03b3V(S_{t+1}) - V(S_t)]\n \"\"\"\n V = defaultdict(float)\n \n for episode in range(n_episodes):\n state = env_simulator.reset()\n done = False\n \n while not done:\n # Choose action (simplified)\n action = policy(state) if callable(policy) else policy.get(state, 0)\n \n # Take step (simplified - assuming env interface)\n next_state, reward, done = env_simulator.step(action)\n \n # TD(0) update\n td_target = reward + gamma * V[next_state]\n td_error = td_target - V[state]\n V[state] = V[state] + alpha * td_error\n \n state = next_state\n \n return V\n\n# Simple example\nclass SimpleEnv:\n \ndef__init__(self):\n self.state = 1\n self.n_states = 5\n \n def reset(self):\n self.state = 1\n return self.state\n \n def step(self, action):\n # Simple transition: move towards goal (state 4)\n if self.state < 4:\n self.state += 1\n reward = 1.0 if self.state == 4 else 0.0\n done = self.state == 4\n return self.state, reward, done\n\nenv = SimpleEnv()\ndef simple_policy(state):\n return 1 # Always move forward\n\nV_td0 = td0(simple_policy, env, n_episodes=100, alpha=0.1, gamma=1.0)\n\nprint(\"\\nTD(0) Estimated State Values:\")\nfor state in sorted(V_td0.keys()):\n print(f\" V({state}) = {V_td0[state]:.4f}\")\n\nprint(\"\\n\u2705 TD(0) implemented!\")\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:12\u001b[0;36m\u001b[0m\n\u001b[0;31m    V = defaultdict(float)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/06_policy_vs_value_iteration_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.7166099548339844,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/applying_q_learning_and_sarsa_in_openai_gym_cartpole_frozenlake.ipynb",
      "status": "failed",
      "execution_time": 0.7980837821960449,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/comparing_policy_iteration_vs_value_iteration_through_code_based_experiments.ipynb",
      "status": "passed",
      "execution_time": 1.7090041637420654,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/implementing_monte_carlo_methods_for_estimating_value_functions.ipynb",
      "status": "passed",
      "execution_time": 4.037752151489258,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/running_td0_and_n_step_td_algorithms_in_simple_rl_environments.ipynb",
      "status": "failed",
      "execution_time": 0.7633271217346191,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/examples/using_python_to_update_q_tables_and_display_agent_learning_progress.ipynb",
      "status": "passed",
      "execution_time": 1.449045181274414,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "example"
    },
    {
      "path": "Course 09/unit2-policy-value/exercises/01_q_learning_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7177531719207764,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit2-policy-value/solutions/01_q_learning_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6318070888519287,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass GridWorld:\n    \n\ndef__init__(self, size=5):\n        self.size = size_self.start = (0, 0)\n        self.goal = (size-1, size-1)\n        self.agent_pos = self.start\n    \n    def reset(self):\n        self.agent_pos = self.start\n        return self.agent_pos\n    \n    def step(self, action):\n        moves = {0: (-1,0), 1: (1,0), 2: (0,-1), 3: (0,1)}\n        dx, dy = moves[action]_new_pos =  (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        new_pos = (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        \n        if 0 <= new_pos[0] < self.size and 0 <= new_pos[1] < self.size:\n            self.agent_pos = new_pos_reward = 10 if self.agent_pos == self.goal else -1_done = self.agent_pos == self.goal\n        return self.agent_pos, reward, done\n\nclass QLearningAgent:\n    \n\ndef__init__(self, n_states, n_actions, lr=0.1, gamma=0.95, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr_self.gamma = gamma_self.epsilon = epsilon\n    \n    def select_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(4)\n        return np.argmax(self.q_table[state])\n    \n    def update(self, state, action, reward, next_state, done):\n        if done:\n            target = reward\n        else:\n            target = reward + self.gamma * np.max(self.q_table[next_state])\n        self.q_table[state, action] += self.lr * (target - self.q_table[state, action])\n\nprint('\u2705 Q-learning solution implemented')\nprint('\\nTeaching Notes: Q-table updates, epsilon-greedy exploration')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def reset(self):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\n\nclass GridWorld:\n    \n\ndef__init__(self, size=5):\n        self.size = size_self.start = (0, 0)\n        self.goal = (size-1, size-1)\n        self.agent_pos = self.start\n    \n    def reset(self):\n        self.agent_pos = self.start\n        return self.agent_pos\n    \n    def step(self, action):\n        moves = {0: (-1,0), 1: (1,0), 2: (0,-1), 3: (0,1)}\n        dx, dy = moves[action]_new_pos =  (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        new_pos = (self.agent_pos[0] + dx, self.agent_pos[1] + dy)\n        \n        if 0 <= new_pos[0] < self.size and 0 <= new_pos[1] < self.size:\n            self.agent_pos = new_pos_reward = 10 if self.agent_pos == self.goal else -1_done = self.agent_pos == self.goal\n        return self.agent_pos, reward, done\n\nclass QLearningAgent:\n    \n\ndef__init__(self, n_states, n_actions, lr=0.1, gamma=0.95, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr_self.gamma = gamma_self.epsilon = epsilon\n    \n    def select_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(4)\n        return np.argmax(self.q_table[state])\n    \n    def update(self, state, action, reward, next_state, done):\n        if done:\n            target = reward\n        else:\n            target = reward + self.gamma * np.max(self.q_table[next_state])\n        self.q_table[state, action] += self.lr * (target - self.q_table[state, action])\n\nprint('\u2705 Q-learning solution implemented')\nprint('\\nTeaching Notes: Q-table updates, epsilon-greedy exploration')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def reset(self):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 09",
      "unit": "unit2-policy-value",
      "type": "other"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/01_dqn_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.7319421768188477,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/02_actor_critic.ipynb",
      "status": "passed",
      "execution_time": 2.083796977996826,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/03_ppo_algorithm.ipynb",
      "status": "passed",
      "execution_time": 0.6698522567749023,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/04_training_evaluation_monitoring.ipynb",
      "status": "passed",
      "execution_time": 1.0270729064941406,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/05_optimization_experience_replay_reward_shaping.ipynb",
      "status": "passed",
      "execution_time": 0.6859951019287109,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/applications_applying_deep_rl_in_games_robotics_and_optimization_tasks_in_simula.ipynb",
      "status": "passed",
      "execution_time": 1.4319038391113281,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/handling_challenges_working_on_exploration_vs_exploitation_problems_stability_an.ipynb",
      "status": "passed",
      "execution_time": 1.5000450611114502,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/implementing_deep_rl_starting_with_simple_algorithms_like_dqn_and_progressing_to.ipynb",
      "status": "passed",
      "execution_time": 1.5078420639038086,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/optimization_experimenting_with_techniques_like_experience_replay_reward_shaping.ipynb",
      "status": "passed",
      "execution_time": 1.4241530895233154,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/examples/training_and_evaluation_monitoring_learning_curves_rewards_and_stability_to_eval.ipynb",
      "status": "passed",
      "execution_time": 1.436431884765625,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "example"
    },
    {
      "path": "Course 09/unit3-deep-rl/exercises/01_deep_reinforcement_learning_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7368118762969971,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit3-deep-rl/solutions/01_deep_reinforcement_learning_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6719837188720703,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit3-deep-rl",
      "type": "other"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/01_exploration_strategies.ipynb",
      "status": "passed",
      "execution_time": 3.032170057296753,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/02_balancing_exploration.ipynb",
      "status": "passed",
      "execution_time": 1.8771309852600098,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/03_adaptive_exploration_ucb.ipynb",
      "status": "passed",
      "execution_time": 0.8145437240600586,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/04_comparing_exploration_methods.ipynb",
      "status": "passed",
      "execution_time": 0.9665021896362305,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/05_tuning_exploration_parameters.ipynb",
      "status": "passed",
      "execution_time": 0.9674458503723145,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/comparing_performance_of_different_exploration_methods.ipynb",
      "status": "passed",
      "execution_time": 1.5136692523956299,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/examples/tuning_exploration_parameters.ipynb",
      "status": "passed",
      "execution_time": 1.5318191051483154,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "example"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/exercises/02_exploration_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.4034950733184814,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit4-exploration-exploitation/solutions/02_exploration_solution.ipynb",
      "status": "failed",
      "execution_time": 0.8085989952087402,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install numpy matplotlib -q\nimport numpy as np\nimport matplotlib.pyplot as plt_np.random.seed(42)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plt_np.random.seed(42)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install numpy matplotlib -q\nimport numpy as np\nimport matplotlib.pyplot as plt_np.random.seed(42)\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as plt_np.random.seed(42)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 09",
      "unit": "unit4-exploration-exploitation",
      "type": "other"
    },
    {
      "path": "Course 09/unit5-applications/examples/01_rl_applications.ipynb",
      "status": "passed",
      "execution_time": 0.7304656505584717,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/02_game_playing_agent.ipynb",
      "status": "passed",
      "execution_time": 1.4889600276947021,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/03_resource_optimization.ipynb",
      "status": "passed",
      "execution_time": 1.3780229091644287,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/04_multi_agent_rl.ipynb",
      "status": "passed",
      "execution_time": 0.5462310314178467,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/05_hierarchical_rl_options.ipynb",
      "status": "passed",
      "execution_time": 0.753328800201416,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/06_model_based_rl_world_models.ipynb",
      "status": "passed",
      "execution_time": 0.6579940319061279,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/07_model_based_vs_model_free_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.7748298645019531,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/08_goal_conditioned_rl.ipynb",
      "status": "passed",
      "execution_time": 0.5462322235107422,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/building_model_based_rl_systems_with_learned_world_models.ipynb",
      "status": "passed",
      "execution_time": 1.652205228805542,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/comparing_model_based_vs_model_free_approaches.ipynb",
      "status": "passed",
      "execution_time": 1.3341188430786133,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/experimenting_with_hierarchical_rl_using_options_framework.ipynb",
      "status": "passed",
      "execution_time": 1.5382771492004395,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/implementing_goal_conditioned_rl_for_complex_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.7616188526153564,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/examples/implementing_multi_agent_rl_environments_and_training_cooperativecompetitive_age.ipynb",
      "status": "failed",
      "execution_time": 0.7432000637054443,
      "error": "An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Gym has two common packages: gymnasium (new) and gym (older)\n# This notebook tries both.\ntry:\n import gymnasium as gym\n gym_name = 'gymnasium'\nexcept ImportError:\n import gym\n gym_name = 'gym'\n\nprint('Using:', gym_name)\n\nenv = gym.make('CartPole-v1')\nobs, info = env.reset()\n\nprint('observation shape:', getattr(obs, 'shape', None))\nprint('action space:', env.action_space)\n\n# Run a random agent for a few episodes\nimport numpy as np\n\nrng = np.random.default_rng(0)\n\ndef run_episode(max_steps=500):\n obs, info = env.reset()\n total_reward = 0.0\n for t in range(max_steps):\n action = env.action_space.sample()\n step = env.step(action)\n # gymnasium returns: obs, reward, terminated, truncated, info\n if len(step) == 5:\n obs, reward, terminated, truncated, info = step\n done = terminated or truncated\n else:\n obs, reward, done, info = step\n\n total_reward += float(reward)\n if done:\n break\n return total_reward, t+1\n\nfor ep in range(3):\n r, steps = run_episode()\n print(f'episode {ep}: reward={r:.1f}, steps={steps}')\n\nenv.close()\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    action = env.action_space.sample()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n\n\n",
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "example"
    },
    {
      "path": "Course 09/unit5-applications/exercises/01_rl_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7770950794219971,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "exercise"
    },
    {
      "path": "Course 09/unit5-applications/solutions/01_rl_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6224181652069092,
      "error": null,
      "error_traceback": null,
      "course": "Course 09",
      "unit": "unit5-applications",
      "type": "other"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/01_generative_vs_discriminative.ipynb",
      "status": "failed",
      "execution_time": 0.6045198440551758,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Generative vs Discriminative Models\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\n\nThis example demonstrates:\n1. Difference between generative and discriminative models2. Simple examples of each\n3. When to use each type\n\"\"\"\n\nimport numpy as np\nfrom sklearn.naive_bayes \nimport GaussianNB # Generative\nfrom sklearn.linear_model \nimport LogisticRegression # Discriminative print(\"=\" * 60)\nprint(\"Example 1: Generative vs Discriminative Models\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\")\nprint(\"=\" * 60)\n\n# Sample data: Height and Weight to predict Gender\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629: \u0627\u0644\u0637\u0648\u0644 \u0648\u0627\u0644\u0648\u0632\u0646 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0627\u0644\u062c\u0646\u0633p\nrint(\"\\n1. Understanding the Difference\")\nprint(\"\u0641\u0647\u0645 \u0627\u0644\u0641\u0631\u0642\")\nprint(\"-\" * 60)\ndifference_explanation = \"\"\"\nGenerative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629):\n- Learn P(X, Y) - joint probability of features and labels\n- Can generate new data samples\n- Examples: Naive Bayes, GANs, VAEs\n\nDiscriminative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629):\n- Learn P(Y|X) - conditional probability of labels given features\n- Focus on decision boundary\n- Examples: Logistic Regression, SVM, Neural Networks\n\"\"\"\n\nprint(difference_explanation)\n\n# Example: Simple classification proble\nmp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Practical Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u064a\")\nprint(\"=\" * 60)\n\n# Generate sample data\n# \u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629np.random.seed(42)\nn_samples = 100\n\n# Male: taller and heavier on average\n# \u0627\u0644\u0630\u0643\u0648\u0631: \u0623\u0637\u0648\u0644 \u0648\u0623\u062b\u0642\u0644 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637m\nale_height = np.random.normal(175, 7, n_samples // 2)\nmale_weight = np.random.normal(80, 10, n_samples // 2)\nmale_data = np.column_stack([male_height, male_weight])\n\n# Female: shorter and lighter on average\n# \u0627\u0644\u0625\u0646\u0627\u062b: \u0623\u0642\u0635\u0631 \u0648\u0623\u062e\u0641 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637f\nemale_height = np.random.normal(165, 6, n_samples // 2)\nfemale_weight = np.random.normal(65, 8, n_samples // 2)\nfemale_data = np.column_stack([female_height, female_weight])\n\n# Combine data\nX = np.vstack([male_data, female_data])\ny = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\nprint(f\"\\nDataset created: {len(X)} samples\")\nprint(f\"Features: Height (cm), Weight (kg)\")\nprint(f\"Labels: 0 = Male, 1 = Female\")\n\n# Generative Model: Naive Baye\nsp\nrint(\"\\n\" + \"-\" * 60)\nprint(\"Generative Model: Naive Bayes\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a: Naive Bayes\")\nprint(\"-\" * 60)\ngenerative_model = GaussianNB()\ngenerative_model.fit(X, y)\nprint(\"\u2713 Naive Bayes trained (learns P(X, Y))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 Naive Bayes (\u064a\u062a\u0639\u0644\u0645 P(X, Y))\")\n\n# Discriminative Model: Logistic Regression\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Discriminative Model: Logistic Regression\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a: \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\")\nprint(\"-\" * 60)\ndiscriminative_model = LogisticRegression()\ndiscriminative_model.fit(X, y)\nprint(\"\u2713 Logistic Regression trained (learns P(Y|X))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a (\u064a\u062a\u0639\u0644\u0645 P(Y|X))\")\n\n# Make prediction\nsp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Predictions\")\nprint(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\")\nprint(\"=\" * 60)\ntest_samples = np.array([\n [170, 75], # Average\n [180, 85], # Likely male\n [160, 60] # Likely female\n])\ngen_predictions = generative_model.predict(test_samples)\ndisc_predictions = discriminative_model.predict(test_samples)\nprint(\"\\nTest samples:\")\nfor i, sample in enumerate(test_samples):\n gen_pred = \"Male\" if gen_predictions[i] == 0 else \"Female\"\n disc_pred = \"Male\" if disc_predictions[i] == 0 else \"Female\"\n print(f\"\\nSample {i+1}: Height={sample[0]}\ncm, Weight={sample[1]}\nkg\")\nprint(f\" Generative (Naive Bayes): {gen_pred}\")\n print(f\" Discriminative (Logistic): {disc_pred}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 1 - Example 1: Generative vs Discriminative Models\u0627\u0644\u0648\u062d\u062f\u0629 1 - \u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\n\nThis example demonstrates:\n1. Difference between generative and discriminative models2. Simple examples of each\n3. When to use each type\n\"\"\"\n\nimport numpy as np\nfrom sklearn.naive_bayes \nimport GaussianNB # Generative\nfrom sklearn.linear_model \nimport LogisticRegression # Discriminative print(\"=\" * 60)\nprint(\"Example 1: Generative vs Discriminative Models\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629\")\nprint(\"=\" * 60)\n\n# Sample data: Height and Weight to predict Gender\n# \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629: \u0627\u0644\u0637\u0648\u0644 \u0648\u0627\u0644\u0648\u0632\u0646 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0627\u0644\u062c\u0646\u0633p\nrint(\"\\n1. Understanding the Difference\")\nprint(\"\u0641\u0647\u0645 \u0627\u0644\u0641\u0631\u0642\")\nprint(\"-\" * 60)\ndifference_explanation = \"\"\"\nGenerative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629):\n- Learn P(X, Y) - joint probability of features and labels\n- Can generate new data samples\n- Examples: Naive Bayes, GANs, VAEs\n\nDiscriminative Models (\u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629):\n- Learn P(Y|X) - conditional probability of labels given features\n- Focus on decision boundary\n- Examples: Logistic Regression, SVM, Neural Networks\n\"\"\"\n\nprint(difference_explanation)\n\n# Example: Simple classification proble\nmp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Practical Example\")\nprint(\"\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u064a\")\nprint(\"=\" * 60)\n\n# Generate sample data\n# \u0625\u0646\u0634\u0627\u0621 \u0628\u064a\u0627\u0646\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629np.random.seed(42)\nn_samples = 100\n\n# Male: taller and heavier on average\n# \u0627\u0644\u0630\u0643\u0648\u0631: \u0623\u0637\u0648\u0644 \u0648\u0623\u062b\u0642\u0644 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637m\nale_height = np.random.normal(175, 7, n_samples // 2)\nmale_weight = np.random.normal(80, 10, n_samples // 2)\nmale_data = np.column_stack([male_height, male_weight])\n\n# Female: shorter and lighter on average\n# \u0627\u0644\u0625\u0646\u0627\u062b: \u0623\u0642\u0635\u0631 \u0648\u0623\u062e\u0641 \u0641\u064a \u0627\u0644\u0645\u062a\u0648\u0633\u0637f\nemale_height = np.random.normal(165, 6, n_samples // 2)\nfemale_weight = np.random.normal(65, 8, n_samples // 2)\nfemale_data = np.column_stack([female_height, female_weight])\n\n# Combine data\nX = np.vstack([male_data, female_data])\ny = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\nprint(f\"\\nDataset created: {len(X)} samples\")\nprint(f\"Features: Height (cm), Weight (kg)\")\nprint(f\"Labels: 0 = Male, 1 = Female\")\n\n# Generative Model: Naive Baye\nsp\nrint(\"\\n\" + \"-\" * 60)\nprint(\"Generative Model: Naive Bayes\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a: Naive Bayes\")\nprint(\"-\" * 60)\ngenerative_model = GaussianNB()\ngenerative_model.fit(X, y)\nprint(\"\u2713 Naive Bayes trained (learns P(X, Y))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 Naive Bayes (\u064a\u062a\u0639\u0644\u0645 P(X, Y))\")\n\n# Discriminative Model: Logistic Regression\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Discriminative Model: Logistic Regression\")\nprint(\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a: \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\")\nprint(\"-\" * 60)\ndiscriminative_model = LogisticRegression()\ndiscriminative_model.fit(X, y)\nprint(\"\u2713 Logistic Regression trained (learns P(Y|X))\")\nprint(\"\u2713 \u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a (\u064a\u062a\u0639\u0644\u0645 P(Y|X))\")\n\n# Make prediction\nsp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Predictions\")\nprint(\"\u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\")\nprint(\"=\" * 60)\ntest_samples = np.array([\n [170, 75], # Average\n [180, 85], # Likely male\n [160, 60] # Likely female\n])\ngen_predictions = generative_model.predict(test_samples)\ndisc_predictions = discriminative_model.predict(test_samples)\nprint(\"\\nTest samples:\")\nfor i, sample in enumerate(test_samples):\n gen_pred = \"Male\" if gen_predictions[i] == 0 else \"Female\"\n disc_pred = \"Male\" if disc_predictions[i] == 0 else \"Female\"\n print(f\"\\nSample {i+1}: Height={sample[0]}\ncm, Weight={sample[1]}\nkg\")\nprint(f\" Generative (Naive Bayes): {gen_pred}\")\n print(f\" Discriminative (Logistic): {disc_pred}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/02_generative_model_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.8138561248779297,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/03_probabilistic_generative_models.ipynb",
      "status": "passed",
      "execution_time": 0.6644039154052734,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/04_building_training_simple_gan.ipynb",
      "status": "passed",
      "execution_time": 3.348173141479492,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/05_implementing_vae_image_generation.ipynb",
      "status": "passed",
      "execution_time": 3.1650400161743164,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/06_comparing_gan_vae_architectures.ipynb",
      "status": "passed",
      "execution_time": 0.8910048007965088,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/06_comparing_generative_models_gans_vae.ipynb",
      "status": "passed",
      "execution_time": 0.9426569938659668,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/07_training_techniques_gradient_penalties.ipynb",
      "status": "passed",
      "execution_time": 3.256378173828125,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/08_evaluating_generative_models_fid_bleu.ipynb",
      "status": "passed",
      "execution_time": 1.4112091064453125,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/09_generating_samples_trained_models.ipynb",
      "status": "passed",
      "execution_time": 0.7271649837493896,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/10_exploring_latent_spaces_interpolation.ipynb",
      "status": "passed",
      "execution_time": 1.0116097927093506,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/building_and_training_a_simple_gan_using_tensorflowpytorch.ipynb",
      "status": "passed",
      "execution_time": 1.6349411010742188,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/experimenting_with_training_techniques_like_gradient_penalties_and_spectral_norm.ipynb",
      "status": "passed",
      "execution_time": 1.5290660858154297,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/examples/exploring_latent_spaces_and_interpolation_in_vaes.ipynb",
      "status": "passed",
      "execution_time": 1.765915870666504,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "example"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/exercises/01_generative_models_fundamentals_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.5772387981414795,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit1-generative-fundamentals/solutions/01_generative_models_fundamentals_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7360477447509766,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit1-generative-fundamentals",
      "type": "other"
    },
    {
      "path": "Course 10/unit2-gans/examples/01_gan_architecture.ipynb",
      "status": "failed",
      "execution_time": 0.525238037109375,
      "error": "An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 2 - Example 1: GAN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\n\nThis example demonstrates:\n1. GAN architecture components2. Generator and Discriminator3. Adversarial training concept4. Loss functions\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60)\nprint(\"Example 1: GAN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\")\nprint(\"=\" * 60)\n\n# 1. GAN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a GA\nNp\nrint(\"\\n1. GAN Architecture\")\nprint(\"\u0647\u064a\u0643\u0644 GAN\")\nprint(\"-\" * 60)\ngan_explanation = \"\"\"\nGAN consists of two networks:\n\nGenerator (\u0627\u0644\u0645\u0648\u0644\u062f):\n- Takes random noise as input\n- Generates fake data\n- Tries to fool the discriminator\n- Goal: Generate realistic data\n\nDiscriminator (\u0627\u0644\u0645\u0645\u064a\u0632):\n- Takes real or fake data as input\n- Classifies as real or fake\n- Tries to distinguish real from fake\n- Goal: Correctly identify fake data\n\nTraining Process:\n- Generator and Discriminator compete\n- Generator improves to create better fakes\n- Discriminator improves to detect fakes\n- Equilibrium: Generator creates perfect fakes\n\"\"\"\n\nprint(gan_explanation)\n\n# 2. Simple Generator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0648\u0644\u062fp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Generator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0648\u0644\u062f\")\nprint(\"=\" * 60)\ndef simple_generator(noise, weights):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple generator that transforms noise to data.\n \u0645\u0648\u0644\u062f \u0628\u0633\u064a\u0637 \u064a\u062d\u0648\u0644 \u0627\u0644\u0636\u0648\u0636\u0627\u0621 \u0625\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n \"\"\"\n # Simulate: noise -> hidden -> output hidden = noise * weights[0]\n output = hidden * weights[1]\n return output\n\n# Example: Generate fake data\nnoise = np.random.randn(10) # Random noisew\neights = [2.0, 1.5] # Generator weightsf\nake_data = simple_generator(noise, weights)\nprint(f\"\\nInput noise shape: {noise.shape}\")\nprint(f\"Generated fake data shape: {fake_data.shape}\")\nprint(f\"Sample fake data: {fake_data[:5]}\")\n\n# 3. Simple Discriminator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0645\u064a\u0632p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Discriminator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0645\u064a\u0632\")\nprint(\"=\" * 60)\ndef simple_discriminator(data, threshold=0.5):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple discriminator that classifies real vs fake.\n \u0645\u0645\u064a\u0632 \u0628\u0633\u064a\u0637 \u064a\u0635\u0646\u0641 \u0627\u0644\u062d\u0642\u064a\u0642\u064a \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0645\u0632\u064a\u0641.\n \"\"\"\n # Simple rule: if data > threshold, likely real probability = 1\n(1 + np.exp(-np.mean(data)))\n prediction = \"real\" if probability > threshold else \"fake\"\n return prediction, probability\n\n# Test discriminato\nrr\neal_data = np.random.randn(10) + 2 # Real data (shifted)\nfake_data = np.random.randn(10) - 2 # Fake data (shifted)\nreal_pred, real_prob = simple_discriminator(real_data)\nfake_pred, fake_prob = simple_discriminator(fake_data)\nprint(f\"\\nReal data: {real_pred} (probability: {real_prob:.3 f})\")\nprint(f\"Fake data: {fake_pred} (probability: {fake_prob:.3 f})\")\n\n# 4. Adversarial Training Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064ap\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Adversarial Training\")\nprint(\"\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064a\")\nprint(\"=\" * 60)\ntraining_concept = \"\"\"\nAdversarial Training Process:\n\nStep 1: Train Discriminator\n- Show real data \u2192 Discriminator learns real patterns\n- Show fake data \u2192 Discriminator learns to detect fakes\n\nStep 2: Train Generator\n- Generate fake data\n- Try to fool discriminator\n- Update generator to create better fakes\n\nStep 3: Repeat\n- Discriminator gets better at detection\n- Generator gets better at generation\n- Both improve together\n\nThis creates a competitive learning environment!\n\"\"\"\n\nprint(training_concept)\n\n# 5. Loss Functions\n# \u062f\u0648\u0627\u0644 \u0627\u0644\u062e\u0633\u0627\u0631\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"5. GAN Loss Functions\")\nprint(\"\u062f\u0648\u0627\u0644 \u062e\u0633\u0627\u0631\u0629 GAN\")\nprint(\"=\" * 60)\nloss_explanation = \"\"\"\nGenerator Loss:\n- Wants to maximize discriminator's error on fake data\n- Loss = -log(D(fake_data))\nDiscriminator Loss:\n- Wants to correctly classify real and fake\n- Loss = -log(D(real_data)) - log(1 - D(fake_data))\nMinimax Game:\n- Generator minimizes its loss\n- Discriminator minimizes its loss\n- Nash equilibrium when both are optimal\n\"\"\"\n\nprint(loss_explanation)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\n\n# Visualization: Generative vs Discriminative Models\n# \u062a\u0635\u0648\u0631: \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629t\nry:\n import matplotlib.pyplot as plt\n \n categories = ['Generative\nModels', 'DiscriminativeModels']\n capabilities = {\n 'Data Generation': [10, 0],\n 'Classification': [7, 10],\n 'Density Estimation': [10, 3],\n 'Feature Learning': [9, 8]\n }\n \n x = np.arange(len(categories))\n width = 0.2\n \n fig, ax = plt.subplots(figsize=(10, 6))\n for i, (cap, values)\nin enumerate(capabilities.items()):\n offset = width * (i - len(capabilities)/2)\n ax.bar(x + offset, values, width, label=cap, alpha=0.8)\nax.set_xlabel('Model Type | \u0646\u0648\u0639 \u0627\u0644\u0646\u0645\u0648\u0630\u062c', fontsize=12)\nax.set_ylabel('Capability Score | \u062f\u0631\u062c\u0629 \u0627\u0644\u0642\u062f\u0631\u0629', fontsize=12)\nax.set_title('Generative vs Discriminative Models | \u0627\u0644\u0646\u0645\u0627\u0630\u062c \u0627\u0644\u062a\u0648\u0644\u064a\u062f\u064a\u0629 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(categories)\nax.legend()\n ax.set_ylim(0, 11)\nplt.tight_layout()\n plt.show()\n print(\"\u2705 Model comparison chart displayed\")\nexcept ImportError:\n print(\"Note: Install matplotlib and numpy for visualizations\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0642\u0645 \u0628\u062a\u062b\u0628\u064a\u062a matplotlib \u0648 numpy \u0644\u0644\u062a\u0635\u0648\u0631\u0627\u062a\")\n\n\"\"\"\nUnit 2 - Example 1: GAN Architecture\u0627\u0644\u0648\u062d\u062f\u0629 2 - \u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\n\nThis example demonstrates:\n1. GAN architecture components2. Generator and Discriminator3. Adversarial training concept4. Loss functions\n\"\"\"\n\nimport numpy as np\n\nprint(\"=\" * 60)\nprint(\"Example 1: GAN Architecture\")\nprint(\"\u0645\u062b\u0627\u0644 1: \u0647\u064a\u0643\u0644 GAN\")\nprint(\"=\" * 60)\n\n# 1. GAN Components\n# \u0645\u0643\u0648\u0646\u0627\u062a GA\nNp\nrint(\"\\n1. GAN Architecture\")\nprint(\"\u0647\u064a\u0643\u0644 GAN\")\nprint(\"-\" * 60)\ngan_explanation = \"\"\"\nGAN consists of two networks:\n\nGenerator (\u0627\u0644\u0645\u0648\u0644\u062f):\n- Takes random noise as input\n- Generates fake data\n- Tries to fool the discriminator\n- Goal: Generate realistic data\n\nDiscriminator (\u0627\u0644\u0645\u0645\u064a\u0632):\n- Takes real or fake data as input\n- Classifies as real or fake\n- Tries to distinguish real from fake\n- Goal: Correctly identify fake data\n\nTraining Process:\n- Generator and Discriminator compete\n- Generator improves to create better fakes\n- Discriminator improves to detect fakes\n- Equilibrium: Generator creates perfect fakes\n\"\"\"\n\nprint(gan_explanation)\n\n# 2. Simple Generator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0648\u0644\u062fp\nrint(\"\\n\" + \"=\" * 60)\nprint(\"2. Generator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0648\u0644\u062f\")\nprint(\"=\" * 60)\ndef simple_generator(noise, weights):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple generator that transforms noise to data.\n \u0645\u0648\u0644\u062f \u0628\u0633\u064a\u0637 \u064a\u062d\u0648\u0644 \u0627\u0644\u0636\u0648\u0636\u0627\u0621 \u0625\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n \"\"\"\n # Simulate: noise -> hidden -> output hidden = noise * weights[0]\n output = hidden * weights[1]\n return output\n\n# Example: Generate fake data\nnoise = np.random.randn(10) # Random noisew\neights = [2.0, 1.5] # Generator weightsf\nake_data = simple_generator(noise, weights)\nprint(f\"\\nInput noise shape: {noise.shape}\")\nprint(f\"Generated fake data shape: {fake_data.shape}\")\nprint(f\"Sample fake data: {fake_data[:5]}\")\n\n# 3. Simple Discriminator Example\n# \u0645\u062b\u0627\u0644 \u0628\u0633\u064a\u0637 \u0639\u0644\u0649 \u0627\u0644\u0645\u0645\u064a\u0632p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"3. Discriminator Network\")\nprint(\"\u0634\u0628\u0643\u0629 \u0627\u0644\u0645\u0645\u064a\u0632\")\nprint(\"=\" * 60)\ndef simple_discriminator(data, threshold=0.5):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\n Simple discriminator that classifies real vs fake.\n \u0645\u0645\u064a\u0632 \u0628\u0633\u064a\u0637 \u064a\u0635\u0646\u0641 \u0627\u0644\u062d\u0642\u064a\u0642\u064a \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0645\u0632\u064a\u0641.\n \"\"\"\n # Simple rule: if data > threshold, likely real probability = 1\n(1 + np.exp(-np.mean(data)))\n prediction = \"real\" if probability > threshold else \"fake\"\n return prediction, probability\n\n# Test discriminato\nrr\neal_data = np.random.randn(10) + 2 # Real data (shifted)\nfake_data = np.random.randn(10) - 2 # Fake data (shifted)\nreal_pred, real_prob = simple_discriminator(real_data)\nfake_pred, fake_prob = simple_discriminator(fake_data)\nprint(f\"\\nReal data: {real_pred} (probability: {real_prob:.3 f})\")\nprint(f\"Fake data: {fake_pred} (probability: {fake_prob:.3 f})\")\n\n# 4. Adversarial Training Concept\n# \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064ap\nrint(\"\\n\" + \"=\" * 60)\nprint(\"4. Adversarial Training\")\nprint(\"\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u062a\u0646\u0627\u0641\u0633\u064a\")\nprint(\"=\" * 60)\ntraining_concept = \"\"\"\nAdversarial Training Process:\n\nStep 1: Train Discriminator\n- Show real data \u2192 Discriminator learns real patterns\n- Show fake data \u2192 Discriminator learns to detect fakes\n\nStep 2: Train Generator\n- Generate fake data\n- Try to fool discriminator\n- Update generator to create better fakes\n\nStep 3: Repeat\n- Discriminator gets better at detection\n- Generator gets better at generation\n- Both improve together\n\nThis creates a competitive learning environment!\n\"\"\"\n\nprint(training_concept)\n\n# 5. Loss Functions\n# \u062f\u0648\u0627\u0644 \u0627\u0644\u062e\u0633\u0627\u0631\u0629p\nrint(\"\\n\" + \"=\" * 60)\nprint(\"5. GAN Loss Functions\")\nprint(\"\u062f\u0648\u0627\u0644 \u062e\u0633\u0627\u0631\u0629 GAN\")\nprint(\"=\" * 60)\nloss_explanation = \"\"\"\nGenerator Loss:\n- Wants to maximize discriminator's error on fake data\n- Loss = -log(D(fake_data))\nDiscriminator Loss:\n- Wants to correctly classify real and fake\n- Loss = -log(D(real_data)) - log(1 - D(fake_data))\nMinimax Game:\n- Generator minimizes its loss\n- Discriminator minimizes its loss\n- Nash equilibrium when both are optimal\n\"\"\"\n\nprint(loss_explanation)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Example completed successfully!\")\nprint(\"\u062a\u0645 \u0625\u0643\u0645\u0627\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0628\u0646\u062c\u0627\u062d!\")\nprint(\"=\" * 60)\nprint(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\nprint(\"\u0645\u0644\u0627\u062d\u0638\u0629: \u0644\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0644\u064a\u060c \u0627\u0633\u062a\u062e\u062f\u0645 TensorFlow/Keras \u0623\u0648 PyTorch\")\n\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    categories = ['Generative\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/02_conditional_gans.ipynb",
      "status": "passed",
      "execution_time": 0.6787331104278564,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/03_stylegan_basics.ipynb",
      "status": "passed",
      "execution_time": 0.8921549320220947,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/04_text_generation_gpt_models.ipynb",
      "status": "passed",
      "execution_time": 5.57607102394104,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/04_training_techniques_gradient_penalties.ipynb",
      "status": "passed",
      "execution_time": 0.5341060161590576,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/05_fine_tuning_language_models.ipynb",
      "status": "failed",
      "execution_time": 0.8273398876190186,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Configure training\")\nprint(\" 4. Train on task data\")\nprint(\" 5. Evaluate performance\")\n\nprint(\"\\nFine-tuning Strategies:\")\nprint(\" - Full fine-tuning\")\nprint(\" - LoRA (Low-Rank Adaptation)\")\nprint(\" - Prompt tuning\")\nprint(\" - Adapter layers\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Task-specific performance\")\nprint(\" - Less data needed\")\nprint(\" - Faster training\")\nprint(\" - Better results\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Configure training\")\nprint(\" 4. Train on task data\")\nprint(\" 5. Evaluate performance\")\n\nprint(\"\\nFine-tuning Strategies:\")\nprint(\" - Full fine-tuning\")\nprint(\" - LoRA (Low-Rank Adaptation)\")\nprint(\" - Prompt tuning\")\nprint(\" - Adapter layers\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Task-specific performance\")\nprint(\" - Less data needed\")\nprint(\" - Faster training\")\nprint(\" - Better results\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/05_finetuning_language_models.ipynb",
      "status": "failed",
      "execution_time": 0.731154203414917,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Update model parameters\")\nprint(\" 4. Evaluate on task\")\nprint(\" 5. Deploy fine-tuned model\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Better task performance\")\nprint(\" - Less data needed\")\nprint(\" - Domain adaptation\")\nprint(\" - Faster training\")\n\nprint(\"\\nTasks:\")\nprint(\" - Text classification\")\nprint(\" - Question answering\")\nprint(\" - Named entity recognition\")\nprint(\" - Summarization\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom transformers \nimport AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nimport torch\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nFine-tuning Language Models\")\nprint(\"=\" * 60)\n\nprint(\"\\nFine-tuning Process:\")\nprint(\" 1. Load pre-trained model\")\nprint(\" 2. Prepare task-specific data\")\nprint(\" 3. Update model parameters\")\nprint(\" 4. Evaluate on task\")\nprint(\" 5. Deploy fine-tuned model\")\n\nprint(\"\\nBenefits:\")\nprint(\" - Better task performance\")\nprint(\" - Less data needed\")\nprint(\" - Domain adaptation\")\nprint(\" - Faster training\")\n\nprint(\"\\nTasks:\")\nprint(\" - Text classification\")\nprint(\" - Question answering\")\nprint(\" - Named entity recognition\")\nprint(\" - Summarization\")\n\nprint(\"\\n\u2705 Fine-tuning concepts understood!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/06_prompt_engineering_openai_huggingface.ipynb",
      "status": "passed",
      "execution_time": 0.7470088005065918,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/07_building_text_to_text_generation.ipynb",
      "status": "passed",
      "execution_time": 5.227774143218994,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/07_text_to_text_generation_transformers.ipynb",
      "status": "passed",
      "execution_time": 0.7916748523712158,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/08_generating_creative_text_stories_poems.ipynb",
      "status": "passed",
      "execution_time": 5.49932599067688,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/09_evaluating_text_quality_bleu_perplexity.ipynb",
      "status": "passed",
      "execution_time": 1.559117078781128,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/building_a_text_to_text_generation_system_using_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.4273109436035156,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/evaluating_text_generation_quality_using_metrics_like_bleu_and_perplexity.ipynb",
      "status": "passed",
      "execution_time": 1.5200200080871582,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/fine_tuning_language_models_for_specific_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.556593894958496,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/generating_creative_text_stories_poems_using_language_models.ipynb",
      "status": "passed",
      "execution_time": 1.5382227897644043,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/implementing_conversational_ai_or_chatbot_using_generative_models.ipynb",
      "status": "passed",
      "execution_time": 1.6266686916351318,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/implementing_text_generation_using_gpt_models.ipynb",
      "status": "passed",
      "execution_time": 1.6380198001861572,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/examples/practicing_prompt_engineering_with_openai_api_or_hugging_face_transformers.ipynb",
      "status": "passed",
      "execution_time": 1.6439878940582275,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "example"
    },
    {
      "path": "Course 10/unit2-gans/exercises/01_gan_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.9824819564819336,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit2-gans/solutions/01_gan_solution.ipynb",
      "status": "passed",
      "execution_time": 1.631537914276123,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit2-gans",
      "type": "other"
    },
    {
      "path": "Course 10/unit3-vaes/examples/01_vae_implementation.ipynb",
      "status": "passed",
      "execution_time": 0.6108138561248779,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/02_vae_applications.ipynb",
      "status": "passed",
      "execution_time": 2.350795030593872,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/03_vae_advanced_topics.ipynb",
      "status": "passed",
      "execution_time": 1.2314929962158203,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/applying_models_like_openai_codex_or_github_copilot_for_code_generation.ipynb",
      "status": "passed",
      "execution_time": 1.4595959186553955,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/audio_and_voice_synthesis_using_ai_tools_like_wavenet_or_jukebox.ipynb",
      "status": "passed",
      "execution_time": 1.5683369636535645,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/automating_code_generation_and_software_development_tasks.ipynb",
      "status": "passed",
      "execution_time": 1.7009198665618896,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/creating_ai_generated_music_and_human_voice_synthesis.ipynb",
      "status": "passed",
      "execution_time": 1.5136499404907227,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/developing_comprehensive_projects_integrating_generative_ai_in_real_world_applic.ipynb",
      "status": "passed",
      "execution_time": 1.5426409244537354,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/experimenting_with_deepfake_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.3627269268035889,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/examples/generating_ai_created_images_using_stylegan_dall_e_or_stable_diffusion.ipynb",
      "status": "passed",
      "execution_time": 1.5279419422149658,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "example"
    },
    {
      "path": "Course 10/unit3-vaes/exercises/01_vae_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.396912097930908,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit3-vaes/solutions/01_vae_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7377519607543945,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision matplotlib -q\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\nelse 'cpu')\nprint(f'Using device: {device}')\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install torch torchvision matplotlib -q\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\nelse 'cpu')\nprint(f'Using device: {device}')\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy as np_device = torch.device('cuda' if torch.cuda.is_available()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit3-vaes",
      "type": "other"
    },
    {
      "path": "Course 10/unit4-applications/examples/01_generative_ai_applications.ipynb",
      "status": "passed",
      "execution_time": 0.5942940711975098,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/02_image_generation_advanced.ipynb",
      "status": "passed",
      "execution_time": 6.8111412525177,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/03_music_generation.ipynb",
      "status": "passed",
      "execution_time": 1.6632649898529053,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/04_generating_ai_images_stylegan_dalle.ipynb",
      "status": "passed",
      "execution_time": 0.6625080108642578,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/05_audio_voice_synthesis_wavenet_jukebox.ipynb",
      "status": "passed",
      "execution_time": 0.5404882431030273,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/06_code_generation_openai_codex_copilot.ipynb",
      "status": "passed",
      "execution_time": 0.5285520553588867,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/applying_ai_regulatory_guidelines_like_gdpr_to_ensure_compliance_in_model_develo.ipynb",
      "status": "passed",
      "execution_time": 1.6858711242675781,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/examples/building_ethical_ai_models_with_principles_like_fairness_and_transparency.ipynb",
      "status": "passed",
      "execution_time": 1.4329240322113037,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "example"
    },
    {
      "path": "Course 10/unit4-applications/exercises/01_generation_exercise.ipynb",
      "status": "passed",
      "execution_time": 5.963052988052368,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit4-applications/solutions/01_generation_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7778308391571045,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n# Load pre-trained model_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprint('\u2705 Text generation model loaded')\nprint('\\nTeaching Notes: Fine-tune GPT-2 on creative writing dataset')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install transformers torch -q\nfrom transformers \nimport GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n# Load pre-trained model_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nprint('\u2705 Text generation model loaded')\nprint('\\nTeaching Notes: Fine-tune GPT-2 on creative writing dataset')\nprint('Grading: Task 1 (25pts), Task 2 (35pts), Task 3 (40pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from transformers\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 10",
      "unit": "unit4-applications",
      "type": "other"
    },
    {
      "path": "Course 10/unit5-ethics/examples/01_generative_ai_ethics.ipynb",
      "status": "passed",
      "execution_time": 0.6023581027984619,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/02_deepfake_detection.ipynb",
      "status": "passed",
      "execution_time": 1.8690569400787354,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/03_future_trends_research.ipynb",
      "status": "passed",
      "execution_time": 0.9223041534423828,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/04_detecting_mitigating_bias_generative.ipynb",
      "status": "passed",
      "execution_time": 0.7723510265350342,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/examples/05_experimenting_advanced_generative_models.ipynb",
      "status": "passed",
      "execution_time": 0.7360472679138184,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "example"
    },
    {
      "path": "Course 10/unit5-ethics/exercises/01_generative_ai_ethics_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.74587082862854,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "exercise"
    },
    {
      "path": "Course 10/unit5-ethics/solutions/01_generative_ai_ethics_solution.ipynb",
      "status": "passed",
      "execution_time": 0.8392369747161865,
      "error": null,
      "error_traceback": null,
      "course": "Course 10",
      "unit": "unit5-ethics",
      "type": "other"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/01_model_serving_api.ipynb",
      "status": "passed",
      "execution_time": 1.6640770435333252,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/02_model_packaging.ipynb",
      "status": "passed",
      "execution_time": 3.9189209938049316,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/03_local_deployment_testing.ipynb",
      "status": "failed",
      "execution_time": 0.604172945022583,
      "error": "An error occurred while executing the following cell:\n------------------\nfrom flask import Flask, request, jsonify\nimport joblib\n\n# Load model\n# model = joblib.load('model.pkl')\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n # TODO: Implement prediction endpoint\n # Handle request, make prediction, return response\n pass\n\nif__name__ == '__main__':\n app.run(debug=True, host='0.0.0.0', port=5000)\n\nprint('Local deployment server defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == '__main__':\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nfrom flask import Flask, request, jsonify\nimport joblib\n\n# Load model\n# model = joblib.load('model.pkl')\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n # TODO: Implement prediction endpoint\n # Handle request, make prediction, return response\n pass\n\nif__name__ == '__main__':\n app.run(debug=True, host='0.0.0.0', port=5000)\n\nprint('Local deployment server defined')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == '__main__':\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/04_model_preparation_saving.ipynb",
      "status": "passed",
      "execution_time": 0.757519006729126,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/05_model_validation_testing.ipynb",
      "status": "passed",
      "execution_time": 0.7704658508300781,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/06_monitoring_updating_models.ipynb",
      "status": "passed",
      "execution_time": 0.706265926361084,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/building_api_interface_for_ai_models_implementing_a_simple_api_using_flask_or_fa.ipynb",
      "status": "passed",
      "execution_time": 1.5164000988006592,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/containerizing_ai_model_using_docker_packaging_ai_model_into_a_container_and_dep.ipynb",
      "status": "passed",
      "execution_time": 1.5478458404541016,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/containerizing_ai_model_using_docker_to_package_a_trained_model_for_scalable_dep.ipynb",
      "status": "passed",
      "execution_time": 1.4029319286346436,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/creating_rest_api_for_ai_model_inference_using_flask_or_fastapi_to_serve_predict.ipynb",
      "status": "passed",
      "execution_time": 1.4101588726043701,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/deploying_model_on_cloud_hosting_a_model_on_aws_google_cloud_or_azure.ipynb",
      "status": "passed",
      "execution_time": 1.397575855255127,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/implementing_security_measures_applying_authentication_encryption_and_access_con.ipynb",
      "status": "passed",
      "execution_time": 1.5021719932556152,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/managing_ai_model_deployment_using_kubernetes_running_and_scaling_a_deployed_mod.ipynb",
      "status": "passed",
      "execution_time": 1.3281128406524658,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/model_validation_and_testing_running_unit_tests_and_performance_evaluations_befo.ipynb",
      "status": "passed",
      "execution_time": 1.543821096420288,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/monitoring_and_logging_deployed_models_on_cloud_setting_up_logging_tracking_api_.ipynb",
      "status": "passed",
      "execution_time": 1.3178517818450928,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/monitoring_and_updating_deployed_models_implementing_logs_feedback_loops_and_ret.ipynb",
      "status": "passed",
      "execution_time": 1.57328200340271,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/examples/preparing_ai_model_for_deployment_training_and_saving_a_model_using_tensorflow_o.ipynb",
      "status": "passed",
      "execution_time": 1.5399658679962158,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "example"
    },
    {
      "path": "Course 11/unit1-deployment-basics/exercises/01_packaging_exercise.ipynb",
      "status": "passed",
      "execution_time": 2.9820778369903564,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit1-deployment-basics/solutions/01_packaging_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7310090065002441,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install pickle5 onnx scikit-learn joblib -q\nimport pickle\nimport joblib\nimport onnx\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Create and train model_model = RandomForestClassifier(n_estimators=100)\nX = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\ny = np.random.randint(0, 2, 100)\nmodel.fit(X, y)\n\n# Package in different formats_pickle.dump(model, open('model.pkl', 'wb'))\njoblib.dump(model, 'model.joblib')\nprint('\u2705 Model packaged in multiple formats')\nprint('\\nTeaching Notes: Different formats for different use cases')\nprint('Grading: Task 1 (40pts), Task 2 (30pts), Task 3 (30pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install pickle5 onnx scikit-learn joblib -q\nimport pickle\nimport joblib\nimport onnx\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Create and train model_model = RandomForestClassifier(n_estimators=100)\nX = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\ny = np.random.randint(0, 2, 100)\nmodel.fit(X, y)\n\n# Package in different formats_pickle.dump(model, open('model.pkl', 'wb'))\njoblib.dump(model, 'model.joblib')\nprint('\u2705 Model packaged in multiple formats')\nprint('\\nTeaching Notes: Different formats for different use cases')\nprint('Grading: Task 1 (40pts), Task 2 (30pts), Task 3 (30pts)')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = np.random.rand(100, 5)_y =  np.random.randint(0, 2, 100)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit1-deployment-basics",
      "type": "other"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/01_flask_api_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7304489612579346,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/02_fastapi_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7832028865814209,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/03_model_versioning.ipynb",
      "status": "failed",
      "execution_time": 0.836961030960083,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install mlflow -q\nimport mlflow\nimport mlflow.sklearnprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mlflow.sklearnprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install mlflow -q\nimport mlflow\nimport mlflow.sklearnprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mlflow.sklearnprint('\u2705 Setup complete!')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/04_saving_loading_models_pickle_onnx.ipynb",
      "status": "passed",
      "execution_time": 0.7228012084960938,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/05_tensorflow_serving_torchserve.ipynb",
      "status": "passed",
      "execution_time": 0.6744823455810547,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/06_batch_vs_realtime_inference.ipynb",
      "status": "passed",
      "execution_time": 0.5466351509094238,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/07_kubernetes_scaling.ipynb",
      "status": "passed",
      "execution_time": 0.6229708194732666,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/containerizing_ai_model_using_docker_creating_docker_image_for_trained_ai_model_.ipynb",
      "status": "passed",
      "execution_time": 1.7566771507263184,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/deploying_using_tensorflow_serving_or_torchserve_using_ready_made_frameworks_for.ipynb",
      "status": "passed",
      "execution_time": 1.7191591262817383,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/saving_and_loading_ai_model_using_pickle_onnx_or_savedmodel_for_tensorflow.ipynb",
      "status": "passed",
      "execution_time": 1.5540661811828613,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/scaling_model_deployment_using_kubernetes_deploying_container_based_ai_model_on_.ipynb",
      "status": "passed",
      "execution_time": 1.5054049491882324,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/examples/testing_batch_vs_real_time_inference_running_batch_processing_scripts_and_deploy.ipynb",
      "status": "passed",
      "execution_time": 1.4967069625854492,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "example"
    },
    {
      "path": "Course 11/unit2-versioning-serving/exercises/03_api_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.5962510108947754,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit2-versioning-serving/solutions/03_api_deployment_solution.ipynb",
      "status": "failed",
      "execution_time": 0.5263111591339111,
      "error": "An error occurred while executing the following cell:\n------------------\n%pip install fastapi uvicorn pydantic scikit-learn -q\nfrom fastapi \nimport FastAPI, HTTPException\nfrom pydantic \nimport BaseModel, validator\nimport pickle\nimport numpy as np\nfrom typing \nimport List_\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from fastapi\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n%pip install fastapi uvicorn pydantic scikit-learn -q\nfrom fastapi \nimport FastAPI, HTTPException\nfrom pydantic \nimport BaseModel, validator\nimport pickle\nimport numpy as np\nfrom typing \nimport List_\nprint('\u2705 Setup complete!')\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from fastapi\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 11",
      "unit": "unit2-versioning-serving",
      "type": "other"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/01_cloud_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7283480167388916,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/02_aws_sagemaker.ipynb",
      "status": "passed",
      "execution_time": 1.8938407897949219,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/03_azure_ml_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.9061598777770996,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/04_gcp_vertex_ai.ipynb",
      "status": "passed",
      "execution_time": 0.5831630229949951,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/05_security_measures.ipynb",
      "status": "passed",
      "execution_time": 0.6370179653167725,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/examples/06_monitoring_logging_cloud.ipynb",
      "status": "passed",
      "execution_time": 0.8117611408233643,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "example"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/exercises/01_cloud_deployment_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.80765700340271,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit3-cloud-deployment/solutions/01_cloud_deployment_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7565648555755615,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit3-cloud-deployment",
      "type": "other"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/01_docker_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.5798070430755615,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/02_kubernetes_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.7952930927276611,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/03_cloud_deployment_comparison.ipynb",
      "status": "passed",
      "execution_time": 0.5593688488006592,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/04_cicd_pipelines.ipynb",
      "status": "passed",
      "execution_time": 0.7723050117492676,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/examples/setting_up_cicd_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.5517840385437012,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "example"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/exercises/01_docker_and_containerization_exercise.ipynb",
      "status": "passed",
      "execution_time": 0.7896759510040283,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit4-containers-orchestration/solutions/01_docker_and_containerization_solution.ipynb",
      "status": "passed",
      "execution_time": 0.6634650230407715,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit4-containers-orchestration",
      "type": "other"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/01_model_monitoring.ipynb",
      "status": "passed",
      "execution_time": 0.5333492755889893,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/02_retraining_pipeline.ipynb",
      "status": "passed",
      "execution_time": 1.3804962635040283,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/03_alerting_incident_management.ipynb",
      "status": "passed",
      "execution_time": 1.606396198272705,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/04_drift_detection.ipynb",
      "status": "passed",
      "execution_time": 1.3576269149780273,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/05_experiment_tracking_mlflow_wandb.ipynb",
      "status": "passed",
      "execution_time": 0.639491081237793,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/06_model_versioning_reproducibility.ipynb",
      "status": "passed",
      "execution_time": 0.6026208400726318,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/07_ab_testing_canary_deployment.ipynb",
      "status": "passed",
      "execution_time": 0.5481069087982178,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_canary_deployment_strategies.ipynb",
      "status": "passed",
      "execution_time": 1.4263558387756348,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_drift_detection_algorithms.ipynb",
      "status": "passed",
      "execution_time": 1.545245885848999,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/implementing_model_versioning_and_reproducibility_practices.ipynb",
      "status": "passed",
      "execution_time": 1.5072999000549316,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/performing_ab_testing_for_model_comparison.ipynb",
      "status": "passed",
      "execution_time": 1.3757340908050537,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/setting_up_model_monitoring_and_performance_tracking_systems.ipynb",
      "status": "passed",
      "execution_time": 1.497898817062378,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/setting_up_retraining_pipelines.ipynb",
      "status": "passed",
      "execution_time": 1.6395959854125977,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/examples/using_experiment_tracking_tools_mlflow_weights_biases.ipynb",
      "status": "passed",
      "execution_time": 1.5518620014190674,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "example"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/exercises/01_monitoring_exercise.ipynb",
      "status": "passed",
      "execution_time": 1.6575889587402344,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "exercise"
    },
    {
      "path": "Course 11/unit5-pipelines-monitoring/solutions/01_monitoring_solution.ipynb",
      "status": "passed",
      "execution_time": 1.8349981307983398,
      "error": null,
      "error_traceback": null,
      "course": "Course 11",
      "unit": "unit5-pipelines-monitoring",
      "type": "other"
    },
    {
      "path": "Course 12/EXAMPLES/01_project_structure_template.ipynb",
      "status": "passed",
      "execution_time": 0.9740622043609619,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/02_data_collection_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 0.9485199451446533,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/03_model_development.ipynb",
      "status": "passed",
      "execution_time": 1.173755168914795,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/04_model_evaluation.ipynb",
      "status": "passed",
      "execution_time": 0.8869872093200684,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/05_deployment_example.ipynb",
      "status": "passed",
      "execution_time": 0.9557838439941406,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXAMPLES/06_project_documentation_template.ipynb",
      "status": "passed",
      "execution_time": 0.9918808937072754,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "example"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_01_project_proposal_solution.ipynb",
      "status": "passed",
      "execution_time": 0.7570338249206543,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_02_system_design_solution.ipynb",
      "status": "passed",
      "execution_time": 4.044513702392578,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/SOLUTIONS/exercise_03_implementation_planning_solution.ipynb",
      "status": "passed",
      "execution_time": 0.8544409275054932,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_01_project_proposal.ipynb",
      "status": "passed",
      "execution_time": 0.7474269866943359,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_02_system_design.ipynb",
      "status": "passed",
      "execution_time": 0.5434279441833496,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/EXERCISES/exercise_03_implementation_planning.ipynb",
      "status": "passed",
      "execution_time": 0.7404501438140869,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/01_project_proposal_literature_review.ipynb",
      "status": "passed",
      "execution_time": 0.7113142013549805,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/04_literature_review_research_papers.ipynb",
      "status": "passed",
      "execution_time": 0.6774201393127441,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/compiling_source_code_documents_and_final_submission_package.ipynb",
      "status": "passed",
      "execution_time": 1.4691400527954102,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/creating_project_timeline_and_resource_allocation_plan.ipynb",
      "status": "passed",
      "execution_time": 1.5476937294006348,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/defining_success_metrics_and_evaluation_criteria_for_the_project.ipynb",
      "status": "passed",
      "execution_time": 1.6572210788726807,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/preparing_recorded_video_or_live_demonstration_of_project.ipynb",
      "status": "passed",
      "execution_time": 1.649493932723999,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit1-project-planning/examples/selecting_and_defining_a_graduation_project_topic.ipynb",
      "status": "passed",
      "execution_time": 1.5471129417419434,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit1-project-planning",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/01_data_collection_preprocessing.ipynb",
      "status": "passed",
      "execution_time": 1.82566237449646,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/04_data_sourcing_strategies.ipynb",
      "status": "passed",
      "execution_time": 0.8876721858978271,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/collecting_and_acquiring_datasets_for_the_graduation_project.ipynb",
      "status": "passed",
      "execution_time": 1.5236949920654297,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/creating_data_exploration_notebooks_with_visualizations.ipynb",
      "status": "passed",
      "execution_time": 2.237553119659424,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/implementing_feature_engineering_techniques.ipynb",
      "status": "passed",
      "execution_time": 1.5377840995788574,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/performing_data_cleaning_and_preprocessing_using_python_libraries_pandas_numpy.ipynb",
      "status": "passed",
      "execution_time": 1.4905426502227783,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit2-data-collection/examples/validating_data_quality_and_preparing_trainvalidationtest_splits.ipynb",
      "status": "passed",
      "execution_time": 1.6341419219970703,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit2-data-collection",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/01_model_training_hyperparameter_optimization.ipynb",
      "status": "passed",
      "execution_time": 19.319874048233032,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/04_model_selection_architecture_design.ipynb",
      "status": "failed",
      "execution_time": 3.011573076248169,
      "error": "An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nModel Selection and Architecture Design\")\nprint(\"=\" * 60)\n\nprint(\"\\nModel Selection:\")\nprint(\"  - Problem type (classification, regression)\")\nprint(\"  - Data characteristics\")\nprint(\"  - Performance requirements\")\nprint(\"  - Resource constraints\")\n\nprint(\"\\nArchitecture Design:\")\nprint(\"  - Layer types\")\nprint(\"  - Network depth\")\nprint(\"  - Activation functions\")\nprint(\"  - Regularization\")\n\nprint(\"\\nConsiderations:\")\nprint(\"  - Complexity vs performance\")\nprint(\"  - Training time\")\nprint(\"  - Inference speed\")\nprint(\"  - Model size\")\n\nprint(\"\\n\u2705 Model selection concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\nprint(\"\u2705 Libraries imported!\")\nprint(\"\\nModel Selection and Architecture Design\")\nprint(\"=\" * 60)\n\nprint(\"\\nModel Selection:\")\nprint(\"  - Problem type (classification, regression)\")\nprint(\"  - Data characteristics\")\nprint(\"  - Performance requirements\")\nprint(\"  - Resource constraints\")\n\nprint(\"\\nArchitecture Design:\")\nprint(\"  - Layer types\")\nprint(\"  - Network depth\")\nprint(\"  - Activation functions\")\nprint(\"  - Regularization\")\n\nprint(\"\\nConsiderations:\")\nprint(\"  - Complexity vs performance\")\nprint(\"  - Training time\")\nprint(\"  - Inference speed\")\nprint(\"  - Model size\")\n\nprint(\"\\n\u2705 Model selection concepts understood!\")\n------------------\n\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\nCell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\nFile \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\n\u001b[0;31mImportError\u001b[0m: cannot import name 'runtime_version' from 'google.protobuf' (/opt/anaconda3/lib/python3.13/site-packages/google/protobuf/__init__.py)\n\n",
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/analyzing_model_outputs_and_identifying_areas_for_improvement.ipynb",
      "status": "passed",
      "execution_time": 1.4272801876068115,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/documenting_training_procedures_and_results.ipynb",
      "status": "passed",
      "execution_time": 1.502615213394165,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/evaluating_model_performance_using_appropriate_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.65006685256958,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/iteratively_refining_the_model_based_on_validation_results.ipynb",
      "status": "passed",
      "execution_time": 1.728332757949829,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit3-model-development/examples/performing_hyperparameter_optimization_using_grid_search_or_automated_tools.ipynb",
      "status": "passed",
      "execution_time": 1.656465768814087,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit3-model-development",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/01_model_evaluation_optimization.ipynb",
      "status": "passed",
      "execution_time": 2.100665807723999,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/04_experiments_performance_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.4771037101745605,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/05_comparing_baseline_models.ipynb",
      "status": "passed",
      "execution_time": 1.4740233421325684,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/06_analyzing_failure_cases.ipynb",
      "status": "passed",
      "execution_time": 1.1474931240081787,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/07_visualizing_results_graphs_matrices.ipynb",
      "status": "passed",
      "execution_time": 1.6717829704284668,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/08_iterative_improvement_retraining.ipynb",
      "status": "passed",
      "execution_time": 1.2763018608093262,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/analyzing_failure_cases_and_identifying_weaknesses_in_the_model.ipynb",
      "status": "passed",
      "execution_time": 1.6432602405548096,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/comparing_results_with_baseline_or_standard_models.ipynb",
      "status": "passed",
      "execution_time": 1.561171054840088,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/conducting_experiments_and_collecting_performance_metrics.ipynb",
      "status": "passed",
      "execution_time": 1.488279104232788,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/iteratively_improving_model_parameters_or_retraining_with_improved_data.ipynb",
      "status": "passed",
      "execution_time": 1.4090712070465088,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit4-evaluation-optimization/examples/visualizing_results_using_graphs_confusion_matrices_or_heat_maps.ipynb",
      "status": "passed",
      "execution_time": 1.4437808990478516,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit4-evaluation-optimization",
      "type": "example"
    },
    {
      "path": "Course 12/unit5-documentation-presentation/examples/01_project_documentation_presentation.ipynb",
      "status": "passed",
      "execution_time": 0.5421268939971924,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit5-documentation-presentation",
      "type": "example"
    },
    {
      "path": "Course 12/unit5-documentation-presentation/examples/04_writing_final_project_report.ipynb",
      "status": "passed",
      "execution_time": 0.671724796295166,
      "error": null,
      "error_traceback": null,
      "course": "Course 12",
      "unit": "unit5-documentation-presentation",
      "type": "example"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit1-data-processing/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 1.5816740989685059,
      "error": "An error occurred while executing the following cell:\n------------------\n# Sample dataset - Sales datanp.random.seed(42)\ndata = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    data = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n# Sample dataset - Sales datanp.random.seed(42)\ndata = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    data = { 'product_id': range(1, 101), 'product_name': [f'Product_{i}' for i in range(1, 101)], 'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Sports'], 100), 'price': np.random.uniform(10, 500, 100), 'quantity_sold': np.random.randint(10, 1000, 100), 'customer_rating': np.random.uniform(1, 5, 100), 'month': np.random.choice(['Jan', 'Feb', 'Mar', 'Apr', 'May'], 100)}df = pd.DataFrame(data)\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit1-data-processing/solutions/exercise_02_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7420952320098877,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom from sklearn.metrics import LinearRegression\nfrom mean_squared_error, mean_absolute_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit1-data-processing",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit2-regression/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7422349452972412,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as from sklearn.model_selection import plt\nfrom from sklearn.linear_model import train_test_split\nfrom LinearRegression, Ridge, from sklearn.preprocessing import Lasso\nfrom from sklearn.metrics import StandardScaler\nfrom mean_squared_error, r2_score\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.pyplot as from sklearn.model_selection import plt\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit2-regression",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit3-classification/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7438368797302246,
      "error": "An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                            confusion_matrix)\nfrom sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                            confusion_matrix)\nfrom sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.datasets import make_classification_plt.rcParams['axes.unicode_minus'] = False_sns.set_style(\"whitegrid\")\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 04",
      "unit": "unit3-classification",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit4-clustering/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.0026869773864746094,
      "error": "The notebook is invalid and is missing an expected key: metadata",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 82, in reads\n    raise ValidationError(msg) from None\njsonschema.exceptions.ValidationError: The notebook is invalid and is missing an expected key: metadata\n",
      "course": "Course 04",
      "unit": "unit4-clustering",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 04/unit5-model-selection/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.00030303001403808594,
      "error": "The notebook is invalid and is missing an expected key: metadata",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 99, in execute_notebook_nbclient\n    nb = read(f, as_version=4)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 174, in read\n    return reads(buf, as_version, capture_validation_error, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/__init__.py\", line 92, in reads\n    nb = reader.reads(s, **kwargs)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbformat/reader.py\", line 82, in reads\n    raise ValidationError(msg) from None\njsonschema.exceptions.ValidationError: The notebook is invalid and is missing an expected key: metadata\n",
      "course": "Course 04",
      "unit": "unit5-model-selection",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit1-ethics-foundations/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7971668243408203,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI EthicsExercise 1 Solution: Ethical Framework Application_This is the solution to Exercise 1.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\n# ============================================================================\n# SOLUTION: TASK 1 - Identify Ethical Issues\n# ============================================================================\ndef identify_ethical_issues():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify ethical issues in employee monitoring scenario\"\"\"_ethical_issues =  [\n ethical_issues = [\n {\n 'issue': 'Privacy Violation', 'issue_ar': '',\n 'severity': 9,\n 'description': 'Monitoring computer usage, emails, and keystrokes violates employee privacy',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Consent',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Employees may not be aware of or consent to this level of monitoring',\n 'description_ar': ''\n },\n {\n 'issue': 'Autonomy and Dignity',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Constant monitoring undermines employee autonomy and human dignity',\n 'description_ar': ''\n },\n {\n 'issue': 'Potential for Discrimination',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Productivity metrics may be biased against certain work styles or disabilities',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Transparency',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Employees may not know how their data is being used or evaluated',\n 'description_ar': ''\n }\n ]\n return ethical_issues\n# ============================================================================\n# SOLUTION: TASK 2 - Apply Ethical Frameworks\n# ============================================================================\ndef apply_utilitarianism():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nUtilitarian analysis\"\"\"_analysis =  {\n analysis = {\n 'benefits': [\n 'Increased productivity for company', 'Better performance management',\n 'Cost savings through efficiency',\n 'Data-driven decision making'\n ],\n 'harms': [\n 'Employee stress and anxiety',\n 'Loss of privacy',\n 'Reduced trust and morale',\n 'Potential for discrimination',\n 'Invasion of personal space'\n ],\n 'overall_utility': -2, # Harms outweigh benefits\n 'conclusion': 'Unethical - The harms to employees (stress, privacy loss, dignity)\noutweigh the benefits to the company. The overall utility is negative.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_deontology():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nDeontological analysis\"\"\"_analysis =  {\n analysis = {\n 'moral_rules': [\n 'Respect for human dignity', 'Right to privacy',\n 'Informed consent',\n 'Treat people as ends, not means',\n 'Fair treatment and non-discrimination'\n ],\n 'violations': [\n 'Violates right to privacy without consent',\n 'Uses employees as means to company ends',\n 'Lacks informed consent',\n 'May violate fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates multiple moral duties including respect for privacy, dignity, and informed consent. The system treats employees as means rather than ends.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_rights_based():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nRights-based analysis\"\"\"_analysis =  {\n analysis = {\n 'rights_at_stake': [\n 'Right to privacy', 'Right to autonomy',\n 'Right to dignity',\n 'Right to informed consent',\n 'Right to fair treatment',\n 'Right to work-life balance'\n ],\n 'violations': [\n 'Severe violation of privacy rights',\n 'Violation of autonomy and dignity',\n 'Lack of informed consent',\n 'Potential violation of fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates fundamental human rights including privacy, autonomy, and dignity. The system cannot be justified from a rights-based perspective.',\n 'conclusion_ar': ''\n }\n return analysis\n# ============================================================================\n# SOLUTION: TASK 3 - Identify Stakeholders\n# ============================================================================\ndef identify_stakeholders():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify all stakeholders\"\"\"_stakeholders =  {\n stakeholders = {\n 'Employees': {\n 'interests': ['Privacy', 'Autonomy', 'Fair treatment', 'Job security'],\n 'interests_ar': ['', '', '', ''],\n 'impact': 9, # Highly affected\n 'influence': 5 # Moderate influence\n },\n 'Company Management': {\n 'interests': ['Productivity', 'Cost efficiency', 'Performance metrics'],\n 'interests_ar': ['', '', ''],\n 'impact': 6, # Moderately affected\n 'influence': 9 # High influence\n },\n 'HR Department': {\n 'interests': ['Performance management', 'Compliance', 'Employee relations'],\n 'interests_ar': ['', '', ''],\n 'impact': 7,\n 'influence': 7\n },\n 'AI Developers': {\n 'interests': ['Technical success', 'Innovation', 'Ethical development'],\n 'interests_ar': ['', '', ''],\n 'impact': 5,\n 'influence': 8\n },\n 'Unions': {\n 'interests': ['Worker rights', 'Privacy protection', 'Fair treatment'],\n 'interests_ar': ['', '', ''],\n 'impact': 8,\n 'influence': 6\n },\n 'Regulators': {\n 'interests': ['Compliance', 'Privacy laws', 'Labor rights'],\n 'interests_ar': ['', '', ''],\n 'impact': 4,\n 'influence': 9\n }\n }\n return stakeholders\n# ============================================================================\n# SOLUTION: TASK 4 - Recommendations\n# ============================================================================\ndef provide_recommendations():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nProvide ethical recommendations\"\"\"_recommendations =  [\n recommendations = [\n {\n 'recommendation': 'Obtain explicit, informed consent from all employees',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Limit monitoring to work-related activities only',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Ensure transparency about what is monitored and how data is used',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Implement privacy-preserving techniques (e.g., aggregate data only)',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Regular audits for bias and discrimination',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Provide opt-out mechanisms for employees',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Establish clear accountability and redress mechanisms',\n 'recommendation_ar': '',\n 'priority': 'High'\n }\n ]\n return recommendations\n# ============================================================================\n# SOLUTION: TASK 5 - Visualizations\n# ============================================================================\ndef create_stakeholder_matrix(stakeholders):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nCreate stakeholder impact\"\"\"_names =  list(stakeholders.keys())\n names = list(stakeholders.keys())_impacts =  [s['impact'] for s in stakeholders.values()]\n impacts = [s['impact'] for s in stakeholders.values()]_influences =  [s['influence'] for s in stakeholders.values()]\n influences = [s['influence'] for s in stakeholders.values()]\n fig, ax = plt.subplots(figsize=(12, 8))_scatter =  ax.scatter(influences, impacts, s=200, alpha=0.6,\n scatter = ax.scatter(influences, impacts, s=200, alpha=0.6, \n c=range(len(names)), cmap='viridis', edgecolors='black', linewidth=2)\n for i, name in enumerate(names):\n ax.annotate(name, (influences[i], impacts[i]), \n xytext=(5, 5), textcoords='offset points', fontsize=9)\n ax.set_xlabel('Influence Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_ylabel('Impact Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Stakeholder Impact-Influence Matrix\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: stakeholder_matrix.png\")\nplt.close()\ndef create_ethical_issues_chart(ethical_issues):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"Create ethical issues severity chart\"\"\"\n_issues =  [e['issue'] for e in ethical_issues]\n issues = [e['issue'] for e in ethical_issues]_severities =  [e['severity'] for e in ethical_issues]\n severities = [e['severity'] for e in ethical_issues]_colors =  ['# e74_c3_c' if s >= 9 else '#f39_colors = ['# e74_c3_c' if s >= 9 else '#f39\nc12' if s >= 7 else '#3498\ndb' \n for s in severities]\n fig, ax = plt.subplots(figsize=(12, 8))_bars =  ax.barh(issues, severities, color=colors, alpha=0.8,\n bars = ax.barh(issues, severities, color=colors, alpha=0.8, \n edgecolor='black', linewidth=1.5)\nax.set_xlabel('Severity Score (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Ethical Issues Severity Analysis\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.grid(axis='x', alpha=0.3, linestyle='--')\nfor i, (bar, severity)\nin enumerate(zip(bars, severities)):\n ax.text(severity + 0.2, i, f'{severity}', \n va='center', fontweight='bold', fontsize=11)\n # Legend_high = mpatches.Patch(color='# e74_c3_c', label='High (9-10)' medium = mpatches.Patch(color='# f39\nc12', label='Medium (7-8)_low =  mpatches.Patch(color='# 3498_low = mpatches.Patch(color='# 3498\ndb', label='Low (<7)\nax.legend(handles=[high, medium, low], loc='lower right', fontsize=10)\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: ethical_issues_severity.png\")\nplt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\nprint(\"Unit 1 - Exercise 1 Solution\")\nprint(\"\")\nprint(\"=\"*80)\n # Task 1__\nprint(\"\\n\ud83d\udccb TASK 1: Ethical Issues\")\nprint(\"-\" * 60)_ethical_issues =  identify_ethical_issues()\n ethical_issues = identify_ethical_issues()\n for issue in ethical_issues:\n print(f\"\\n{issue[\"issue']}'issue_ar']}')\nprint(f\" Severity: {issue[\"severity']}')\nprint(f\" {issue[\"description']}')\n # Task 2__\nprint(\"\\n\\n\ud83d\udccb TASK 2: Framework Analysis\")\nprint(\"-\" * 60)\nprint(\"\\nUtilitarianism:\")_util =  apply_utilitarianism()\n util = apply_utilitarianism()\n print(f\" Overall Utility: {util[\"overall_utility']}')\nprint(f\" Conclusion: {util[\"conclusion']}')\nprint(\"\\nDeontology:\")_deon =  apply_deontology()\n deon = apply_deontology()\n print(f\" Conclusion: {deon[\"conclusion']}')\nprint(\"\\nRights-Based:\")_rights =  apply_rights_based()\n rights = apply_rights_based()\n print(f\" Conclusion: {rights[\"conclusion']}')\n # Task 3__\nprint(\"\\n\\n\ud83d\udccb TASK 3: Stakeholders\")\nprint(\"-\" * 60)_stakeholders =  identify_stakeholders()\n stakeholders = identify_stakeholders()\n for name, info in stakeholders.items():\n print(f\"\\n{name}:\")\nprint(f\" Impact: {info[\"impact']}'influence']}')\nprint(f\" Interests: {\", '.join(info['interests'])}')\n # Task 4__\nprint(\"\\n\\n\ud83d\udccb TASK 4: Recommendations\")\nprint(\"-\" * 60)_recommendations =  provide_recommendations()\n recommendations = provide_recommendations()\n for i, rec in enumerate(recommendations, 1):\n print(f\"\\n{i}. [{rec[\"priority']}] {rec['recommendation']}')\nprint(f\" {rec[\"recommendation_ar']}')\n # Task 5__\nprint(\"\\n\\n\ud83d\udccb TASK 5: Creating Visualizations\")\nprint(\"-\" * 60)\ncreate_stakeholder_matrix(stakeholders)\ncreate_ethical_issues_chart(ethical_issues)\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 Solution completed successfully!\")\nprint(\"\")\nprint(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 1: Foundations of AI EthicsExercise 1 Solution: Ethical Framework Application_This is the solution to Exercise 1.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\n# ============================================================================\n# SOLUTION: TASK 1 - Identify Ethical Issues\n# ============================================================================\ndef identify_ethical_issues():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify ethical issues in employee monitoring scenario\"\"\"_ethical_issues =  [\n ethical_issues = [\n {\n 'issue': 'Privacy Violation', 'issue_ar': '',\n 'severity': 9,\n 'description': 'Monitoring computer usage, emails, and keystrokes violates employee privacy',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Consent',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Employees may not be aware of or consent to this level of monitoring',\n 'description_ar': ''\n },\n {\n 'issue': 'Autonomy and Dignity',\n 'issue_ar': '',\n 'severity': 8,\n 'description': 'Constant monitoring undermines employee autonomy and human dignity',\n 'description_ar': ''\n },\n {\n 'issue': 'Potential for Discrimination',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Productivity metrics may be biased against certain work styles or disabilities',\n 'description_ar': ''\n },\n {\n 'issue': 'Lack of Transparency',\n 'issue_ar': '',\n 'severity': 7,\n 'description': 'Employees may not know how their data is being used or evaluated',\n 'description_ar': ''\n }\n ]\n return ethical_issues\n# ============================================================================\n# SOLUTION: TASK 2 - Apply Ethical Frameworks\n# ============================================================================\ndef apply_utilitarianism():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nUtilitarian analysis\"\"\"_analysis =  {\n analysis = {\n 'benefits': [\n 'Increased productivity for company', 'Better performance management',\n 'Cost savings through efficiency',\n 'Data-driven decision making'\n ],\n 'harms': [\n 'Employee stress and anxiety',\n 'Loss of privacy',\n 'Reduced trust and morale',\n 'Potential for discrimination',\n 'Invasion of personal space'\n ],\n 'overall_utility': -2, # Harms outweigh benefits\n 'conclusion': 'Unethical - The harms to employees (stress, privacy loss, dignity)\noutweigh the benefits to the company. The overall utility is negative.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_deontology():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nDeontological analysis\"\"\"_analysis =  {\n analysis = {\n 'moral_rules': [\n 'Respect for human dignity', 'Right to privacy',\n 'Informed consent',\n 'Treat people as ends, not means',\n 'Fair treatment and non-discrimination'\n ],\n 'violations': [\n 'Violates right to privacy without consent',\n 'Uses employees as means to company ends',\n 'Lacks informed consent',\n 'May violate fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates multiple moral duties including respect for privacy, dignity, and informed consent. The system treats employees as means rather than ends.',\n 'conclusion_ar': ''\n }\n return analysis\ndef apply_rights_based():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nRights-based analysis\"\"\"_analysis =  {\n analysis = {\n 'rights_at_stake': [\n 'Right to privacy', 'Right to autonomy',\n 'Right to dignity',\n 'Right to informed consent',\n 'Right to fair treatment',\n 'Right to work-life balance'\n ],\n 'violations': [\n 'Severe violation of privacy rights',\n 'Violation of autonomy and dignity',\n 'Lack of informed consent',\n 'Potential violation of fair treatment if biased'\n ],\n 'conclusion': 'Unethical - Violates fundamental human rights including privacy, autonomy, and dignity. The system cannot be justified from a rights-based perspective.',\n 'conclusion_ar': ''\n }\n return analysis\n# ============================================================================\n# SOLUTION: TASK 3 - Identify Stakeholders\n# ============================================================================\ndef identify_stakeholders():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nIdentify all stakeholders\"\"\"_stakeholders =  {\n stakeholders = {\n 'Employees': {\n 'interests': ['Privacy', 'Autonomy', 'Fair treatment', 'Job security'],\n 'interests_ar': ['', '', '', ''],\n 'impact': 9, # Highly affected\n 'influence': 5 # Moderate influence\n },\n 'Company Management': {\n 'interests': ['Productivity', 'Cost efficiency', 'Performance metrics'],\n 'interests_ar': ['', '', ''],\n 'impact': 6, # Moderately affected\n 'influence': 9 # High influence\n },\n 'HR Department': {\n 'interests': ['Performance management', 'Compliance', 'Employee relations'],\n 'interests_ar': ['', '', ''],\n 'impact': 7,\n 'influence': 7\n },\n 'AI Developers': {\n 'interests': ['Technical success', 'Innovation', 'Ethical development'],\n 'interests_ar': ['', '', ''],\n 'impact': 5,\n 'influence': 8\n },\n 'Unions': {\n 'interests': ['Worker rights', 'Privacy protection', 'Fair treatment'],\n 'interests_ar': ['', '', ''],\n 'impact': 8,\n 'influence': 6\n },\n 'Regulators': {\n 'interests': ['Compliance', 'Privacy laws', 'Labor rights'],\n 'interests_ar': ['', '', ''],\n 'impact': 4,\n 'influence': 9\n }\n }\n return stakeholders\n# ============================================================================\n# SOLUTION: TASK 4 - Recommendations\n# ============================================================================\ndef provide_recommendations():\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nProvide ethical recommendations\"\"\"_recommendations =  [\n recommendations = [\n {\n 'recommendation': 'Obtain explicit, informed consent from all employees',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Limit monitoring to work-related activities only',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Ensure transparency about what is monitored and how data is used',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Implement privacy-preserving techniques (e.g., aggregate data only)',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Regular audits for bias and discrimination',\n 'recommendation_ar': '',\n 'priority': 'High'\n },\n {\n 'recommendation': 'Provide opt-out mechanisms for employees',\n 'recommendation_ar': '',\n 'priority': 'Medium'\n },\n {\n 'recommendation': 'Establish clear accountability and redress mechanisms',\n 'recommendation_ar': '',\n 'priority': 'High'\n }\n ]\n return recommendations\n# ============================================================================\n# SOLUTION: TASK 5 - Visualizations\n# ============================================================================\ndef create_stakeholder_matrix(stakeholders):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nCreate stakeholder impact\"\"\"_names =  list(stakeholders.keys())\n names = list(stakeholders.keys())_impacts =  [s['impact'] for s in stakeholders.values()]\n impacts = [s['impact'] for s in stakeholders.values()]_influences =  [s['influence'] for s in stakeholders.values()]\n influences = [s['influence'] for s in stakeholders.values()]\n fig, ax = plt.subplots(figsize=(12, 8))_scatter =  ax.scatter(influences, impacts, s=200, alpha=0.6,\n scatter = ax.scatter(influences, impacts, s=200, alpha=0.6, \n c=range(len(names)), cmap='viridis', edgecolors='black', linewidth=2)\n for i, name in enumerate(names):\n ax.annotate(name, (influences[i], impacts[i]), \n xytext=(5, 5), textcoords='offset points', fontsize=9)\n ax.set_xlabel('Influence Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_ylabel('Impact Level (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Stakeholder Impact-Influence Matrix\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.grid(True, alpha=0.3, linestyle='--')\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: stakeholder_matrix.png\")\nplt.close()\ndef create_ethical_issues_chart(ethical_issues):\n \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"Create ethical issues severity chart\"\"\"\n_issues =  [e['issue'] for e in ethical_issues]\n issues = [e['issue'] for e in ethical_issues]_severities =  [e['severity'] for e in ethical_issues]\n severities = [e['severity'] for e in ethical_issues]_colors =  ['# e74_c3_c' if s >= 9 else '#f39_colors = ['# e74_c3_c' if s >= 9 else '#f39\nc12' if s >= 7 else '#3498\ndb' \n for s in severities]\n fig, ax = plt.subplots(figsize=(12, 8))_bars =  ax.barh(issues, severities, color=colors, alpha=0.8,\n bars = ax.barh(issues, severities, color=colors, alpha=0.8, \n edgecolor='black', linewidth=1.5)\nax.set_xlabel('Severity Score (1-10)', fontsize=12, fontweight='bold')\n ax.set_title('Ethical Issues Severity Analysis\\n'\n '', fontsize=14, fontweight='bold', pad=20)\nax.set_xlim(0, 10)\nax.grid(axis='x', alpha=0.3, linestyle='--')\nfor i, (bar, severity)\nin enumerate(zip(bars, severities)):\n ax.text(severity + 0.2, i, f'{severity}', \n va='center', fontweight='bold', fontsize=11)\n # Legend_high = mpatches.Patch(color='# e74_c3_c', label='High (9-10)' medium = mpatches.Patch(color='# f39\nc12', label='Medium (7-8)_low =  mpatches.Patch(color='# 3498_low = mpatches.Patch(color='# 3498\ndb', label='Low (<7)\nax.legend(handles=[high, medium, low], loc='lower right', fontsize=10)\nplt.tight_layout()\n plt.savefig('unit1-ethics-foundations', dpi=300, bbox_inches = 'tight')\nprint(\"\u2705 Saved: ethical_issues_severity.png\")\nplt.close()\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\nprint(\"Unit 1 - Exercise 1 Solution\")\nprint(\"\")\nprint(\"=\"*80)\n # Task 1__\nprint(\"\\n\ud83d\udccb TASK 1: Ethical Issues\")\nprint(\"-\" * 60)_ethical_issues =  identify_ethical_issues()\n ethical_issues = identify_ethical_issues()\n for issue in ethical_issues:\n print(f\"\\n{issue[\"issue']}'issue_ar']}')\nprint(f\" Severity: {issue[\"severity']}')\nprint(f\" {issue[\"description']}')\n # Task 2__\nprint(\"\\n\\n\ud83d\udccb TASK 2: Framework Analysis\")\nprint(\"-\" * 60)\nprint(\"\\nUtilitarianism:\")_util =  apply_utilitarianism()\n util = apply_utilitarianism()\n print(f\" Overall Utility: {util[\"overall_utility']}')\nprint(f\" Conclusion: {util[\"conclusion']}')\nprint(\"\\nDeontology:\")_deon =  apply_deontology()\n deon = apply_deontology()\n print(f\" Conclusion: {deon[\"conclusion']}')\nprint(\"\\nRights-Based:\")_rights =  apply_rights_based()\n rights = apply_rights_based()\n print(f\" Conclusion: {rights[\"conclusion']}')\n # Task 3__\nprint(\"\\n\\n\ud83d\udccb TASK 3: Stakeholders\")\nprint(\"-\" * 60)_stakeholders =  identify_stakeholders()\n stakeholders = identify_stakeholders()\n for name, info in stakeholders.items():\n print(f\"\\n{name}:\")\nprint(f\" Impact: {info[\"impact']}'influence']}')\nprint(f\" Interests: {\", '.join(info['interests'])}')\n # Task 4__\nprint(\"\\n\\n\ud83d\udccb TASK 4: Recommendations\")\nprint(\"-\" * 60)_recommendations =  provide_recommendations()\n recommendations = provide_recommendations()\n for i, rec in enumerate(recommendations, 1):\n print(f\"\\n{i}. [{rec[\"priority']}] {rec['recommendation']}')\nprint(f\" {rec[\"recommendation_ar']}')\n # Task 5__\nprint(\"\\n\\n\ud83d\udccb TASK 5: Creating Visualizations\")\nprint(\"-\" * 60)\ncreate_stakeholder_matrix(stakeholders)\ncreate_ethical_issues_chart(ethical_issues)\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 Solution completed successfully!\")\nprint(\"\")\nprint(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import matplotlib.patches as mpatches_plt.rcParams['font.size'] = 10_plt.rcParams['figure.figsize'] = (14, 8)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n\n\n",
      "course": "Course 06",
      "unit": "unit1-ethics-foundations",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit2-bias-justice/solutions/exercise_02_solution.ipynb",
      "status": "failed",
      "execution_time": 0.833892822265625,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI_Exercise 2 Solution: Bias Mitigation TechniquesComplete solution for the bias mitigation exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# SOLUTION 1: Generate Biased Dataset\n# ============================================================================\ndef generate_biased_dataset(n_samples = 2000):\n \n    \n    \n    \"\"\"\n Generate a synthetic dataset with bias.\n \"\"\"\n np.random.seed(42)\n # Sensitive attribute (e.g., gender: 0 = group A, 1 = group B)\n sensitive = np.random.binomial(1, 0.5, n_samples)\n # Features_X1 = np.random.normal(0, 1, n_samples)\n X2 = np.random.normal(0, 1, n_samples)\n # Introduce bias: group B has lower probability of positive outcome_true_prob = 0.3 + 0.4 * X1 + 0.3 * X2_bias_penalty = 0.3 * (1 - sensitive) # Group B (0) gets penalty_prob = true_prob - bias_penalty + np.random.normal(0, 0.1, n_samples)\n prob = np.clip(prob, 0, 1)\n # Target variable_y = (prob > 0.5).astype(int)\n # Create DataFrame_df = pd.DataFrame({\n 'feature1': X1, 'feature2': X2,\n 'sensitive': sensitive,\n 'target': y\n })\n return df\n# ============================================================================\n# SOLUTION 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Implement reweighing technique.\n \"\"\"\n # Calculate weights to balance groups_group_counts = pd.Series(sensitive_train).value_counts()\n total = len(sensitive_train)_weights =  np.ones(len(sensitive_train))\n weights = np.ones(len(sensitive_train))\n for group in group_counts.index:\n group_size = group_counts[group]\n # Weight inversely proportional to group size_weights[sensitive_train = = group] = total\n(len(group_counts) * group_size)\n return weights\n# ============================================================================\n# SOLUTION 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \n    \"\"\"\n Train a baseline model without any bias mitigation.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)_model =  RandomForestClassifier(n_estimators = 100, random_state = 42)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train)\n return model, scaler\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Train a model using reweighing technique.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)\n # Get weights from reweighing_weights = preprocess_reweighing(X_train_scaled, y_train, sensitive_train)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train, sample_weight = weights)\n return model, scaler\n# ============================================================================\n# SOLUTION 4: Evaluate Fairness Metrics\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \n    \"\"\"\n Evaluate fairness metrics.\n \"\"\"\n_metrics =  {\n metrics = {\n 'demographic_parity_diff': demographic_parity_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'equalized_odds_diff': equalized_odds_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'accuracy': accuracy_score(y_true, y_pred)\n }\n return metrics\n# ============================================================================\n# SOLUTION 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \n    \"\"\"\n Compare baseline vs reweighing techniques.\n \"\"\"\n # Prepare data_X = df[['feature1', 'feature2']].valuesy = df['target'].values_sensitive = df['sensitive'].values\n # Split data_X_train, X_test, y_train, y_test, sensitive\ntrain, sensitive_test = train_test_split(\n X, y, sensitive, test_size = 0.3, random_state = 42, stratify=y\n )\n print(\"\\n\" + \"=\"*80)\n print(\"BASELINE MODEL (No Mitigation)\")\n print(\"=\"*80)\n # Train baseline model_baseline\nmodel, baseline_scaler = train_baseline_model(X_train, y_train)_X_test_scaled =  baseline_scaler.transform(X_test)\n X_test_scaled = baseline_scaler.transform(X_test)_y_pred_baseline =  baseline_model.predict(X_test_scaled)\n y_pred_baseline = baseline_model.predict(X_test_scaled)\n # Evaluate baseline_baseline_metrics = evaluate_fairness(y_test, y_pred_baseline, sensitive_test)\n print(f\"Accuracy: {baseline_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {baseline_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {baseline_metrics[\"equalized_odds_diff']:.4 f}')\n print(\"\\n\" + \"=\"*80)\n print(\"REWEIGHING MODEL\")\n print(\"=\"*80)\n # Train reweighed model_reweigh\nmodel, reweigh_scaler = train_reweighed_model(X_train, y_train, sensitive_train)_X_test_reweigh =  reweigh_scaler.transform(X_test)\n X_test_reweigh = reweigh_scaler.transform(X_test)_y_pred_reweigh =  reweigh_model.predict(X_test_reweigh)\n y_pred_reweigh = reweigh_model.predict(X_test_reweigh)\n # Evaluate reweighing_reweigh_metrics = evaluate_fairness(y_test, y_pred_reweigh, sensitive_test)\n print(f\"Accuracy: {reweigh_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {reweigh_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {reweigh_metrics[\"equalized_odds_diff']:.4 f}')\n # Comparison__\nprint(\"\\n\" + \"=\"*80)\n print(\"COMPARISON\")\n print(\"=\"*80)\n print(f\"Demographic Parity Improvement: \"\n f\"{abs(baseline_metrics[\"demographic_parity_diff']) - abs(reweigh_metrics['demographic_parity_diff']):.4 f}')\n print(f\"Equalized Odds Improvement: \"\n f\"{abs(baseline_metrics[\"equalized_odds_diff']) - abs(reweigh_metrics['equalized_odds_diff']):.4 f}')\n print(f\"Accuracy Change: {reweigh_metrics[\"accuracy'] - baseline_metrics['accuracy']:.4 f}')\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2 Solution: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate dataset__\nprint(\"\\nGenerating biased dataset...\")_df =  generate_biased_dataset()\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"\\nSensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n print(f\"\\nTarget distribution:\")\n print(df['target'].value_counts())\n # Compare techniques_compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Solution completed!\")\n print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 2: Bias, Justice, and Discrimination in AI_Exercise 2 Solution: Bias Mitigation TechniquesComplete solution for the bias mitigation exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n# ============================================================================\n# SOLUTION 1: Generate Biased Dataset\n# ============================================================================\ndef generate_biased_dataset(n_samples = 2000):\n \n    \n    \n    \"\"\"\n Generate a synthetic dataset with bias.\n \"\"\"\n np.random.seed(42)\n # Sensitive attribute (e.g., gender: 0 = group A, 1 = group B)\n sensitive = np.random.binomial(1, 0.5, n_samples)\n # Features_X1 = np.random.normal(0, 1, n_samples)\n X2 = np.random.normal(0, 1, n_samples)\n # Introduce bias: group B has lower probability of positive outcome_true_prob = 0.3 + 0.4 * X1 + 0.3 * X2_bias_penalty = 0.3 * (1 - sensitive) # Group B (0) gets penalty_prob = true_prob - bias_penalty + np.random.normal(0, 0.1, n_samples)\n prob = np.clip(prob, 0, 1)\n # Target variable_y = (prob > 0.5).astype(int)\n # Create DataFrame_df = pd.DataFrame({\n 'feature1': X1, 'feature2': X2,\n 'sensitive': sensitive,\n 'target': y\n })\n return df\n# ============================================================================\n# SOLUTION 2: Implement Pre-processing Bias Mitigation\n# ============================================================================\ndef preprocess_reweighing(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Implement reweighing technique.\n \"\"\"\n # Calculate weights to balance groups_group_counts = pd.Series(sensitive_train).value_counts()\n total = len(sensitive_train)_weights =  np.ones(len(sensitive_train))\n weights = np.ones(len(sensitive_train))\n for group in group_counts.index:\n group_size = group_counts[group]\n # Weight inversely proportional to group size_weights[sensitive_train = = group] = total\n(len(group_counts) * group_size)\n return weights\n# ============================================================================\n# SOLUTION 3: Train Models with Different Mitigation Techniques\n# ============================================================================\ndef train_baseline_model(X_train, y_train):\n \n    \n    \n    \"\"\"\n Train a baseline model without any bias mitigation.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)_model =  RandomForestClassifier(n_estimators = 100, random_state = 42)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train)\n return model, scaler\ndef train_reweighed_model(X_train, y_train, sensitive_train):\n \n    \n    \n    \"\"\"\n Train a model using reweighing technique.\n \"\"\"\n_scaler =  StandardScaler()\n scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n X_train_scaled = scaler.fit_transform(X_train)\n # Get weights from reweighing_weights = preprocess_reweighing(X_train_scaled, y_train, sensitive_train)\n model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n model.fit(X_train_scaled, y_train, sample_weight = weights)\n return model, scaler\n# ============================================================================\n# SOLUTION 4: Evaluate Fairness Metrics\n# ============================================================================\ndef evaluate_fairness(y_true, y_pred, sensitive):\n \n    \n    \n    \"\"\"\n Evaluate fairness metrics.\n \"\"\"\n_metrics =  {\n metrics = {\n 'demographic_parity_diff': demographic_parity_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'equalized_odds_diff': equalized_odds_difference(\n y_true, y_pred, sensitive_features = sensitive\n ),\n 'accuracy': accuracy_score(y_true, y_pred)\n }\n return metrics\n# ============================================================================\n# SOLUTION 5: Compare Techniques\n# ============================================================================\ndef compare_mitigation_techniques(df):\n \n    \n    \n    \"\"\"\n Compare baseline vs reweighing techniques.\n \"\"\"\n # Prepare data_X = df[['feature1', 'feature2']].valuesy = df['target'].values_sensitive = df['sensitive'].values\n # Split data_X_train, X_test, y_train, y_test, sensitive\ntrain, sensitive_test = train_test_split(\n X, y, sensitive, test_size = 0.3, random_state = 42, stratify=y\n )\n print(\"\\n\" + \"=\"*80)\n print(\"BASELINE MODEL (No Mitigation)\")\n print(\"=\"*80)\n # Train baseline model_baseline\nmodel, baseline_scaler = train_baseline_model(X_train, y_train)_X_test_scaled =  baseline_scaler.transform(X_test)\n X_test_scaled = baseline_scaler.transform(X_test)_y_pred_baseline =  baseline_model.predict(X_test_scaled)\n y_pred_baseline = baseline_model.predict(X_test_scaled)\n # Evaluate baseline_baseline_metrics = evaluate_fairness(y_test, y_pred_baseline, sensitive_test)\n print(f\"Accuracy: {baseline_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {baseline_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {baseline_metrics[\"equalized_odds_diff']:.4 f}')\n print(\"\\n\" + \"=\"*80)\n print(\"REWEIGHING MODEL\")\n print(\"=\"*80)\n # Train reweighed model_reweigh\nmodel, reweigh_scaler = train_reweighed_model(X_train, y_train, sensitive_train)_X_test_reweigh =  reweigh_scaler.transform(X_test)\n X_test_reweigh = reweigh_scaler.transform(X_test)_y_pred_reweigh =  reweigh_model.predict(X_test_reweigh)\n y_pred_reweigh = reweigh_model.predict(X_test_reweigh)\n # Evaluate reweighing_reweigh_metrics = evaluate_fairness(y_test, y_pred_reweigh, sensitive_test)\n print(f\"Accuracy: {reweigh_metrics[\"accuracy']:.4 f}')\n print(f\"Demographic Parity Difference: {reweigh_metrics[\"demographic_parity_diff']:.4 f}')\n print(f\"Equalized Odds Difference: {reweigh_metrics[\"equalized_odds_diff']:.4 f}')\n # Comparison__\nprint(\"\\n\" + \"=\"*80)\n print(\"COMPARISON\")\n print(\"=\"*80)\n print(f\"Demographic Parity Improvement: \"\n f\"{abs(baseline_metrics[\"demographic_parity_diff']) - abs(reweigh_metrics['demographic_parity_diff']):.4 f}')\n print(f\"Equalized Odds Improvement: \"\n f\"{abs(baseline_metrics[\"equalized_odds_diff']) - abs(reweigh_metrics['equalized_odds_diff']):.4 f}')\n print(f\"Accuracy Change: {reweigh_metrics[\"accuracy'] - baseline_metrics['accuracy']:.4 f}')\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\nif__name__ == \"__main__\":\n print(\"=\"*80)\n print(\"Unit 2 - Exercise 2 Solution: Bias Mitigation Techniques\")\n print(\"=\"*80)\n # Generate dataset__\nprint(\"\\nGenerating biased dataset...\")_df =  generate_biased_dataset()\n df = generate_biased_dataset()\n print(f\"Dataset shape: {df.shape}\")\n print(f\"\\nSensitive attribute distribution:\")\n print(df['sensitive'].value_counts())\n print(f\"\\nTarget distribution:\")\n print(df['target'].value_counts())\n # Compare techniques_compare_mitigation_techniques(df)\n print(\"\\n\" + \"=\"*80)\n print(\"Solution completed!\")\n print(\"=\"*80)\n------------------\n\n\n\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n\n\n",
      "course": "Course 06",
      "unit": "unit2-bias-justice",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit3-privacy-security/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.6371171474456787,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1 Solution: Privacy Techniques\nComplete solution for the privacy techniques exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport hashlib\ndef anonymize_data(df, columns_to_anonymize):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data anonymization\"\"\"_df_anonymized =  df.copy()\n    df_anonymized = df.copy()\n    for col in columns_to_anonymize:\n        if col in df_anonymized.columns:\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]\n    return df_anonymized\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data pseudonymization using hashing\"\"\"_df_pseudonymized =  df.copy()\n    df_pseudonymized = df.copy()\n    for col in columns_to_pseudonymize:\n        if col in df_pseudonymized.columns:\n            df_pseudonymized[col] = df_pseudonymized[col].apply(lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]\n            )\n    return df_pseudonymized\ndef add_differential_privacy_noise(value, epsilon=1.0, sensitivity=1.0):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nAdd Laplace noise for differential privacy\"\"\"_scale =  sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nscale = sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nreturn value + noise\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 3 - Exercise 1 Solution: Privacy Techniques\")\nprint(\"=\"*80)\n    # Test with sample data_np.random.seed(42)\ndf = pd.DataFrame({\n        'name': [f'Person_{i}' for i in range(10)], 'email': [f'user{i}@example.com' for i in range(10)], 'value': np.random.normal(100, 20, 10)\n    })\n    print(\"\\nOriginal Data:\")\nprint(df.head())\n    print(\"\\nAnonymized Data:\")_df_anon =  anonymize_data(df, ['name', 'email'])\ndf_anon = anonymize_data(df, ['name', 'email'])\nprint(df_anon.head())\n    print(\"\\nPseudonymized Data:\")_df_pseudo =  pseudonymize_data(df, ['name', 'email'])\ndf_pseudo = pseudonymize_data(df, ['name', 'email'])\nprint(df_pseudo.head())\n    print(\"\\nDifferential Privacy:\")_true_mean =  df['value'].mean()\n    true_mean = df['value'].mean()_noisy_mean =  add_differential_privacy_noise(true_mean, epsilon=1.0)\nnoisy_mean = add_differential_privacy_noise(true_mean, epsilon=1.0)\nprint(f\"True mean: {true_mean:.2f}\")\nprint(f\"Noisy mean: {noisy_mean:.2f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    Implement data anonymization\"\"\"_df_anonymized =  df.copy()\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 3: Privacy, Security, and Data Protection\nExercise 1 Solution: Privacy Techniques\nComplete solution for the privacy techniques exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport hashlib\ndef anonymize_data(df, columns_to_anonymize):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data anonymization\"\"\"_df_anonymized =  df.copy()\n    df_anonymized = df.copy()\n    for col in columns_to_anonymize:\n        if col in df_anonymized.columns:\n            df_anonymized[col] = [f'ID_{i}' for i in range(len(df_anonymized))]\n    return df_anonymized\ndef pseudonymize_data(df, columns_to_pseudonymize, salt='default_salt'):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nImplement data pseudonymization using hashing\"\"\"_df_pseudonymized =  df.copy()\n    df_pseudonymized = df.copy()\n    for col in columns_to_pseudonymize:\n        if col in df_pseudonymized.columns:\n            df_pseudonymized[col] = df_pseudonymized[col].apply(lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()[:16]\n            )\n    return df_pseudonymized\ndef add_differential_privacy_noise(value, epsilon=1.0, sensitivity=1.0):\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \"\"\"\nAdd Laplace noise for differential privacy\"\"\"_scale =  sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nscale = sensitivity\nepsilon_noise = np.random.laplace(0, scale)\nreturn value + noise\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 3 - Exercise 1 Solution: Privacy Techniques\")\nprint(\"=\"*80)\n    # Test with sample data_np.random.seed(42)\ndf = pd.DataFrame({\n        'name': [f'Person_{i}' for i in range(10)], 'email': [f'user{i}@example.com' for i in range(10)], 'value': np.random.normal(100, 20, 10)\n    })\n    print(\"\\nOriginal Data:\")\nprint(df.head())\n    print(\"\\nAnonymized Data:\")_df_anon =  anonymize_data(df, ['name', 'email'])\ndf_anon = anonymize_data(df, ['name', 'email'])\nprint(df_anon.head())\n    print(\"\\nPseudonymized Data:\")_df_pseudo =  pseudonymize_data(df, ['name', 'email'])\ndf_pseudo = pseudonymize_data(df, ['name', 'email'])\nprint(df_pseudo.head())\n    print(\"\\nDifferential Privacy:\")_true_mean =  df['value'].mean()\n    true_mean = df['value'].mean()_noisy_mean =  add_differential_privacy_noise(true_mean, epsilon=1.0)\nnoisy_mean = add_differential_privacy_noise(true_mean, epsilon=1.0)\nprint(f\"True mean: {true_mean:.2f}\")\nprint(f\"Noisy mean: {noisy_mean:.2f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    Implement data anonymization\"\"\"_df_anonymized =  df.copy()\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit3-privacy-security",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit4-transparency-accountability/solutions/exercise_01_solution.ipynb",
      "status": "failed",
      "execution_time": 0.7689108848571777,
      "error": "An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1 Solution: SHAP and LIME Explanations\nComplete solution for the SHAP/LIME exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\nage = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples)\nincome = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples)\ncredit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\napproval = (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\nreturn pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval})\ndef calculate_shap_values(model, X_sample, X_train, feature_names):\n    baseline = model.predict_proba(X_train)[:, 1].mean()_sample_pred =  model.predict_proba(X_sample)[0, 1]\n    sample_pred = model.predict_proba(X_sample)[0, 1]_shap_values =  []\n    shap_values = []\n    for i in range(len(feature_names)):\n        X_perm = X_train.copy()\n        X_perm[:, i] = X_sample[0, i]_perm_pred =  model.predict_proba(X_perm)[:, 1].mean()\n        perm_pred = model.predict_proba(X_perm)[:, 1].mean()\n        shap_values.append(sample_pred - perm_pred)\nreturn np.array(shap_values)\ndef calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    perturbations = np.random.normal(0, 0.1, (1000, X_sample.shape[1]))_X_pert =  X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]\n    X_pert = X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]_distances =  np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))\n    distances = np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))_linear_model =  Ridge(alpha=0.1)\nlinear_model = Ridge(alpha=0.1)\nlinear_model.fit(X_pert, y_pert, sample_weight=distances)\nreturn linear_model.coef_\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 4 - Exercise 1 Solution: SHAP and LIME Explanations\")\nprint(\"=\"*80)_df =  generate_dataset()\n    df = generate_dataset()_X =  df[['age', 'income', 'credit_score']].values_y = df['approved'].values_X = df[['age', 'income', 'credit_score']].values_y = df['approved'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)_scaler =  StandardScaler()\n    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n    X_test_scaled = scaler.transform(X_test)_model =  RandomForestClassifier(n_estimators=100, random_state=42)\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)_sample =  X_test_scaled[0:1]\n    sample = X_test_scaled[0:1]_feature_names =  ['age', 'income', 'credit_score']\n    feature_names = ['age', 'income', 'credit_score']_shap_vals =  calculate_shap_values(model, sample, X_train_scaled, feature_names)\nshap_vals = calculate_shap_values(model, sample, X_train_scaled, feature_names)_lime_vals =  calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nlime_vals = calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nprint(\"\\nSHAP Values:\")\nfor name, val in zip(feature_names, shap_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\nLIME Values:\")\nfor name, val in zip(feature_names, lime_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\n\"\"\"\nUnit 4: Interpretability, Transparency, and Accountability\nExercise 1 Solution: SHAP and LIME Explanations\nComplete solution for the SHAP/LIME exercise.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\ndef generate_dataset(n_samples=1000):\n    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\nage = np.random.randint(25, 70, n_samples)_income =  np.random.normal(60000, 25000, n_samples)\nincome = np.random.normal(60000, 25000, n_samples)_credit_score =  np.random.normal(650, 100, n_samples)\ncredit_score = np.random.normal(650, 100, n_samples)_approval =  (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\napproval = (credit_score\n850 * 0.5 + income\n100000 * 0.3 + np.random.normal(0, 0.05, n_samples) > 0.5).astype(int)\nreturn pd.DataFrame({'age': age, 'income': income, 'credit_score': credit_score, 'approved': approval})\ndef calculate_shap_values(model, X_sample, X_train, feature_names):\n    baseline = model.predict_proba(X_train)[:, 1].mean()_sample_pred =  model.predict_proba(X_sample)[0, 1]\n    sample_pred = model.predict_proba(X_sample)[0, 1]_shap_values =  []\n    shap_values = []\n    for i in range(len(feature_names)):\n        X_perm = X_train.copy()\n        X_perm[:, i] = X_sample[0, i]_perm_pred =  model.predict_proba(X_perm)[:, 1].mean()\n        perm_pred = model.predict_proba(X_perm)[:, 1].mean()\n        shap_values.append(sample_pred - perm_pred)\nreturn np.array(shap_values)\ndef calculate_lime_explanation(model, X_sample, X_train, feature_names):\n    perturbations = np.random.normal(0, 0.1, (1000, X_sample.shape[1]))_X_pert =  X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]\n    X_pert = X_sample + perturbations_y_pert = model.predict_proba(X_pert)[:, 1]_distances =  np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))\n    distances = np.exp(-np.sum((X_pert - X_sample) ** 2, axis=1))_linear_model =  Ridge(alpha=0.1)\nlinear_model = Ridge(alpha=0.1)\nlinear_model.fit(X_pert, y_pert, sample_weight=distances)\nreturn linear_model.coef_\nif__name__ == \"__main__\":\n    print(\"=\"*80)\nprint(\"Unit 4 - Exercise 1 Solution: SHAP and LIME Explanations\")\nprint(\"=\"*80)_df =  generate_dataset()\n    df = generate_dataset()_X =  df[['age', 'income', 'credit_score']].values_y = df['approved'].values_X = df[['age', 'income', 'credit_score']].values_y = df['approved'].values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)_scaler =  StandardScaler()\n    scaler = StandardScaler()_X_train_scaled =  scaler.fit_transform(X_train)\n    X_train_scaled = scaler.fit_transform(X_train)_X_test_scaled =  scaler.transform(X_test)\n    X_test_scaled = scaler.transform(X_test)_model =  RandomForestClassifier(n_estimators=100, random_state=42)\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)_sample =  X_test_scaled[0:1]\n    sample = X_test_scaled[0:1]_feature_names =  ['age', 'income', 'credit_score']\n    feature_names = ['age', 'income', 'credit_score']_shap_vals =  calculate_shap_values(model, sample, X_train_scaled, feature_names)\nshap_vals = calculate_shap_values(model, sample, X_train_scaled, feature_names)_lime_vals =  calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nlime_vals = calculate_lime_explanation(model, sample, X_train_scaled, feature_names)\nprint(\"\\nSHAP Values:\")\nfor name, val in zip(feature_names, shap_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\nLIME Values:\")\nfor name, val in zip(feature_names, lime_vals):\n        print(f\"  {name}: {val:.4f}\")\nprint(\"\\n\u2705 Solution completed!\")\n\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.random.seed(42)_age =  np.random.randint(25, 70, n_samples)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": "Course 06",
      "unit": "unit4-transparency-accountability",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course 06/unit5-governance-regulations/solutions/exercise_01_solution.ipynb",
      "status": "passed",
      "execution_time": 0.5920982360839844,
      "error": null,
      "error_traceback": null,
      "course": "Course 06",
      "unit": "unit5-governance-regulations",
      "type": "other"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_01/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.6931588649749756,
      "error": "An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\nprint(\"=\" * 60) # Test 1: Create data matrix print(\"\\n1. create_data_matrix:\")\ndata = create_data_matrix(5, 3)\nprint(f\" Created matrix shape: {data.shape}\")\nprint(f\" Matrix:\\n{data}\") # Test 2: Dot product print(\"\\n2. compute_dot_product:\")\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\nresult = compute_dot_product(v1, v2)\nprint(f\" v1: {v1}\")\nprint(f\" v2: {v2}\")\nprint(f\" Dot product: {result}\")\nprint(f\" Explanation: (1\u00d74) + (2\u00d75) + (3\u00d76) = {result}\") # Test 3: Matrix multiplication print(\"\\n3. matrix_multiplication:\") A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]])\nresult = matrix_multiplication(A, B)\nprint(f\" A:\\n{A}\")\nprint(f\" B:\\n{B}\")\nprint(f\" A @ B:\\n{result}\")\nprint(f\" Explanation:\")\nprint(f\" - First row: [1\u00d75+2\u00d77, 1\u00d76+2\u00d78] = [{result[0,0]}, {result[0,1]}]\")\nprint(f\" - Second row: [3\u00d75+4\u00d77, 3\u00d76+4\u00d78] = [{result[1,0]}, {result[1,1]}]\") # Test 4: Transpose print(\"\\n4. compute_transpose:\")\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])\nresult = compute_transpose(matrix)\nprint(f\" Original:\\n{matrix}\")\nprint(f\" Shape: {matrix.shape}\")\nprint(f\" Transposed:\\n{result}\")\nprint(f\" Shape: {result.shape}\")\nprint(f\" Explanation: Rows become columns, columns become rows\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 Solution verified!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nif__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\nprint(\"=\" * 60) # Test 1: Create data matrix print(\"\\n1. create_data_matrix:\")\ndata = create_data_matrix(5, 3)\nprint(f\" Created matrix shape: {data.shape}\")\nprint(f\" Matrix:\\n{data}\") # Test 2: Dot product print(\"\\n2. compute_dot_product:\")\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\nresult = compute_dot_product(v1, v2)\nprint(f\" v1: {v1}\")\nprint(f\" v2: {v2}\")\nprint(f\" Dot product: {result}\")\nprint(f\" Explanation: (1\u00d74) + (2\u00d75) + (3\u00d76) = {result}\") # Test 3: Matrix multiplication print(\"\\n3. matrix_multiplication:\") A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]])\nresult = matrix_multiplication(A, B)\nprint(f\" A:\\n{A}\")\nprint(f\" B:\\n{B}\")\nprint(f\" A @ B:\\n{result}\")\nprint(f\" Explanation:\")\nprint(f\" - First row: [1\u00d75+2\u00d77, 1\u00d76+2\u00d78] = [{result[0,0]}, {result[0,1]}]\")\nprint(f\" - Second row: [3\u00d75+4\u00d77, 3\u00d76+4\u00d78] = [{result[1,0]}, {result[1,1]}]\") # Test 4: Transpose print(\"\\n4. compute_transpose:\")\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])\nresult = compute_transpose(matrix)\nprint(f\" Original:\\n{matrix}\")\nprint(f\" Shape: {matrix.shape}\")\nprint(f\" Transposed:\\n{result}\")\nprint(f\" Shape: {result.shape}\")\nprint(f\" Explanation: Rows become columns, columns become rows\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 Solution verified!\")\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    if__name__ == \"__main__\": print(\"Solution 01: Vector and Matrix Operations\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_01/exercises/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.6029658317565918,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_determinant(matrix): return np.linalg.det(matrix)\ndef compute_matrix_inverse(matrix): return np.linalg.inv(matrix)\ndef compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix)\nreturn eigenvals, eigenvecs\ndef verify_inverse(matrix, inverse): identity = np.eye(matrix.shape[0])\nresult = matrix @ inverse return np.allclose(result, identity)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = matrix @ inverse return np.allclose(result, identity)# Test the solution\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_determinant(matrix): return np.linalg.det(matrix)\ndef compute_matrix_inverse(matrix): return np.linalg.inv(matrix)\ndef compute_eigenvalues_eigenvectors(matrix): eigenvals, eigenvecs = np.linalg.eig(matrix)\nreturn eigenvals, eigenvecs\ndef verify_inverse(matrix, inverse): identity = np.eye(matrix.shape[0])\nresult = matrix @ inverse return np.allclose(result, identity)# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = matrix @ inverse return np.allclose(result, identity)# Test the solution\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_02/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.5487282276153564,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead\ndef compute_derivative(func, x, h=1e-6): return (func(x + h) - func(x))\nh\ndef compute_gradient(func, point): h = 1e-6 grad = np.zeros_like(point)\nfor i in range(len(point)): # Create points for computing partial derivative point_plus = point.copy() point_plus[i] += h point_minus = point.copy() point_minus[i] -= h # Partial derivative: \u2202f/\u2202x\ni \u2248 (f(x+h) - f(x-h))\n(2\nh)\ngrad[i] = (func(point_plus) - func(point_minus))\n(2 * h)\nreturn grad\ndef gradient_descent_step(func, x, learning_rate = 0.1): h = 1e-6 # Compute gradient numerically grad = (func(x + h) - func(x - h))\n(2 * h) # Move in opposite direction return x - learning\nrate * grad# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    i \u2248 (f(x+h) - f(x-h))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '\u2248' (U+2248)\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy.optimize import approx_fprime\n# Note: scipy.misc.derivative moved, using approx_fprime instead\ndef compute_derivative(func, x, h=1e-6): return (func(x + h) - func(x))\nh\ndef compute_gradient(func, point): h = 1e-6 grad = np.zeros_like(point)\nfor i in range(len(point)): # Create points for computing partial derivative point_plus = point.copy() point_plus[i] += h point_minus = point.copy() point_minus[i] -= h # Partial derivative: \u2202f/\u2202x\ni \u2248 (f(x+h) - f(x-h))\n(2\nh)\ngrad[i] = (func(point_plus) - func(point_minus))\n(2 * h)\nreturn grad\ndef gradient_descent_step(func, x, learning_rate = 0.1): h = 1e-6 # Compute gradient numerically grad = (func(x + h) - func(x - h))\n(2 * h) # Move in opposite direction return x - learning\nrate * grad# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    i \u2248 (f(x+h) - f(x-h))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '\u2248' (U+2248)\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_02/exercises/solutions/solution_02.ipynb",
      "status": "failed",
      "execution_time": 0.6146900653839111,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\nreturn x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50): results = {} for lr in learning_rates: final_x, _ = gradient_descent(func, gradient_func, initial_x, lr, iterations)\nresults[lr] = final\nx return results# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\nreturn x, history\ndef analyze_learning_rate(func, gradient_func, initial_x, learning_rates, iterations=50): results = {} for lr in learning_rates: final_x, _ = gradient_descent(func, gradient_func, initial_x, lr, iterations)\nresults[lr] = final\nx return results# Test the solution\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def gradient_descent(func, gradient_func, initial_x, learning_rate = 0.1, iterations=100): x = initial_x history = [x] for i in range(iterations): # Compute gradient at current point grad = gradient_func(x) # Update: move in opposite direction of gradient x = x - learning_rate * grad history.append(x)\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_03/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7452218532562256,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nclass SimpleGDOptimizer: \n\ndef__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\nclass MomentumOptimizer: \n\ndef__init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.velocity = None def update(self, params, grads): if self.velocity is None: self.velocity = np.zeros_like(params) # Update velocity: v = momentum * v + lr * grads self.velocity = self.momentum * self.velocity + self.lr * grads # Update params: params = params - velocity return params - self.velocity\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100): results = {} for name, optimizer in optimizers.items(): params = initial_params.copy() if isinstance(initial_params, np.ndarray) else initial_params for i in range(iterations): grads = grad_func(params) params = optimizer.update(params, grads) results[name] = params return results\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 2\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nclass SimpleGDOptimizer: \n\ndef__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\nclass MomentumOptimizer: \n\ndef__init__(self, lr=0.01, momentum=0.9): self.lr = lr self.momentum = momentum self.velocity = None def update(self, params, grads): if self.velocity is None: self.velocity = np.zeros_like(params) # Update velocity: v = momentum * v + lr * grads self.velocity = self.momentum * self.velocity + self.lr * grads # Update params: params = params - velocity return params - self.velocity\ndef compare_optimizers(loss_func, grad_func, initial_params, optimizers, iterations=100): results = {} for name, optimizer in optimizers.items(): params = initial_params.copy() if isinstance(initial_params, np.ndarray) else initial_params for i in range(iterations): grads = grad_func(params) params = optimizer.update(params, grads) results[name] = params return results\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self, lr=0.01): self.lr = lr def update(self, params, grads): return params - self.lr * grads\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 2\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_04/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.7431929111480713,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_covariance_matrix(data): # Center the data (subtract mean) centered = data - np.mean(data, axis=0) # Compute covariance: (1/n) * X^T @ X n = data.shape[0] return (centered.T @ centered)\n(n - 1)\ndef pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\ncomponents top_eigenvectors = eigenvectors[:, :n_components] # 6. Project data reduced = centered @ top_eigenvectors # 7. Calculate explained variance ratio explained_variance_ratio = np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues) return reduced, explained_variance_ratio\ndef calculate_variance_explained(eigenvalues, n_components): return np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    (n - 1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\ndef compute_covariance_matrix(data): # Center the data (subtract mean) centered = data - np.mean(data, axis=0) # Compute covariance: (1/n) * X^T @ X n = data.shape[0] return (centered.T @ centered)\n(n - 1)\ndef pca_from_scratch(data, n_components = 2): # 1. Center the data mean = np.mean(data, axis=0) centered = data - mean # 2. Compute covariance matrix cov = compute_covariance_matrix(data) # 3. Find eigenvalues and eigenvectors eigenvalues, eigenvectors = np.linalg.eig(cov) # 4. Sort by eigenvalues (descending) idx = np.argsort(eigenvalues)[::-1] eigenvalues = eigenvalues[idx] eigenvectors = eigenvectors[:, idx] # 5. Select top n\ncomponents top_eigenvectors = eigenvectors[:, :n_components] # 6. Project data reduced = centered @ top_eigenvectors # 7. Calculate explained variance ratio explained_variance_ratio = np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues) return reduced, explained_variance_ratio\ndef calculate_variance_explained(eigenvalues, n_components): return np.sum(eigenvalues[:n_components])\nnp.sum(eigenvalues)\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    (n - 1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    },
    {
      "path": "SOLUTIONS_ALL/Course03/modules/module_05/exercises/solutions/solution_01.ipynb",
      "status": "failed",
      "execution_time": 0.8152010440826416,
      "error": "An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95): n = len(data)\nmean = np.mean(data)\nstd_err = stats.sem(data) # Standard error of the mean # Get t-critical value alpha = 1 - confidence t_critical = stats.t.ppf(1 - alpha/2, df=n-1) # Compute CI margin = t_critical * std\nerr lower = mean - margin upper = mean + margin return (lower, upper)\ndef t_test_two_samples(sample1, sample2): t_stat, p_value = stats.ttest_ind(sample1, sample2)\nreturn t_stat, p_value\ndef interpret_p_value(p_value, alpha=0.05): if p_value < alpha: return f\"Significant difference (p={p_value:.4f} < {alpha})\" else: return f\"No significant difference (p={p_value:.4f} >= {alpha})\"def compare_models(model1_scores, model2_scores, alpha=0.05): # Compute means and CIs mean1 = np.mean(model1_scores)\nmean2 = np.mean(model2_scores)\nci1 = compute_confidence_interval(model1_scores)\nci2 = compute_confidence_interval(model2_scores) # Perform t-test t\nstat, p_value = t_test_two_samples(model1_scores, model2_scores) # Interpret interpretation = interpret_p_value(p_value, alpha)\nreturn { 'model1_mean': mean1, 'model2_mean': mean2, 'model1_ci': ci1, 'model2_ci': ci2, 't_statistic': t_stat, 'p_value': p_value, 'interpretation': interpretation, 'significant': p\nvalue < alpha }\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    err lower = mean - margin upper = mean + margin return (lower, upper)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n",
      "error_traceback": "Traceback (most recent call last):\n  File \"/Users/abdullah/Downloads/AI Diploma/tools/notebook_runner.py\", line 103, in execute_notebook_nbclient\n    client.execute()\n    ~~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n    return loop.run_until_complete(inner)\n           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n  File \"/opt/anaconda3/lib/python3.13/asyncio/base_events.py\", line 725, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 709, in async_execute\n    await self.async_execute_cell(\n        cell, index, execution_count=self.code_cells_executed + 1\n    )\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 1062, in async_execute_cell\n    await self._check_raise_for_error(cell, cell_index, exec_reply)\n  File \"/opt/anaconda3/lib/python3.13/site-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\nnbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n------------------\nimport numpy as np\nfrom scipy import stats\ndef compute_confidence_interval(data, confidence=0.95): n = len(data)\nmean = np.mean(data)\nstd_err = stats.sem(data) # Standard error of the mean # Get t-critical value alpha = 1 - confidence t_critical = stats.t.ppf(1 - alpha/2, df=n-1) # Compute CI margin = t_critical * std\nerr lower = mean - margin upper = mean + margin return (lower, upper)\ndef t_test_two_samples(sample1, sample2): t_stat, p_value = stats.ttest_ind(sample1, sample2)\nreturn t_stat, p_value\ndef interpret_p_value(p_value, alpha=0.05): if p_value < alpha: return f\"Significant difference (p={p_value:.4f} < {alpha})\" else: return f\"No significant difference (p={p_value:.4f} >= {alpha})\"def compare_models(model1_scores, model2_scores, alpha=0.05): # Compute means and CIs mean1 = np.mean(model1_scores)\nmean2 = np.mean(model2_scores)\nci1 = compute_confidence_interval(model1_scores)\nci2 = compute_confidence_interval(model2_scores) # Perform t-test t\nstat, p_value = t_test_two_samples(model1_scores, model2_scores) # Interpret interpretation = interpret_p_value(p_value, alpha)\nreturn { 'model1_mean': mean1, 'model2_mean': mean2, 'model1_ci': ci1, 'model2_ci': ci2, 't_statistic': t_stat, 'p_value': p_value, 'interpretation': interpretation, 'significant': p\nvalue < alpha }\n------------------\n\n\n\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    err lower = mean - margin upper = mean + margin return (lower, upper)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n\n\n",
      "course": null,
      "unit": null,
      "type": "exercise"
    }
  ],
  "summary": {
    "passed": 631,
    "failed": 186,
    "pass_rate": 77.23378212974296
  }
}