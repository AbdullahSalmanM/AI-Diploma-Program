{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Unit 4 - Example 1: RNNs and LSTMs for NLP\n",
        "الوحدة 4 - مثال 1: RNNs و LSTMs لمعالجة اللغة الطبيعية\n",
        "\n",
        "This example demonstrates:\n",
        "1. RNN architecture for sequences\n",
        "2. LSTM for long-term dependencies\n",
        "3. Text sequence modeling\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Example 1: RNNs and LSTMs for NLP\")\n",
        "print(\"مثال 1: RNNs و LSTMs لمعالجة اللغة الطبيعية\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Understanding RNNs\n",
        "# فهم RNNs\n",
        "print(\"\\n1. Recurrent Neural Networks (RNNs)\")\n",
        "print(\"الشبكات العصبية المتكررة (RNNs)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "rnn_explanation = \"\"\"\n",
        "RNN Structure:\n",
        "- Processes sequences one element at a time\n",
        "- Maintains hidden state across time steps\n",
        "- Can remember previous context\n",
        "- Useful for sequential data like text\n",
        "\n",
        "هيكل RNN:\n",
        "- يعالج التسلسلات عنصراً واحداً في كل مرة\n",
        "- يحافظ على الحالة المخفية عبر الخطوات الزمنية\n",
        "- يمكنه تذكر السياق السابق\n",
        "- مفيد للبيانات المتسلسلة مثل النص\n",
        "\"\"\"\n",
        "\n",
        "print(rnn_explanation)\n",
        "\n",
        "# 2. LSTM for Long-term Dependencies\n",
        "# LSTM للتبعيات طويلة المدى\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"2. Long Short-Term Memory (LSTM)\")\n",
        "print(\"الذاكرة قصيرة وطويلة المدى (LSTM)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "lstm_explanation = \"\"\"\n",
        "LSTM Advantages over RNN:\n",
        "- Can remember information for longer periods\n",
        "- Solves vanishing gradient problem\n",
        "- Better for long sequences\n",
        "- Three gates: Forget, Input, Output\n",
        "\n",
        "مزايا LSTM على RNN:\n",
        "- يمكنه تذكر المعلومات لفترات أطول\n",
        "- يحل مشكلة اختفاء التدرج\n",
        "- أفضل للتسلسلات الطويلة\n",
        "- ثلاث بوابات: النسيان، الإدخال، الإخراج\n",
        "\"\"\"\n",
        "\n",
        "print(lstm_explanation)\n",
        "\n",
        "# 3. Simple Sequence Example\n",
        "# مثال بسيط على التسلسل\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"3. Sequence Modeling Example\")\n",
        "print(\"مثال على نمذجة التسلسل\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Simple character-level sequence\n",
        "# تسلسل بسيط على مستوى الأحرف\n",
        "text_sequence = \"hello\"\n",
        "char_to_int = {char: i for i, char in enumerate(set(text_sequence))}\n",
        "int_to_char = {i: char for char, i in char_to_int.items()}\n",
        "\n",
        "print(f\"\\nText sequence: {text_sequence}\")\n",
        "print(f\"Character mapping: {char_to_int}\")\n",
        "\n",
        "# Convert to sequence of integers\n",
        "# تحويل إلى تسلسل من الأعداد الصحيحة\n",
        "sequence = [char_to_int[char] for char in text_sequence]\n",
        "print(f\"Integer sequence: {sequence}\")\n",
        "\n",
        "# Simulate RNN processing\n",
        "# محاكاة معالجة RNN\n",
        "print(\"\\nSimulating RNN processing:\")\n",
        "print(\"محاكاة معالجة RNN:\")\n",
        "hidden_state = 0\n",
        "for i, char_int in enumerate(sequence):\n",
        "    char = int_to_char[char_int]\n",
        "    # Simple update (in real RNN, this would be a neural network)\n",
        "    hidden_state = hidden_state * 0.5 + char_int * 0.5\n",
        "    print(f\"  Step {i+1}: Input='{char}' ({char_int}), Hidden state={hidden_state:.2f}\")\n",
        "\n",
        "# 4. Applications\n",
        "# التطبيقات\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"4. NLP Applications\")\n",
        "print(\"تطبيقات معالجة اللغة الطبيعية\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "applications = {\n",
        "    \"Text Generation\": \"Generate next word/character in sequence\",\n",
        "    \"Sentiment Analysis\": \"Classify sentiment of text sequences\",\n",
        "    \"Machine Translation\": \"Translate sequences from one language to another\",\n",
        "    \"Named Entity Recognition\": \"Identify entities in text sequences\"\n",
        "}\n",
        "\n",
        "print(\"\\nCommon Applications:\")\n",
        "print(\"التطبيقات الشائعة:\")\n",
        "for app, description in applications.items():\n",
        "    print(f\"\\n{app}:\")\n",
        "    print(f\"  {description}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Example completed successfully!\")\n",
        "print(\"تم إكمال المثال بنجاح!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nNote: For actual implementation, use TensorFlow/Keras or PyTorch\")\n",
        "print(\"ملاحظة: للتنفيذ الفعلي، استخدم TensorFlow/Keras أو PyTorch\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}